{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ieVSoT-0TvDE",
        "Af3fBq_dsjSr",
        "TPPM61ACUCdN",
        "-CwvtZqNUQ4u",
        "aaxk0FML3Mjo",
        "LUNow4c31PAr",
        "qQubMtF_ousL"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dev Notes"
      ],
      "metadata": {
        "id": "4B9iwgtHqack"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REALLY HACKY FIX FOR OBTAINING Hidden State:\n",
        "- Swapped the keys for the testing function (bic version) such that hidden state tensor is located at the 'network_activity' key, and hidden layer output activity is located at 'network_hidden_state'\n",
        "- This means. IF I WANT TO RUN IT AGAIN BUT USE THE OUTPUT ACTIVITY FOR THE ANALYSIS AND THEN USE HIDDEN STATE FPS WITH RELU ACTIVATION TO PLOT ALONGSIDE THE HIDDEN LAYER OUTPUT ACTIVITY FROM TESTING TRIALS:\n",
        "  -  NEED TO RE RUN WITH THE FOLLOWING:\n",
        "    - Keys swapped back\n",
        "    - hidden_key (in FPF input) == 'network_hidden_state'\n",
        "    - (Easier to copy note book and rerun like this)"
      ],
      "metadata": {
        "id": "V3fyHK95Dvjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CURRENT MODE == ANALYSE HIDDEN STATE"
      ],
      "metadata": {
        "id": "s5qbdCjhEk_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages ((un)comment neuro and sb imports)"
      ],
      "metadata": {
        "id": "FY1zE_W-zNCH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWp1iecHfRWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dcf61b-46fb-4f7f-bc82-6a95910874d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neurogym in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.11/dist-packages (from neurogym) (2.10.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from neurogym) (4.67.1)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.13.3)\n",
            "Requirement already satisfied: numpy==2.1.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (2.1.3)\n",
            "Requirement already satisfied: gymnasium==0.29.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.29.1)\n",
            "Requirement already satisfied: matplotlib==3.9.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (3.9.4)\n",
            "Requirement already satisfied: scipy==1.14.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (1.14.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (2.9.0.post0)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (0.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->pydantic-settings->neurogym) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->pydantic-settings->neurogym) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.*->neurogym) (1.17.0)\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-3e_npxdq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-3e_npxdq\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit bf51a6233a8f934a68430f8f78e44360410d23ca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (0.29.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (3.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3==2.7.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3==2.7.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: stable_baselines3\n",
            "  Building wheel for stable_baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable_baselines3: filename=stable_baselines3-2.7.0-py3-none-any.whl size=187216 sha256=55d1d1adedaa12d2b7d2c13a81a7c310883492b1e185c839867d0d9a27e1e901\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3x1muxle/wheels/4e/50/0a/1b04f64886428aef488eca102d1c66b00f5218ca4ec32fa9e6\n",
            "Successfully built stable_baselines3\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.7.0\n",
            "Collecting git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
            "  Cloning https://github.com/Stable-Baselines-Team/stable-baselines3-contrib to /tmp/pip-req-build-99bs8zpa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Stable-Baselines-Team/stable-baselines3-contrib /tmp/pip-req-build-99bs8zpa\n",
            "  Resolved https://github.com/Stable-Baselines-Team/stable-baselines3-contrib to commit 33889dbb215b8992bf463551657b79241f4bccf8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sb3_contrib==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.29.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.0.2)\n",
            "Building wheels for collected packages: sb3_contrib\n",
            "  Building wheel for sb3_contrib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sb3_contrib: filename=sb3_contrib-2.7.0-py3-none-any.whl size=93173 sha256=82b7e706868e2752fe871cd5cf67d2ee81ee626417d7ba8aaf11817037cae50e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dr8lo7fu/wheels/f0/c6/aa/f7853333ad7a263ac541ccb1fff7a8ebcb1d94855318f2a49a\n",
            "Successfully built sb3_contrib\n",
            "Installing collected packages: sb3_contrib\n",
            "Successfully installed sb3_contrib-2.7.0\n",
            "Collecting deepdiff\n",
            "  Downloading deepdiff-8.5.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Downloading deepdiff-8.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: orderly-set, deepdiff\n",
            "Successfully installed deepdiff-8.5.0 orderly-set-5.5.0\n"
          ]
        }
      ],
      "source": [
        "# # # # # Uncomment VV for session restart\n",
        "!pip install neurogym\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "!pip install git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "!pip install deepdiff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D-CJ15dewzV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from copy import deepcopy\n",
        "from sklearn.decomposition import PCA\n",
        "import itertools # Unused if not gridsearching\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"matplotlib\").setLevel(logging.CRITICAL)\n",
        "\n",
        "device = 'cpu'\n",
        "import neurogym as ngym\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Suppress UserWarnings specifically from the 'gymnasium' module\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium\")\n",
        "\n",
        "## Extras\n",
        "from matplotlib.lines import Line2D\n",
        "from collections import defaultdict\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Regime (Training with Validation Thresholding and Early Stopping)"
      ],
      "metadata": {
        "id": "6iIYcnr02hH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Function"
      ],
      "metadata": {
        "id": "iEJ5UG072zly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component function to run eval style trials on network for a single dataset (task trial setup)"
      ],
      "metadata": {
        "id": "i11UiICa3UBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6k_YFOjPeHr"
      },
      "outputs": [],
      "source": [
        "def validate_network(net, dataset, num_trials=200):\n",
        "    # same as test but no print statements\n",
        "    # Reset environment\n",
        "  env = dataset.env\n",
        "  env.reset()\n",
        "\n",
        "  # Initialise variables for logging\n",
        "  # perf = 0\n",
        "  activity_dict = {}  # recording activity\n",
        "  trial_infos = {}  # recording trial information\n",
        "\n",
        "  num_trial = num_trials\n",
        "  for i in range(num_trial):\n",
        "      # Neurogym boiler plate\n",
        "      # Sample a new trial\n",
        "      trial_info = env.new_trial()\n",
        "      # Observation and groud-truth of this trial\n",
        "      ob, gt = env.ob, env.gt\n",
        "      # Convert to numpy, add batch dimension to input\n",
        "      inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "      # Run the network for one trial\n",
        "      # inputs (SeqLen, Batch, InputSize)\n",
        "      # action_pred (SeqLen, Batch, OutputSize)\n",
        "      action_pred, rnn_activity = net(inputs)\n",
        "\n",
        "      # Compute performance\n",
        "      # First convert back to numpy\n",
        "\n",
        "      action_pred = action_pred.detach().numpy()[:, 0, :]\n",
        "      # Read out final choice at last time step\n",
        "      choice = np.argmax(action_pred[-1, :])\n",
        "      # Compare to ground truth\n",
        "      correct = choice == gt[-1]\n",
        "\n",
        "      # Record activity, trial information, choice, correctness\n",
        "      rnn_activity = rnn_activity[:, 0, :].detach().numpy()\n",
        "      activity_dict[i] = rnn_activity\n",
        "      trial_infos[i] = trial_info  # trial_info is a dictionary\n",
        "      trial_infos[i].update({'correct': correct})\n",
        "  avg_trial_performance = np.mean([val['correct'] for val in trial_infos.values()])\n",
        "  return trial_infos, activity_dict, avg_trial_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stop Validation Helper"
      ],
      "metadata": {
        "id": "cmLH2ZaP26A3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calling Validation Component for each validation data set and returning Performances to main training function"
      ],
      "metadata": {
        "id": "XCOwR_p-3R4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def early_stop_validation(model_in_training, validation_set_dict, validation_trials=200):\n",
        "  performance_dict = {}\n",
        "  for dataset_name, dataset in validation_set_dict.items():\n",
        "    trial_infos_valid, activity_dict_valid, avg_trial_performance_valid = validate_network(model_in_training, dataset, num_trials=validation_trials)\n",
        "    performance_dict[dataset_name] = avg_trial_performance_valid\n",
        "    # print(f'{dataset_name} - Accuracy : {avg_trial_performance_vt}')\n",
        "  return performance_dict\n"
      ],
      "metadata": {
        "id": "HOhkI7evHSvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Training Function (Bics run from pre-trained (check training nb)"
      ],
      "metadata": {
        "id": "C4KfC0k33ap8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1AGOSEsMG21"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def training_with_early_stop(model, training_set, validation_set_dict, max_steps = 10000, min_validation_perf = 0.8, patience = 5, num_steps_for_early_stop_check = 500, num_validation_trials = 200, model_name = 'model_name', tr_output_mode = False):\n",
        "\n",
        "      # validation_set_dict is like = {'Short': <neurogym dataset object> , ... }\n",
        "      # training set is like <neurogym dataset object>\n",
        "\n",
        "      # PERFORMANCE is each individual validation set accuracy\n",
        "      # ACCURACY is the overall average of these\n",
        "      # ES is for early stopping, i.e. perf/accuracy of validations that meet the es conditions (>threshold)\n",
        "      # all is for all i.e. perf/accuracy of validations that haven't met the es conditions\n",
        "\n",
        "      output_size = model.output_size\n",
        "\n",
        "      # we need to retain running loss / validation performances for plotting learning curves\n",
        "      # Learning tracking\n",
        "      # Training Loss Tracking\n",
        "      tr_epochs_loss = []\n",
        "      tr_loss = []\n",
        "\n",
        "      # Validation Performance Tracking\n",
        "      tr_epochs_valid_perf = []\n",
        "      tr_valid_perfs_list_of_dicts = []\n",
        "      tr_valid_perfs_avg = []\n",
        "      n_steps_first_th = 0\n",
        "      n_steps_final = 0\n",
        "\n",
        "      # Setup\n",
        "      optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      running_loss = 0\n",
        "      running_acc = 0\n",
        "      start_time = time.time()\n",
        "\n",
        "      # Loop over training batches\n",
        "      print('Training network...')\n",
        "\n",
        "      current_best_valid_accuracy_es = 0.0\n",
        "      current_best_valid_accuracy_all = 0.0\n",
        "\n",
        "\n",
        "      # set best_valid_performance_es to a list of len n containing zeros where n is number of keys in validation_set_dict\n",
        "      best_valid_performance_all = [0 for _ in validation_set_dict.keys()]\n",
        "      best_valid_performance_es = [0 for _ in validation_set_dict.keys()]\n",
        "      surpassed_threshold = False\n",
        "      current_patience = patience\n",
        "      model.train()\n",
        "      model_save_name = f'{model_name}_best.pth'\n",
        "      for i in range(max_steps):\n",
        "\n",
        "          # Generate input and target, convert to pytorch tensor\n",
        "          # inputs, labels = dataset()\n",
        "          inputs, labels = training_set()\n",
        "          inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "          labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "                  # boiler plate pytorch training:\n",
        "          optimiser.zero_grad()   # zero the gradient buffers\n",
        "          output, _ = model(inputs)\n",
        "          # Reshape to (SeqLen x Batch, OutputSize)\n",
        "          output = output.view(-1, output_size)\n",
        "\n",
        "          loss = criterion(output, labels)\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "          optimiser.step()    # Does the update\n",
        "          running_loss += loss.item()\n",
        "          if i % 100 == 99:\n",
        "            running_loss /= 100\n",
        "            print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i+1, running_loss, time.time() - start_time))\n",
        "            tr_epochs_loss.append(i+1)\n",
        "            tr_loss.append(running_loss)\n",
        "\n",
        "            running_loss = 0\n",
        "          if (i + 1) % num_steps_for_early_stop_check == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "              current_perf_dict = early_stop_validation(model, validation_set_dict, num_validation_trials)\n",
        "              print(f'Current Performance Dict: {current_perf_dict}')\n",
        "              list_avg_perfs = list(current_perf_dict.values())\n",
        "              average_perf = np.mean(list_avg_perfs)\n",
        "\n",
        "              tr_epochs_valid_perf.append(i+1)\n",
        "              tr_valid_perfs_list_of_dicts.append(current_perf_dict) # Means we retain labels for performance scores for the plot\n",
        "              tr_valid_perfs_avg.append(average_perf)\n",
        "\n",
        "              print(f'Current Average Performance: {average_perf}')\n",
        "              status_list = [i>min_validation_perf for i in list_avg_perfs]\n",
        "\n",
        "              performance_th_list = [i>j for i,j in zip(list_avg_perfs, best_valid_performance_all)]\n",
        "\n",
        "              best_valid_performance_all = list_avg_perfs if all(performance_th_list) else best_valid_performance_all\n",
        "\n",
        "              current_best_valid_accuracy_all = average_perf if average_perf > current_best_valid_accuracy_all else current_best_valid_accuracy_all\n",
        "              if all(status_list):\n",
        "                surpassed_threshold = True\n",
        "                n_steps_first_th = i+1\n",
        "                num_steps_for_early_stop_check = 100\n",
        "                if average_perf > current_best_valid_accuracy_es:\n",
        "                  current_best_valid_accuracy_es = average_perf\n",
        "                  best_valid_performance_es = list_avg_perfs\n",
        "                  # create a file of current best model\n",
        "                  torch.save(model.state_dict(), model_save_name)\n",
        "                  # Reset patience\n",
        "                  current_patience = patience\n",
        "                elif ((average_perf == current_best_valid_accuracy_es) and (current_patience > 0)):\n",
        "                  current_best_valid_accuracy_es = average_perf\n",
        "                  best_valid_performance_es = list_avg_perfs\n",
        "                  # create a file of current best model\n",
        "                  torch.save(model.state_dict(), model_save_name)\n",
        "                  # Dont Reset patience, continue to decrease (model trains a bit more beyond first attempt at 100)\n",
        "                  current_patience -= 1\n",
        "\n",
        "                else:\n",
        "                  if current_patience <= 0:\n",
        "                    n_steps_final = i+1\n",
        "                    print('Early Stopping. I have run out of patience Grrr' )\n",
        "                    break\n",
        "                  else:\n",
        "                    current_patience -= 1\n",
        "              elif surpassed_threshold == True:\n",
        "                if current_patience <= 0:\n",
        "                    n_steps_final = i+1\n",
        "                    print('Early Stopping. I have run out of patience Grrr' )\n",
        "                    break\n",
        "                else:\n",
        "                    current_patience -= 1\n",
        "\n",
        "            model.train()\n",
        "      learning_curve_dict = {\n",
        "            'training_loss_epochs_list': tr_epochs_loss,\n",
        "            'training_total_loss_values_list' : tr_loss,\n",
        "            'validation_perf_epochs_list': tr_epochs_valid_perf,\n",
        "            'validation_perf_dicts_list' : tr_valid_perfs_list_of_dicts,\n",
        "            'validation_perf_avg_values_list' : tr_valid_perfs_avg,\n",
        "            'n_steps_first_th' : n_steps_first_th,\n",
        "            'n_steps_final' : n_steps_final\n",
        "              }\n",
        "      # Try to Load best model from last saved file. Handle for if it doesn't exist!\n",
        "      try:\n",
        "        model.load_state_dict(torch.load(model_save_name))\n",
        "        print('Best model loaded')\n",
        "        # Print best performance stats\n",
        "        for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_es):\n",
        "          print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "        if tr_output_mode:\n",
        "          return model, learning_curve_dict\n",
        "\n",
        "        return model\n",
        "      except:\n",
        "        print('No best model that satisfies validation threshold found')\n",
        "        print(f'Best all time performance: {current_best_valid_accuracy_all}')\n",
        "        for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_all):\n",
        "          print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "        if tr_output_mode:\n",
        "          return model, learning_curve_dict\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function for BIC Networks"
      ],
      "metadata": {
        "id": "FYleT7hUJtk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training_with_early_stop_and_regularisation(\n",
        "    model,\n",
        "    training_set,\n",
        "    validation_set_dict,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='model_name',\n",
        "    tr_output_mode=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains mode (optional wiring distance and activity regularisation if used in BICs),\n",
        "    keeps the early stop mechanism. Also tracks non task loss to plot if needed.\n",
        "    (Baso a Cleaned up version of the main training function with additional functionality for BICs - keep other in case ive fd up)\n",
        "    \"\"\"\n",
        "    # --- Setup ---\n",
        "    output_size = model.output_size\n",
        "    optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    start_time = time.time()\n",
        "    model_save_name = f'{model_name}_best.pth'\n",
        "\n",
        "    # --- Loss Tracking ---\n",
        "    tr_epochs_loss = []\n",
        "    tr_total_loss_values = []\n",
        "    tr_task_loss_values = []\n",
        "    tr_wiring_loss_values = []\n",
        "    tr_activity_loss_values = []\n",
        "    running_loss = 0\n",
        "    running_task_loss = 0\n",
        "    running_wiring_loss = 0\n",
        "    running_activity_loss = 0\n",
        "\n",
        "    # --- Validation and Early Stopping Tracking ---\n",
        "    tr_epochs_valid_perf = []\n",
        "    tr_valid_perfs_list_of_dicts = []\n",
        "    tr_valid_perfs_avg = []\n",
        "    n_steps_first_th = 0\n",
        "    n_steps_final = 0\n",
        "    current_best_valid_accuracy_es = 0.0\n",
        "    current_best_valid_accuracy_all = 0.0\n",
        "    best_valid_performance_all = [0 for _ in validation_set_dict.keys()]\n",
        "    best_valid_performance_es = [0 for _ in validation_set_dict.keys()]\n",
        "    surpassed_threshold = False\n",
        "    current_patience = patience\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    print('Training network...')\n",
        "    model.train()\n",
        "    for i in range(max_steps):\n",
        "        # --- Data ---\n",
        "        inputs, labels = training_set()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        # --- Forward Pass and Loss Calc ---\n",
        "        optimiser.zero_grad()\n",
        "        output, rnn_output = model(inputs) # Now Capturing rnn_output for activity loss\n",
        "        output = output.view(-1, output_size)\n",
        "\n",
        "        # 1. Task Loss (styll)\n",
        "        task_loss = criterion(output, labels)\n",
        "\n",
        "        # 2. Wiring Loss (is optional, adding 0 has no effect)\n",
        "        wiring_loss = torch.tensor(0.0)\n",
        "        if WD_approach:\n",
        "            wiring_loss = WD_regulariser(model)\n",
        "        elif 'penalise_weight_distance' in dir(model): # Check if method exists\n",
        "             wiring_loss = wiring_beta * model.penalise_weight_distance()\n",
        "\n",
        "        # 3. Activity Loss (optional)\n",
        "        activity_loss = torch.tensor(0.0)\n",
        "        if activity_regularisation:\n",
        "            activity_loss = activity_beta * torch.mean(rnn_output**2)\n",
        "\n",
        "        # Total Loss\n",
        "        loss = task_loss + wiring_loss + activity_loss\n",
        "\n",
        "        # --- Backprop and optmise step ---\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimiser.step()\n",
        "\n",
        "        # --- Tracking all loss components  ---\n",
        "        running_loss += loss.item()\n",
        "        running_task_loss += task_loss.item()\n",
        "        running_wiring_loss += wiring_loss.item()\n",
        "        running_activity_loss += activity_loss.item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            # running losses\n",
        "            running_loss /= 100\n",
        "            running_task_loss /= 100\n",
        "            running_wiring_loss /= 100\n",
        "            running_activity_loss /= 100\n",
        "\n",
        "            print(f'Step {i+1}, Total Loss: {running_loss:.4f}, Time: {time.time() - start_time:.1f}s')\n",
        "            print(f' Loss Components -> Task: {running_task_loss:.4f}, Wiring: {running_wiring_loss:.4f}, Activity: {running_activity_loss:.4f}')\n",
        "\n",
        "            # Append to tracking lists\n",
        "            tr_epochs_loss.append(i + 1)\n",
        "            tr_total_loss_values.append(running_loss)\n",
        "            tr_task_loss_values.append(running_task_loss)\n",
        "            tr_wiring_loss_values.append(running_wiring_loss)\n",
        "            tr_activity_loss_values.append(running_activity_loss)\n",
        "\n",
        "            # Reset running losses\n",
        "            running_loss, running_task_loss, running_wiring_loss, running_activity_loss = 0, 0, 0, 0\n",
        "\n",
        "        # --- Early Stopping Check ---\n",
        "        if (i + 1) % num_steps_for_early_stop_check == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                current_perf_dict = early_stop_validation(model, validation_set_dict, num_validation_trials)\n",
        "                list_avg_perfs = list(current_perf_dict.values())\n",
        "                average_perf = np.mean(list_avg_perfs)\n",
        "\n",
        "                tr_epochs_valid_perf.append(i + 1)\n",
        "                tr_valid_perfs_list_of_dicts.append(current_perf_dict)\n",
        "                tr_valid_perfs_avg.append(average_perf)\n",
        "                print(f'Validation at Step {i+1} | Avg Perf: {average_perf:.3f}')\n",
        "\n",
        "                # Print all performances by key and perf value , without new line\n",
        "                for key, value in current_perf_dict.items():\n",
        "                    print(f'{key}: {value:.3f}', end=' ')\n",
        "                print()\n",
        "                status_list = [p > min_validation_perf for p in list_avg_perfs]\n",
        "                if all(status_list):\n",
        "                    if not surpassed_threshold:\n",
        "                        surpassed_threshold = True\n",
        "                        n_steps_first_th = i + 1\n",
        "                        num_steps_for_early_stop_check = 100 # Check more frequently after threshold\n",
        "                        print(\"Performance threshold surpassed. Checking more frequently.\")\n",
        "\n",
        "                    if average_perf > current_best_valid_accuracy_es:\n",
        "                        current_best_valid_accuracy_es = average_perf\n",
        "                        best_valid_performance_es = list_avg_perfs\n",
        "                        torch.save(model.state_dict(), model_save_name)\n",
        "                        current_patience = patience # Reset patience\n",
        "                        print(f\"New best model saved with avg perf: {average_perf:.3f}\")\n",
        "                    else:\n",
        "                      if current_patience <= 0:\n",
        "                        n_steps_final = i + 1\n",
        "                        print('Early Stopping. I have run out of patience Grrr')\n",
        "                        break\n",
        "                      else:\n",
        "                        current_patience -= 1\n",
        "                        print(f\"No improvement. Patience left: {current_patience}\")\n",
        "\n",
        "                elif surpassed_threshold:\n",
        "\n",
        "                  if current_patience <= 0:\n",
        "                    n_steps_final = i + 1\n",
        "                    print('Early Stopping. I have run out of patience Grrr')\n",
        "                    break\n",
        "                  else:\n",
        "                    current_patience -= 1\n",
        "\n",
        "            model.train()\n",
        "\n",
        "    # final tracking dict\n",
        "    learning_curve_dict = {\n",
        "        'training_loss_epochs_list': tr_epochs_loss,\n",
        "        'training_total_loss_values_list': tr_total_loss_values,\n",
        "        'training_task_loss_values_list': tr_task_loss_values,\n",
        "        'training_wiring_loss_values_list': tr_wiring_loss_values,\n",
        "        'training_activity_loss_values_list': tr_activity_loss_values,\n",
        "        'validation_perf_epochs_list': tr_epochs_valid_perf,\n",
        "        'validation_perf_dicts_list': tr_valid_perfs_list_of_dicts,\n",
        "        'validation_perf_avg_values_list': tr_valid_perfs_avg,\n",
        "        'n_steps_first_th': n_steps_first_th,\n",
        "        'n_steps_final': n_steps_final\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_save_name))\n",
        "        print('Best model loaded.')\n",
        "        for valid_set_name, perf in zip(validation_set_dict.keys(), best_valid_performance_es):\n",
        "            print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print('No best model was saved that satisfied the validation threshold.')\n",
        "\n",
        "    if tr_output_mode:\n",
        "        return model, learning_curve_dict\n",
        "    return model"
      ],
      "metadata": {
        "id": "XjEXaxFRoHpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Curve Visualisation"
      ],
      "metadata": {
        "id": "cskcUXhNnJUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(\n",
        "    learning_curve_dict,\n",
        "    average_only=False,\n",
        "    plot_loss_components=True,\n",
        "    filename=None,\n",
        "    show_legend=True,\n",
        "    legend_location='upper center'\n",
        "):\n",
        "    \"\"\"\n",
        "    Takes the learning_curve_dict from the training function and plots\n",
        "    the training loss and validation performance on a single graph.\n",
        "    Has options to show individual validation sets or just the average.\n",
        "    \"\"\"\n",
        "    # unpack all the data from the dictionary\n",
        "    tr_epochs_loss = learning_curve_dict['training_loss_epochs_list']\n",
        "    tr_total_loss = learning_curve_dict['training_total_loss_values_list']\n",
        "    tr_task_loss = learning_curve_dict.get('training_task_loss_values_list', [])\n",
        "    tr_wiring_loss = learning_curve_dict.get('training_wiring_loss_values_list', [])\n",
        "    tr_activity_loss = learning_curve_dict.get('training_activity_loss_values_list', [])\n",
        "\n",
        "    val_epochs = learning_curve_dict['validation_perf_epochs_list']\n",
        "    val_dicts = learning_curve_dict['validation_perf_dicts_list']\n",
        "    val_avg = learning_curve_dict['validation_perf_avg_values_list']\n",
        "\n",
        "    n_steps_final = learning_curve_dict.get('n_steps_final', None)\n",
        "    th_location = np.where(np.array(val_avg) > 0.8)[0][0] if np.any(np.array(val_avg) > 0.8) else None\n",
        "    n_steps_first_th = val_epochs[th_location] if th_location is not None else None\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # plot training loss on the left y-axis\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss', color='tab:blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "    ax1.plot(tr_epochs_loss, tr_total_loss, color='tab:blue', label='Total Training Loss')\n",
        "\n",
        "    # if we have them, plot the wiring and activity loss components too\n",
        "    if plot_loss_components:\n",
        "        if np.any(tr_wiring_loss):\n",
        "            ax1.plot(tr_epochs_loss, tr_wiring_loss, color='tab:green', linestyle=':', label='Wiring Loss')\n",
        "        if np.any(tr_activity_loss):\n",
        "            ax1.plot(tr_epochs_loss, tr_activity_loss, color='tab:cyan', linestyle=':', label='Activity Loss')\n",
        "\n",
        "    # make a second y-axis for the validation performance\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel('Validation Performance', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "    ax2.set_ylim(0, 1.05) # Set y-axis for performance from 0 to 1\n",
        "\n",
        "    # plot the validation performance on the right y-axis\n",
        "    if average_only:\n",
        "        ax2.plot(val_epochs, val_avg, color='tab:red', linestyle='--', label='Average Validation Performance')\n",
        "    else:\n",
        "        if val_dicts:\n",
        "            validation_set_names = list(val_dicts[0].keys())\n",
        "            # get some nice contrasting colours for the lines\n",
        "            colours = plt.cm.get_cmap('Set1')(np.linspace(0, 1, len(validation_set_names)))\n",
        "\n",
        "            for i, name in enumerate(validation_set_names):\n",
        "                values = [d[name] for d in val_dicts]\n",
        "                ax2.plot(val_epochs, values, color=colours[i], linestyle='-', label=f'{name} Performance')\n",
        "\n",
        "    # add vertical lines for early stopping events\n",
        "    if n_steps_first_th is not None:\n",
        "        ax2.axvline(x=n_steps_first_th, color='gray', linestyle='--', label='Perf. Threshold Met')\n",
        "    if n_steps_final is not None and n_steps_final > 0:\n",
        "         ax2.axvline(x=n_steps_final, color='black', linestyle='--', label='Early Stopping')\n",
        "\n",
        "    # put all the labels into one legend\n",
        "    if show_legend:\n",
        "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax2.legend(lines1 + lines2, labels1 + labels2, loc=legend_location)\n",
        "\n",
        "    plt.title('Learning Curve: Training Loss and Validation Performance vs. Epoch')\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {filename}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qbkL_0wTiJwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Regime"
      ],
      "metadata": {
        "id": "SMokBRwksnDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing - Functions"
      ],
      "metadata": {
        "id": "Pw6FJ4fijOB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Functions - Run Test Trials and Record Data Function"
      ],
      "metadata": {
        "id": "rUapAvGvjYxZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36_3TSuYy2n-"
      },
      "outputs": [],
      "source": [
        "def bic_testing_w_state_tracking(network, dataset_to_evaluate, num_trials=200):\n",
        "    \"\"\"\n",
        "    Evaluates the given network on a NeuroGym dataset and records trial data.\n",
        "    Needs to have .forward_for_fpf_ics(self, x) method implemented.\n",
        "\n",
        "    Args:\n",
        "        network (nn.Module): The neural network to evaluate.\n",
        "        dataset_to_evaluate (ngym.Dataset): The NeuroGym dataset to use for evaluation.\n",
        "        num_trials (int): The number of trials to run for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing environmental information and detailed trial data\n",
        "              including network activity, stimulus values, and correctness.\n",
        "    \"\"\"\n",
        "    # Reset environment\n",
        "    environment = dataset_to_evaluate.env\n",
        "    environment.reset()\n",
        "\n",
        "    # Initialise variables for logging\n",
        "    # Stores correctness for calculating average performance\n",
        "    trial_correctness_records = {}\n",
        "    # Stores detailed information and network activity for each trial\n",
        "    trial_data_and_activity = {}\n",
        "\n",
        "    # Store the information of the trial environment\n",
        "    # For reporting or future devs with sequence isolation\n",
        "    # NOTE: for trial envs with varying task period timings this will need to be called IN THE LOOP AND STORED ALONGSIDE EACH TRIAL\n",
        "    # NOTE : Having trial envs with varying task period timings also f up the results data processing func so dont forget\n",
        "\n",
        "    environment_info = {\n",
        "            'dt' : environment.dt,\n",
        "            'trial_start_ind': environment.start_ind,\n",
        "            'trial_end_ind': environment.end_ind,\n",
        "            'timing': environment.timing,\n",
        "            'sigma': environment.sigma,\n",
        "            'choices': environment.choices,\n",
        "            'cohs': environment.cohs\n",
        "            }\n",
        "\n",
        "\n",
        "    for trial_index in range(num_trials):\n",
        "        # Initialise dictionary for the current trial's data\n",
        "        trial_data_and_activity[trial_index] = {}\n",
        "\n",
        "        # Sample a new trial\n",
        "        trial_information = environment.new_trial()\n",
        "\n",
        "        # Observation and groud-truth of this trial\n",
        "        observation, ground_truth = environment.ob, environment.gt\n",
        "\n",
        "        # Convert to numpy, add batch dimension to input (for consistency)\n",
        "        inputs_tensor = torch.from_numpy(observation[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "        # Run the network for one trial\n",
        "        # inputs_tensor (SeqLen, Batch, InputSize)\n",
        "        # predicted_actions (SeqLen, Batch, OutputSize) (output layer activity across all timesteps)\n",
        "        # hidden_activity (seq_len, batch, hidden layer size)\n",
        "        # prediction_action, hidden_activity = network(inputs_tensor)\n",
        "        prediction_action, hidden_activity, hidden_state_tensor = network.forward_for_fpf_ics(inputs_tensor)\n",
        "\n",
        "        # Compute performance\n",
        "        # First convert back to numpy\n",
        "        prediction_action_np = prediction_action.detach().numpy()[:, 0, :]\n",
        "        # Read out final choice at last time step\n",
        "        network_choice = np.argmax(prediction_action_np[-1, :])\n",
        "        # Compare to ground truth\n",
        "        # print(f'Network Choice: {network_choice}')\n",
        "        # print(f' Reported Ground Truth: {ground_truth[-1]}')\n",
        "\n",
        "        is_correct = network_choice == ground_truth[-1]\n",
        "\n",
        "        # Record activity, trial information, choice, correctness\n",
        "        hidden_activity_np = hidden_activity[:, 0, :].detach().numpy() # becomes (seq_len, hidden_size)\n",
        "        hidden_state_np = hidden_state_tensor[:, 0, :].detach().numpy()\n",
        "        # Update all logging of trial information and network activity\n",
        "        trial_correctness_records[trial_index] = {}\n",
        "        trial_correctness_records[trial_index].update({'correct': is_correct}) # Redundant but kept for original output structure\n",
        "\n",
        "        trial_data_and_activity[trial_index]['network_activity'] = hidden_activity_np ### NOTE THIS HAS BEEN CHANGED TO SEE HOW ANALYSIS CHANGES ### IF THESE ARE SWAPPED BACK (i.e. activity = output activity), the hidden_key input for bic fpf needs to be changed to = 'network_hidden_state'\n",
        "        trial_data_and_activity[trial_index]['network_hidden_state'] = hidden_state_np\n",
        "        # trial_data_and_activity[trial_index]['network_activity'] =  hidden_state_np ### NOTE THIS HAS BEEN CHANGED TO SEE HOW ANALYSIS CHANGES ### IF THESE ARE SWAPPED BACK (i.e. activity = output activity), the hidden_key input for bic fpf needs to be changed to = 'network_hidden_state'\n",
        "        # trial_data_and_activity[trial_index]['network_hidden_state'] = hidden_activity_np\n",
        "        # trial_data_and_activity[trial_index]['sample_stim_value'] = trial_information['sample_theta']\n",
        "        # trial_data_and_activity[trial_index]['test_stim_value'] = trial_information['test_theta']\n",
        "        # trial_data_and_activity[trial_index]['test_equals_sample'] = True if int(trial_information['ground_truth']) == 1 else False\n",
        "        trial_data_and_activity[trial_index]['network_correct'] = is_correct\n",
        "\n",
        "        trial_data_and_activity[trial_index]['ground_truth'] = int(trial_information['ground_truth']) + 1\n",
        "        trial_data_and_activity[trial_index]['coh'] = float(trial_information['coh'])\n",
        "\n",
        "    # Print Average trial performance during testing\n",
        "    average_trial_performance = np.mean([val['correct'] for val in trial_correctness_records.values()])\n",
        "    print('Average performance', average_trial_performance)\n",
        "\n",
        "    # PACKING THE DICTS - cut down so now returning essentials\n",
        "    full_testing_data = {\n",
        "        'testing_env_info' : environment_info,\n",
        "        'testing_trial_and_activity': trial_data_and_activity,\n",
        "        'testing_trial_performance': average_trial_performance\n",
        "    }\n",
        "\n",
        "    return full_testing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----- ANALYSIS FUNCTIONS ------\n",
        "\n"
      ],
      "metadata": {
        "id": "cTpwWWrMp-pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VISUALISATION FUNCTIONS"
      ],
      "metadata": {
        "id": "yWHgCl0mqs4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Trial Unit Activty Plotting Function"
      ],
      "metadata": {
        "id": "kkV1iPjXix8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe this should take the whole trial dict, not just the activity? would be good for the title\n",
        "def plot_unit_activity_over_time(trial_activity, env_info, unit_indices_to_plot=None, legend = False, filename=None):\n",
        "    \"\"\"\n",
        "    plots the activty of all the units in a trial over time.\n",
        "    can also just plot a specefic subset of them if you want.\n",
        "    \"\"\"\n",
        "    seq_len, hidden_size = trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # make the time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    # get the fig and ax so we can save it later\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # figure out which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = unit_indices_to_plot\n",
        "        # just make sure the indicies are actually in the array\n",
        "        units_to_plot = [i for i in units_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "\n",
        "    for i in units_to_plot:\n",
        "        ax.plot(time_points, trial_activity[:, i], label=f'Unit {i+1}')\n",
        "\n",
        "    # draw the lines for the different task bits\n",
        "    current_time = 0\n",
        "    # bit fiddly, just makes sure we dont get duplicate labels in the legend\n",
        "    existing_legend_labels = [l.get_text() for l in ax.get_legend().get_texts()] if legend and ax.get_legend() else []\n",
        "\n",
        "    for phase, duration in timing.items():\n",
        "        # only works for fixed timings for now\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            # don't draw a line if it's off the edge of the plot\n",
        "            if current_time < time_points[-1]:\n",
        "                # add the line, but only give it a label if we want a legend\n",
        "                # and if that label isn't already there\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', label=phase if legend and phase not in existing_legend_labels else \"\")\n",
        "\n",
        "\n",
        "    ax.set_title('Network Unit Activity Over Time')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Activity')\n",
        "    if legend:\n",
        "      # put a legend on if we asked for one. can get a bit crowded\n",
        "      ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # save the plot if we got a filename, otherwise just show it\n",
        "    if filename:\n",
        "        try:\n",
        "            # make sure the directory exists\n",
        "            if os.path.dirname(filename):\n",
        "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            # save it out\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            # close the plot so it doesn't just pop up anyway / saves colab ram\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            # if saving went wrong for some reason, just show the plot instead\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "uc9XEhCYgvuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average Unit Activity Function"
      ],
      "metadata": {
        "id": "PMq5wtfLiugg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmLT1G2Ti1Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_average_unit_activity_over_time(trial_data_dict, env_info, unit_indices_to_plot=None, legend=False, filename=None):\n",
        "    \"\"\"\n",
        "    Averages the unit activty across a number of trials and then plots it.\n",
        "    You can also provide a list of speific units to plot.\n",
        "    \"\"\"\n",
        "    if not trial_data_dict:\n",
        "        print(\"No trial data provided for plotting.\")\n",
        "        return\n",
        "\n",
        "    # First, get the shape info from one of the trials\n",
        "    first_trial_key = list(trial_data_dict.keys())[0]\n",
        "    first_trial_activity = trial_data_dict[first_trial_key]['network_activity']\n",
        "    seq_len, hidden_size = first_trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Go through all the trials and stack their activities together\n",
        "    all_activities = []\n",
        "    for trial_data in trial_data_dict.values():\n",
        "        # just a check to make sure the shapes match up\n",
        "        if trial_data['network_activity'].shape == (seq_len, hidden_size):\n",
        "            all_activities.append(trial_data['network_activity'])\n",
        "        else:\n",
        "            # never happens but just incase\n",
        "            print(f\"Warning: Skipping trial with inconsistent shape: {trial_data['network_activity'].shape}\")\n",
        "\n",
        "    if not all_activities:\n",
        "        print(\"No valid trial data found for averaging.\")\n",
        "        return\n",
        "\n",
        "    all_activities_stacked = np.stack(all_activities, axis=0)\n",
        "\n",
        "    # Now we can average across all the trials\n",
        "    average_activity = np.mean(all_activities_stacked, axis=0)\n",
        "\n",
        "    # create the time axis for the plot\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    # get the fig and ax so we can save the plot\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "\n",
        "    # Decide which units we're actually plotting\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = unit_indices_to_plot\n",
        "        # Make sure the requested indicies are valid\n",
        "        units_to_plot = [i for i in units_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "\n",
        "    for i in units_to_plot:\n",
        "        ax.plot(time_points, average_activity[:, i], label=f'Avg Unit {i+1}')\n",
        "\n",
        "    # Add the vertical lines for task phases\n",
        "    current_time = 0\n",
        "    # a check to prevent duplicate labels appearing in the legend\n",
        "    existing_legend_labels = [l.get_text() for l in ax.get_legend().get_texts()] if legend and ax.get_legend() else []\n",
        "\n",
        "    for phase, duration in timing.items():\n",
        "        # This only works for the fixed timings\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            # don't draw lines that would be off the chart\n",
        "            if current_time < time_points[-1]:\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', label=phase if legend and phase not in existing_legend_labels else \"\")\n",
        "        else:\n",
        "            # For handling variable timings in future if needed\n",
        "            print(f\"Skipping phase '{phase}' with variable timing for plotting vertical lines.\")\n",
        "\n",
        "\n",
        "    ax.set_title('Average Network Unit Activity Over Time Across Trials')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Average Activity')\n",
        "    # The legend is optional as it can sometimes mess up the plot\n",
        "    if legend:\n",
        "      ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Save the figure or show it\n",
        "    if filename:\n",
        "        try:\n",
        "            # make sure the directory exists first\n",
        "            if os.path.dirname(filename):\n",
        "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            # close the plot so it doesn't show up after saving\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            # if saving fails, show the plot instead\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "sphc54ZBhWp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heat Map for Network Structure - BIC Change"
      ],
      "metadata": {
        "id": "oiQQWkED75Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhKmn1mpi-rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_recurrent_weights_heatmap_BIC(net, filename = None, mask=None, weights_passed=False):\n",
        "    \"\"\"\n",
        "    Makes a heatmap of the recurrent weights from the RNN's h2h layer.\n",
        "    It expects the network to have a net.rnn.h2h.weight structure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if mask is not None:\n",
        "            effective_weights = net.rnn.h2h.weight * mask\n",
        "            weights = effective_weights.detach().cpu().numpy()\n",
        "        elif weights_passed:\n",
        "            weights = net\n",
        "        else:\n",
        "            # get the recurrent weights from the linear layer\n",
        "            weights = net.rnn.h2h.weight.detach().cpu().numpy()\n",
        "    except AttributeError:\n",
        "        print(\"Error: Could not find 'net.rnn.h2h.weight'.\")\n",
        "        return\n",
        "\n",
        "    num_units = weights.shape[0]\n",
        "\n",
        "    # set up a symmetric colour range for the plot\n",
        "    max_abs_val = np.max(np.abs(weights))\n",
        "    norm = mcolors.Normalize(vmin=-max_abs_val, vmax=max_abs_val)\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "    # use imshow to create the heatmap itself\n",
        "    im = ax.imshow(weights, cmap='bwr_r', norm=norm, interpolation='none')\n",
        "\n",
        "    # configure the colour bar\n",
        "    cbar = fig.colorbar(im, ax=ax, shrink=0.8)\n",
        "    cbar.set_label('Connection Weight', rotation=270, labelpad=20, fontsize=12)\n",
        "\n",
        "    # configure the axes and labels\n",
        "    ax.set_title('Recurrent Connection Weights Heatmap', fontsize=16, pad=20)\n",
        "    ax.set_ylabel('To Unit Index', fontsize=12)\n",
        "    ax.set_xlabel('From Unit Index', fontsize=12)\n",
        "\n",
        "    # configure the main ticks to be centered and rotated\n",
        "    tick_labels = np.arange(num_units)\n",
        "    ax.set_xticks(tick_labels)\n",
        "    ax.set_yticks(tick_labels)\n",
        "    ax.tick_params(axis='x', labelsize=10)\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "    plt.setp(\n",
        "        ax.get_xticklabels(),\n",
        "        rotation=90,\n",
        "        ha=\"center\",\n",
        "        rotation_mode=\"default\"\n",
        "    )\n",
        "\n",
        "    # add grid lines and borders inside the heatmap\n",
        "    # set minor ticks to sit between the major ones, which is where the grid lines go\n",
        "    ax.set_xticks(np.arange(-.5, num_units, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, num_units, 1), minor=True)\n",
        "\n",
        "    # add some faint gridlines to all the cells\n",
        "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.25, alpha=0.5)\n",
        "\n",
        "    # this is important - hide the minor tick marks on the axes themselves\n",
        "    ax.tick_params(which='minor', bottom=False, left=False)\n",
        "\n",
        "    # add a slightly more prominent border for the diagonal cells\n",
        "    for i in range(num_units):\n",
        "        rect = patches.Rectangle(\n",
        "            (i - 0.5, i - 0.5), 1, 1,\n",
        "            linewidth=0.75, edgecolor='black', facecolor='none', alpha=0.7\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    fig.tight_layout(pad=1.5)\n",
        "\n",
        "    # save or display the figure\n",
        "    if filename:\n",
        "      plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "      print(f\"Figure saved to {filename}\")\n",
        "      plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "5zhvZV7Rhk9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIMENSIONALITY REDUCTION"
      ],
      "metadata": {
        "id": "DTkePl_CscHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dPCA (I/O)"
      ],
      "metadata": {
        "id": "ieVSoT-0TvDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (O)"
      ],
      "metadata": {
        "id": "Af3fBq_dsjSr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "export_nested_dict_to_json"
      },
      "source": [
        "def export_nested_dict_to_json(data, filename):\n",
        "    \"\"\"\n",
        "    Exports a nested dictionary containing NumPy arrays to a JSON file.\n",
        "\n",
        "    Recursively converts NumPy arrays to lists before exporting and adds an\n",
        "    indicator to mark lists that were originally NumPy arrays.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The nested dictionary to export.\n",
        "        filename (str): The name of the JSON file to create.\n",
        "    \"\"\"\n",
        "    def convert_numpy_to_list(obj):\n",
        "        \"\"\"\n",
        "        Recursively converts NumPy arrays within an object to lists and adds a marker.\n",
        "        \"\"\"\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            # Convert to list and add a marker at the beginning\n",
        "            return ['NUMPY'] + obj.tolist()\n",
        "        elif isinstance(obj, dict):\n",
        "            return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [convert_numpy_to_list(item) for item in obj]\n",
        "        elif isinstance(obj, (np.float64, np.bool_, np.int64, np.int32)): # Added more scalar types\n",
        "             return obj.item() # Convert NumPy scalar types to Python types\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    export_ready_data = convert_numpy_to_list(data)\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(export_ready_data, f, indent=4)\n",
        "        print(f\"Data successfully exported to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting data to {filename}: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (I)"
      ],
      "metadata": {
        "id": "TPPM61ACUCdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accompanying Import Function (also located in dPCA notebook)"
      ],
      "metadata": {
        "id": "uRuYdxF-somd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "import_nested_dict_from_json"
      },
      "source": [
        "\n",
        "\n",
        "def import_nested_dict_from_json(filename):\n",
        "    \"\"\"\n",
        "    Imports data from a JSON file exported by export_nested_dict_to_json\n",
        "    and reconstructs NumPy arrays based on the indicator.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The name of the JSON file to import.\n",
        "\n",
        "    Returns:\n",
        "        dict or None: The reconstructed nested dictionary, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    def convert_list_to_numpy_array(obj):\n",
        "        \"\"\"\n",
        "        Recursively converts lists back to NumPy arrays if they have the marker.\n",
        "        \"\"\"\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: convert_list_to_numpy_array(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            # Check for the 'NUMPY' marker at the beginning of the list\n",
        "            if obj and isinstance(obj[0], str) and obj[0] == 'NUMPY':\n",
        "                # Remove the marker and convert the rest of the list to a NumPy array\n",
        "                try:\n",
        "                    # Recursively convert inner elements before converting to numpy array\n",
        "                    list_without_marker = [convert_list_to_numpy_array(item) for item in obj[1:]]\n",
        "                    return np.array(list_without_marker)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not convert list marked as 'NUMPY' to array. Returning list. Error: {e}\")\n",
        "                    return obj # Return original list if conversion fails\n",
        "            else:\n",
        "                # If no marker, just recursively process the list's elements\n",
        "                return [convert_list_to_numpy_array(item) for item in obj]\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            imported_data = json.load(f)\n",
        "\n",
        "        reconstructed_data = convert_list_to_numpy_array(imported_data)\n",
        "        print(f\"Data successfully imported from {filename}\")\n",
        "        return reconstructed_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filename}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from {filename}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error importing data from {filename}: {e}\")\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check I/O"
      ],
      "metadata": {
        "id": "-CwvtZqNUQ4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Check if the dict you are exporting will be imported as an exact match in the dPCA notebook"
      ],
      "metadata": {
        "id": "k5pJyi8Osu-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deepdiff\n",
        "\n",
        "def compare_dicts(dict1, dict2):\n",
        "    \"\"\"\n",
        "    Compares two dictionaries and reports the differences.\n",
        "    Handles NumPy arrays by comparing their content.\n",
        "\n",
        "    Args:\n",
        "        dict1 (dict): The first dictionary.\n",
        "        dict2 (dict): The second dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the differences.\n",
        "    \"\"\"\n",
        "\n",
        "    diff = deepdiff.DeepDiff(dict1, dict2, ignore_order=False, verbose_level=0)\n",
        "\n",
        "    if not diff:\n",
        "        print(\"Dictionaries are identical.\")\n",
        "    else:\n",
        "        print(\"Differences found:\")\n",
        "        print(diff)\n",
        "\n",
        "    return diff\n",
        "\n",
        "# Perform Comparison verification\n",
        "# diff = compare_dicts(LRNN_NB_trained_full_testing_data, imported_data_with_marker)"
      ],
      "metadata": {
        "id": "muWNZCH1UYlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "CVkk3zgVs8r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit PCA"
      ],
      "metadata": {
        "id": "zL0BDeMSfwS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_pca_on_selected_data(dict_of_trial_dicts, pca_components=2, report_var_expls = False):\n",
        "  '''\n",
        "  takes a dict structured like testing_trial_and_activity\n",
        "  Dual use,\n",
        "  1) Use with pca_components = None and report_var_expls = True:\n",
        "    - get the scree plot and the variance explanation (cumulative and individual)\n",
        "    - -> decide n components\n",
        "  2) Use with pca_components = n and report_var_expls = False:\n",
        "    - -> Get a fit PCA object for n components ready for use\n",
        "  '''\n",
        "  list_of_activity_arrays = []\n",
        "  for trial_num, trial_dict in dict_of_trial_dicts.items():\n",
        "    list_of_activity_arrays.append(trial_dict['network_activity'])\n",
        "\n",
        "  activity_for_fit = np.concatenate(list_of_activity_arrays, axis=0)\n",
        "  # print(f' Checking Dimensionality should be (<seqlen*n_trials>, hidden size ) ')\n",
        "  # print(f'{activity_for_fit.shape} ')\n",
        "  pca = PCA(n_components=pca_components)\n",
        "  pca.fit(activity_for_fit)\n",
        "\n",
        "  if report_var_expls:\n",
        "\n",
        "    print(\"--- Detailed PCA Variance Explanation ---\")\n",
        "\n",
        "    # Convert ratios to Percentages and print for each component\n",
        "    for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
        "        print(f\"Principal Component {i+1}: {ratio*100:.2f}% of total variance explained\")\n",
        "\n",
        "    # Calculate and Print cumulative explained variance as percentages\n",
        "    cumulative_variance_percent = np.cumsum(pca.explained_variance_ratio_) * 100\n",
        "    for i, cum_percent in enumerate(cumulative_variance_percent):\n",
        "        print(f\"Cumulative Variance Explained by first {i+1} components: {cum_percent:.2f}%\")\n",
        "\n",
        "    print(f\"Total variance explained by all {pca.n_components_} selected components: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
        "\n",
        "    # Scree plot\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
        "    plt.xlabel('Principal Component Number')\n",
        "    plt.ylabel('Proportion of Variance Explained')\n",
        "    plt.title('Scree Plot: Explained Variance Ratio per Component')\n",
        "    plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "    # plot the cumulative explained variance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(cumulative_variance_percent) + 1), cumulative_variance_percent, marker='o', linestyle='-')\n",
        "    plt.xlabel('Number of Principal Components')\n",
        "    plt.ylabel('Cumulative Explained Variance (%)')\n",
        "    plt.title('Cumulative Explained Variance vs. Number of Components')\n",
        "    plt.xticks(range(1, len(cumulative_variance_percent) + 1))\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.axhline(y=90, color='r', linestyle='--', label='90% Threshold')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  else:\n",
        "    return pca\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yxJW4Oe-aAih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot PC1 against time Function"
      ],
      "metadata": {
        "id": "8_hsHMkNvlEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for PDM\n",
        "\n",
        "def plot_pca_trajectories(pca_object, data_to_transform_dict, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None):\n",
        "    \"\"\"\n",
        "    Takes a fitted PCA object and some data and plots the average PC1 trajectries\n",
        "    over time. It colours the lines based on the modalities\n",
        "    using the project's style.\n",
        "\n",
        "    The plot_title argument is ignored to make sure the plots all look the same.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict:\n",
        "        print(\"No trial data provided for plotting PCA trajectories.\")\n",
        "        return\n",
        "\n",
        "    # --- Updated Style for PDM  ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        1: {'color': '#e69010', 'label': 'Stim 1 > Stim 2'},  # Orange\n",
        "        2: {'color': '#6b08bd', 'label': 'Stim 2 > Stim 1'},  # Purple\n",
        "    }\n",
        "    LINESTYLE = '-'\n",
        "\n",
        "    # --- Updated Data Preparation ---\n",
        "    # Group trials by the 'ground_truth' condition\n",
        "    grouped_trajectories = defaultdict(list)\n",
        "    limited_trials = dict(list(data_to_transform_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "    for trial_dict in limited_trials.values():\n",
        "        # MODIFIED: Use 'ground_truth' as the key for grouping conditions\n",
        "        stim_condition = trial_dict.get('ground_truth')\n",
        "\n",
        "        if stim_condition is not None and stim_condition in STYLE_GUIDE_COLORS:\n",
        "            activity = np.array(trial_dict['network_activity'])\n",
        "            pc1_trajectory = pca_object.transform(activity)[:, 0]\n",
        "            grouped_trajectories[stim_condition].append(pc1_trajectory)\n",
        "\n",
        "    # --- Plotting Setup ---\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    max_plotted_time = 0\n",
        "\n",
        "    # --- Plot Mean Trajectories ---\n",
        "    for condition, trajectories in grouped_trajectories.items():\n",
        "        if trajectories:\n",
        "            mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "            color = STYLE_GUIDE_COLORS[condition]['color']\n",
        "            label = STYLE_GUIDE_COLORS[condition]['label']\n",
        "\n",
        "            time_points = np.arange(len(mean_trajectory)) * testing_env_info['dt']\n",
        "            max_plotted_time = max(max_plotted_time, time_points[-1] if len(time_points) > 0 else 0)\n",
        "\n",
        "            ax.plot(time_points, mean_trajectory, color=color, linestyle=LINESTYLE, label=label, linewidth=2.5)\n",
        "\n",
        "    # --- Add Task Phase Annotations and Vertical Lines ---\n",
        "    # This is flexible and will use the new phase names from testing_env_info\n",
        "    task_env_dt = testing_env_info['dt']\n",
        "    ax.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "        end_time_ms = (end_index - 1) * task_env_dt\n",
        "        if end_time_ms <= max_plotted_time + task_env_dt:\n",
        "            ax.axvline(x=end_time_ms, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    annotation_y_pos = y_max - (y_max - y_min) * 0.05\n",
        "\n",
        "    for phase, start_index in testing_env_info['trial_start_ind'].items():\n",
        "        start_time_ms = start_index * task_env_dt\n",
        "        end_time_ms = (testing_env_info['trial_end_ind'][phase] - 1) * task_env_dt\n",
        "        center_time_ms = (start_time_ms + end_time_ms) / 2\n",
        "        if center_time_ms <= max_plotted_time:\n",
        "            ax.text(center_time_ms, annotation_y_pos, phase.capitalize(),\n",
        "                    ha='center', va='top', fontsize=12, color='black')\n",
        "\n",
        "    # --- Final Plot Customisation ---\n",
        "    ax.set_xlabel('Time (ms)', fontsize=14)\n",
        "    ax.set_ylabel('PC1 (from PCA fit)', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    y_range = y_max - y_min\n",
        "    if y_range > 0:\n",
        "      ax.set_ylim(y_min - y_range * 0.1, y_max + y_range * 0.1)\n",
        "\n",
        "    ax.legend(title=\"Trial Conditions\", loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=10)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- Save or Display ---\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "jKWhS5FIT-EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2 Datasets 1 PCA Plotting 1D (For Leisoning)"
      ],
      "metadata": {
        "id": "_QlfAF6-3VCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for pdm\n",
        "\n",
        "\n",
        "def plot_pca_trajectories_two_datasets(pca_object, data_to_transform_dict1, data_to_transform_dict2, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None, label1=\"Unleisoned\", label2=\"Leisoned\"):\n",
        "    \"\"\"\n",
        "    Plots and compares mean PC1 trajectories from two datasets - for leisoning.\n",
        "    Colour indicates the task condition, and line style indicates the dataset.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict1 and not data_to_transform_dict2:\n",
        "        print(\"No trial data provided from either dataset for plotting.\")\n",
        "        return\n",
        "\n",
        "    # --- Updated Style Definitions for PDM ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        1: {'color': '#e69010', 'label': 'Stim 1 > Stim 2'},  # Orange\n",
        "        2: {'color': '#6b08bd', 'label': 'Stim 2 > Stim 1'},  # Purple\n",
        "    }\n",
        "    DATASET_STYLES = [\n",
        "        {'linestyle': '-', 'label': label1}, # Solid lines for dataset 1\n",
        "        {'linestyle': '--', 'label': label2}  # Dashed lines for dataset 2\n",
        "    ]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    max_plotted_time = 0\n",
        "    all_plotted_conditions = set()\n",
        "\n",
        "    datasets = [(data_to_transform_dict1, DATASET_STYLES[0]), (data_to_transform_dict2, DATASET_STYLES[1])]\n",
        "\n",
        "    for data_dict, style in datasets:\n",
        "        if not data_dict:\n",
        "            continue\n",
        "\n",
        "        grouped_trajectories = defaultdict(list)\n",
        "        limited_trials = dict(list(data_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "        for trial_dict in limited_trials.values():\n",
        "            # MODIFIED: Use 'ground_truth' as the key for grouping conditions\n",
        "            stim_condition = trial_dict.get('ground_truth')\n",
        "            if stim_condition is not None and stim_condition in STYLE_GUIDE_COLORS:\n",
        "                activity = np.array(trial_dict['network_activity'])\n",
        "                pc1_trajectory = pca_object.transform(activity)[:, 0]\n",
        "                grouped_trajectories[stim_condition].append(pc1_trajectory)\n",
        "                all_plotted_conditions.add(stim_condition)\n",
        "\n",
        "        for condition, trajectories in grouped_trajectories.items():\n",
        "            if trajectories:\n",
        "                mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "                color = STYLE_GUIDE_COLORS[condition]['color']\n",
        "                time_points = np.arange(len(mean_trajectory)) * testing_env_info['dt']\n",
        "                max_plotted_time = max(max_plotted_time, time_points[-1] if len(time_points) > 0 else 0)\n",
        "\n",
        "                ax.plot(time_points, mean_trajectory, color=color, linestyle=style['linestyle'], linewidth=2.5)\n",
        "\n",
        "    # --- Add Task Phase Annotations ---\n",
        "    task_env_dt = testing_env_info['dt']\n",
        "    ax.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
        "    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "        end_time_ms = (end_index - 1) * task_env_dt\n",
        "        if end_time_ms <= max_plotted_time + task_env_dt:\n",
        "            ax.axvline(x=end_time_ms, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    annotation_y_pos = y_max - (y_max - y_min) * 0.05\n",
        "    for phase, start_index in testing_env_info['trial_start_ind'].items():\n",
        "        start_time_ms = start_index * task_env_dt\n",
        "        end_time_ms = (testing_env_info['trial_end_ind'][phase] - 1) * task_env_dt\n",
        "        center_time_ms = (start_time_ms + end_time_ms) / 2\n",
        "        if center_time_ms <= max_plotted_time:\n",
        "            ax.text(center_time_ms, annotation_y_pos, phase.capitalize(), ha='center', va='top', fontsize=12)\n",
        "\n",
        "    # --- Final Plot Customisation ---\n",
        "    ax.set_xlabel('Time (ms)', fontsize=14)\n",
        "    ax.set_ylabel('PC1 (from PCA fit)', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    if y_max > y_min:\n",
        "        ax.set_ylim(y_min - (y_max - y_min) * 0.1, y_max + (y_max - y_min) * 0.1)\n",
        "\n",
        "    # --- Manual Hierarchical Legend ---\n",
        "    legend_handles = []\n",
        "    # Part 1: Dataset line styles\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[0]['linestyle'], label=DATASET_STYLES[0]['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[1]['linestyle'], label=DATASET_STYLES[1]['label']))\n",
        "\n",
        "    # Add a spacer\n",
        "    if all_plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # Part 2: Condition colors\n",
        "    sorted_conditions = sorted(list(all_plotted_conditions))\n",
        "    for condition in sorted_conditions:\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- Save or Display ---\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ezVb-KmOUcL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot PC1(hla) vs PC2(hla)  "
      ],
      "metadata": {
        "id": "tQqMSmwpyMRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# modified for pdm\n",
        "def plot_pca_trajectories_2d(pca_object, data_to_transform_dict, testing_env_info,\n",
        "                             num_trials_to_plot=100, plot_title=None, save_filename=None,\n",
        "                             add_phase_markers=True):\n",
        "    \"\"\"\n",
        "    Plots the mean PC1 vs PC2 trajectories of network activity. Modified for PDM.\n",
        "    Includes options for colour mapping, indicating start/end points, and\n",
        "    marking task phase transitions.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict:\n",
        "        print(\"No trial data provided for plotting PCA trajectories.\")\n",
        "        return\n",
        "\n",
        "    if pca_object.n_components < 2:\n",
        "        print(f\"Error: PCA object must be fit with n_components>=2, but has {pca_object.n_components}\")\n",
        "        return\n",
        "\n",
        "    # --- Updated Style Definitions for PDM ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        1: {'color': '#e69010', 'label': 'Stim 1 > Stim 2'},  # Orange\n",
        "        2: {'color': '#6b08bd', 'label': 'Stim 2 > Stim 1'},  # Purple\n",
        "    }\n",
        "    LINESTYLE = '-' # Single dataset -> solid lines\n",
        "\n",
        "    # --- Updated Data Preparation ---\n",
        "    grouped_trajectories = defaultdict(list)\n",
        "    limited_trials = dict(list(data_to_transform_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "    for trial_dict in limited_trials.values():\n",
        "        # MODIFIED: Use 'ground_truth' as the key for grouping conditions\n",
        "        stim_condition = trial_dict.get('ground_truth')\n",
        "\n",
        "        if stim_condition is not None and stim_condition in STYLE_GUIDE_COLORS:\n",
        "            activity = np.array(trial_dict['network_activity'])\n",
        "            pc_trajectory = pca_object.transform(activity)[:, :2]\n",
        "            grouped_trajectories[stim_condition].append(pc_trajectory)\n",
        "\n",
        "    # --- Plotting Setup ---\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    # --- Plot Mean Trajectories and Markers ---\n",
        "    plotted_conditions = []\n",
        "    for condition, trajectories in grouped_trajectories.items():\n",
        "        if trajectories:\n",
        "            plotted_conditions.append(condition)\n",
        "            mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "            color = STYLE_GUIDE_COLORS[condition]['color']\n",
        "\n",
        "            ax.plot(mean_trajectory[:, 0], mean_trajectory[:, 1], color=color, linestyle=LINESTYLE, linewidth=2.5)\n",
        "            ax.plot(mean_trajectory[0, 0], mean_trajectory[0, 1], marker='s', color='k', markersize=8, linestyle='None')\n",
        "            ax.plot(mean_trajectory[-1, 0], mean_trajectory[-1, 1], marker='X', color='k', markersize=10, mew=2, linestyle='None')\n",
        "\n",
        "            if add_phase_markers:\n",
        "                for end_index in testing_env_info['trial_end_ind'].values():\n",
        "                    marker_idx = end_index - 1\n",
        "                    if marker_idx < len(mean_trajectory):\n",
        "                        ax.plot(mean_trajectory[marker_idx, 0], mean_trajectory[marker_idx, 1],\n",
        "                                marker='*', color='gold', markersize=12, linestyle='None')\n",
        "\n",
        "    # --- Manual Legend Construction ---\n",
        "    legend_handles = []\n",
        "    # Add trajectory color handles\n",
        "    for condition in plotted_conditions:\n",
        "         style = STYLE_GUIDE_COLORS[condition]\n",
        "         legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "\n",
        "    # Add marker handles\n",
        "    legend_handles.append(Line2D([0], [0], marker='s', color='k', label='Start', linestyle='None', markersize=8))\n",
        "    legend_handles.append(Line2D([0], [0], marker='X', color='k', label='End', linestyle='None', markersize=10, mew=2))\n",
        "    if add_phase_markers and plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], marker='*', color='gold', label='Phase Transition', linestyle='None', markersize=12))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # --- Final Plot Customisation ---\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- Save or Display ---\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "pvc4AavHU4CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot 2 Datasets 1 PCA(2D)"
      ],
      "metadata": {
        "id": "aaxk0FML3Mjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modified for pdm\n",
        "def plot_pca_trajectories_two_datasets_2d(pca_object, data_to_transform_dict1, data_to_transform_dict2, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None, add_phase_markers=True, label1=\"Unlesioned\", label2=\"Lesioned\"):\n",
        "    \"\"\"\n",
        "    Plots and compares mean PC1 vs PC2 trajectories from two datasets - for leisoning comparison.\n",
        "    Color indicates task condition, line style indicates dataset, and markers show key events.\n",
        "\n",
        "    Args:\n",
        "        pca_object (sklearn.decomposition.PCA): A fitted PCA object (with n_components>=2).\n",
        "        data_to_transform_dict1 (dict): First dictionary of trial data.\n",
        "        data_to_transform_dict2 (dict): Second dictionary of trial data.\n",
        "        testing_env_info (dict): Environmental information for phase markers.\n",
        "        num_trials_to_plot (int, optional): Max trials from each dataset to average. Defaults to 100.\n",
        "        plot_title (str, optional): This argument is ignored for stile guide. (not changing signature to update plot styles)\n",
        "        save_filename (str, optional): The file path to save the figure. Defaults to None.\n",
        "        add_phase_markers (bool, optional): If True, add markers for phase transitions. Defaults to True.\n",
        "        label1 (str, optional): Label for the first dataset (solid lines). Defaults to \"Unlesioned\".\n",
        "        label2 (str, optional): Label for the second dataset (dashed lines). Defaults to \"Lesioned\".\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict1 and not data_to_transform_dict2:\n",
        "        print(\"No trial data provided from either dataset for plotting.\")\n",
        "        return\n",
        "\n",
        "    if pca_object.n_components < 2:\n",
        "        print(f\"Error: PCA object must be fit with n_components>=2, but has {pca_object.n_components}\")\n",
        "        return\n",
        "\n",
        "    # --- Updated Style Guide Definitions for the New Task ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        1: {'color': '#e69010', 'label': 'Stim 1 > Stim 2'},  # Orange\n",
        "        2: {'color': '#6b08bd', 'label': 'Stim 2 > Stim 1'},  # Purple\n",
        "    }\n",
        "    DATASET_STYLES = [\n",
        "        {'linestyle': '-', 'label': label1}, # Solid lines\n",
        "        {'linestyle': '--', 'label': label2}  # Dashed lines\n",
        "    ]\n",
        "\n",
        "    # --- Plotting Setup ---\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    datasets = [(data_to_transform_dict1, DATASET_STYLES[0]), (data_to_transform_dict2, DATASET_STYLES[1])]\n",
        "    all_plotted_conditions = set()\n",
        "\n",
        "    # --- Plot Mean Trajectories and Markers ---\n",
        "    for data_dict, style in datasets:\n",
        "        if not data_dict:\n",
        "            continue\n",
        "\n",
        "        grouped_trajectories = defaultdict(list)\n",
        "        limited_trials = dict(list(data_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "        for trial_dict in limited_trials.values():\n",
        "            # MODIFIED: Use 'ground_truth' as the key for grouping conditions\n",
        "            stim_condition = trial_dict.get('ground_truth')\n",
        "            if stim_condition is not None and stim_condition in STYLE_GUIDE_COLORS:\n",
        "                activity = np.array(trial_dict['network_activity'])\n",
        "                pc_trajectory = pca_object.transform(activity)[:, :2]\n",
        "                grouped_trajectories[stim_condition].append(pc_trajectory)\n",
        "                all_plotted_conditions.add(stim_condition)\n",
        "\n",
        "        for condition, trajectories in grouped_trajectories.items():\n",
        "            if trajectories:\n",
        "                mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "                color = STYLE_GUIDE_COLORS[condition]['color']\n",
        "\n",
        "                # Plot trajectory line\n",
        "                ax.plot(mean_trajectory[:, 0], mean_trajectory[:, 1], color=color, linestyle=style['linestyle'], linewidth=2.5)\n",
        "                # Plot Start/End markers\n",
        "                ax.plot(mean_trajectory[0, 0], mean_trajectory[0, 1], marker='s', color='k', markersize=8, linestyle='None')\n",
        "                ax.plot(mean_trajectory[-1, 0], mean_trajectory[-1, 1], marker='X', color='k', markersize=10, mew=2, linestyle='None')\n",
        "\n",
        "                if add_phase_markers:\n",
        "                    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "                        marker_idx = end_index - 1\n",
        "                        if marker_idx < len(mean_trajectory):\n",
        "                            ax.plot(mean_trajectory[marker_idx, 0], mean_trajectory[marker_idx, 1], marker='*', color='gold', markersize=12, linestyle='None')\n",
        "\n",
        "    # --- Manual Hierarchical Legend ---\n",
        "    legend_handles = []\n",
        "    # Part 1: Dataset line styles\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[0]['linestyle'], label=DATASET_STYLES[0]['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[1]['linestyle'], label=DATASET_STYLES[1]['label']))\n",
        "\n",
        "    if all_plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], color='w', label='')) # Spacer\n",
        "\n",
        "    # Part 2: Condition colors\n",
        "    sorted_conditions = sorted(list(all_plotted_conditions))\n",
        "    for condition in sorted_conditions:\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "\n",
        "    if all_plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], color='w', label='')) # Spacer\n",
        "\n",
        "    # Part 3: Event Markers\n",
        "    legend_handles.append(Line2D([0], [0], marker='s', color='k', label='Start', linestyle='None', markersize=8))\n",
        "    legend_handles.append(Line2D([0], [0], marker='X', color='k', label='End', linestyle='None', markersize=10, mew=2))\n",
        "    if add_phase_markers and all_plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], marker='*', color='gold', label='Phase Transition', linestyle='None', markersize=12))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # --- Final Plot Customisation (No changes needed) ---\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- Save or Display (No changes needed) ---\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename) and not os.path.exists(os.path.dirname(save_filename)):\n",
        "                os.makedirs(os.path.dirname(save_filename))\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hpkx9ydRVFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNIT SELECTIVITY"
      ],
      "metadata": {
        "id": "FyA6-ZSWykrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calc Selectivity (and Inds)"
      ],
      "metadata": {
        "id": "VwbYY9HSzv_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_selectivity_indexes(task_condition_1_data_dict, task_condition_2_data_dict):\n",
        "  \"\"\"\n",
        "  Calculates a selectivity index for each hidden unit between two task conditions.\n",
        "\n",
        "  \"\"\"\n",
        "  # Uses absolute selectivity.\n",
        "\n",
        "  mean_activity = []\n",
        "  std_activity = []\n",
        "\n",
        "  # Iterate through the two task condition data dictionaries\n",
        "  for task_condition in [task_condition_1_data_dict, task_condition_2_data_dict]:\n",
        "    # Concatenate network activity across all trials for the current condition\n",
        "    task_condition_activity = np.concatenate([value['network_activity'] for value in task_condition.values()], axis=0)\n",
        "\n",
        "    # Calculate the mean activity for each unit across all time steps and trials\n",
        "    mean_activity.append(np.mean(task_condition_activity, axis=0))\n",
        "\n",
        "    # Calculate the standard deviation of activity for each unit\n",
        "    std_activity.append(np.std(task_condition_activity, axis=0))\n",
        "\n",
        "  # Calculate the absolute difference between the mean activities of the two conditions\n",
        "  abs_selectivity_for_cond1xcond2 = abs((mean_activity[0] - mean_activity[1]))\n",
        "\n",
        "  # Normalise the absolute difference by the pooled standard deviation\n",
        "  # Adding a small to the denominator to prevent division by zero\n",
        "  abs_selectivity_for_cond1xcond2 /= np.sqrt((std_activity[0]**2 + std_activity[1]**2 + 1e-7)/2)\n",
        "\n",
        "  # Get the indices of the units sorted by their selectivity in ascending order\n",
        "  sorted_indexes = np.argsort(abs_selectivity_for_cond1xcond2)\n",
        "\n",
        "  # Return the selectivity values and the sorted unit indexes\n",
        "  return abs_selectivity_for_cond1xcond2, sorted_indexes"
      ],
      "metadata": {
        "id": "hLTXFIV518gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NETWORK LEISONING"
      ],
      "metadata": {
        "id": "pow7TcLBzyoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lesion_network(trained_network, units_to_lesion):\n",
        "  # May not work for all network configs (designed on LRNN NB 1 HL(LeakyRNN))\n",
        "    try:\n",
        "        # Create a deep copy of the network\n",
        "        lesioned_network = deepcopy(trained_network)\n",
        "        print(\"Created a deep copy of the network.\")\n",
        "\n",
        "        # Locate the h2h Linear layer\n",
        "        if hasattr(lesioned_network, 'rnn') and hasattr(lesioned_network.rnn, 'h2h'):\n",
        "            h2h_layer = lesioned_network.rnn.h2h # Direct ref?\n",
        "            print(f\"Found h2h layer: {h2h_layer}\")\n",
        "\n",
        "            # Get the weight tensor\n",
        "            h2h_weights = h2h_layer.weight.data.cpu().numpy()\n",
        "            print(f\"Original h2h weights shape: {h2h_weights.shape}\")\n",
        "\n",
        "            # Check if the provided unit indices are valid\n",
        "            hidden_size = h2h_weights.shape[0] # Assuming output dim == input dim for recurrent weights\n",
        "            valid_units_to_lesion = [u for u in units_to_lesion if 0 <= u < hidden_size]\n",
        "\n",
        "            if len(valid_units_to_lesion) != len(units_to_lesion):\n",
        "                print(\"Warning: Some provided unit indices were out of bounds.\")\n",
        "                print(f\"Valid hidden unit range is [0, {hidden_size - 1}].\")\n",
        "                print(f\"Lesioning units: {valid_units_to_lesion}\")\n",
        "            else:\n",
        "                print(f\"Lesioning recurrent connections for units: {valid_units_to_lesion}\")\n",
        "\n",
        "\n",
        "            # Set incoming and outgoing recurrent weights for the specified units to zero\n",
        "            # Recurrent weights shape: (output_features, input_features) or (to_units, from_units)\n",
        "            for unit_index in valid_units_to_lesion:\n",
        "                # Set weights to this unit from all other units in the h2h layer\n",
        "                h2h_weights[unit_index, :] = 0\n",
        "\n",
        "                # Set weights from this unit to all other units in the h2h layer\n",
        "                h2h_weights[:, unit_index] = 0\n",
        "            print(\"Recurrent weights for specified units set to zero.\")\n",
        "\n",
        "            # Update the weight tensor in the lesioned network\n",
        "            h2h_layer.weight.data = torch.from_numpy(h2h_weights).to(h2h_layer.weight.data.device) # Depends on if h2h_layer is direct ref or copy (wouldve seen probs in non BIC)\n",
        "\n",
        "\n",
        "            return lesioned_network\n",
        "\n",
        "        else:\n",
        "            print(\"Error: The network structure is not as expected (missing .rnn.h2h).\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during network lesioning: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "yIkEEN4v1-fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SELECTIVITY AND LEISONING FRAMEWORK"
      ],
      "metadata": {
        "id": "IbizyJKez4mE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leisoned Network for n% most selective Units and Analysis"
      ],
      "metadata": {
        "id": "LPLJGpQ30VxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leison_network_for_top_n_and_test(trained_network, list_of_task_cond_1_cond_2_data_dicts_for_selectivity, testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = None, fig_file_name = 'leisoned_unleisoned' , file_ext='.png', unleisoned_PCA_2d = None, return_results = False):\n",
        "  ## Note:\n",
        "  # calculate_selectivity_indexes is expecting the dicts in list_of_task... to be <trial_num>: 'network_activity',... i.e. testing_trial_and_activity structured so use data func with return like input = false\n",
        "\n",
        "  # Produce Leisoned Network\n",
        "\n",
        "  abs_selectivity_, sorted_indexes_ = calculate_selectivity_indexes(list_of_task_cond_1_cond_2_data_dicts_for_selectivity[0], list_of_task_cond_1_cond_2_data_dicts_for_selectivity[1])\n",
        "  units_to_leison_ = sorted_indexes_[-int(len(sorted_indexes_)*n_perc_leison/100):]\n",
        "\n",
        "\n",
        "  leisoned_network_ = lesion_network(trained_network, units_to_leison_)\n",
        "\n",
        "  # Test uneleisoned network\n",
        "  unleisoned_full_testing_data_ = evaluate_network_on_dataset(trained_network, testing_data_set, num_trials=2000)\n",
        "  # Test Leisoned Network\n",
        "  leisoned_full_testing_data_ = evaluate_network_on_dataset(leisoned_network_, testing_data_set, num_trials=2000)\n",
        "\n",
        "\n",
        "  testing_env_info_ = unleisoned_full_testing_data_['testing_env_info']\n",
        "\n",
        "  print(f\"Unleisoned Network Performance: {unleisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Leisoned Network Performance: {leisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Performance Difference: {((unleisoned_full_testing_data_['testing_trial_performance'] - leisoned_full_testing_data_['testing_trial_performance'])/(unleisoned_full_testing_data_['testing_trial_performance'])) * 100} %\")\n",
        "\n",
        "  # Print a PCA Transformed Plot of the test activities for both networks\n",
        "\n",
        "  #### ------WONT WORK FOR Attn\n",
        "  if unleisoned_PCA_1d:\n",
        "    one_d_pca_filename = fig_file_name + '_1d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets(unleisoned_PCA_1d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1 across t', save_filename=one_d_pca_filename, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "  #------WONT WORK FOR  Attn\n",
        "  if unleisoned_PCA_2d:\n",
        "    two_d_pca_filename = fig_file_name + '_2d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets_2d(unleisoned_PCA_2d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1xPC2', save_filename=two_d_pca_filename, add_phase_markers=True, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  all_results_ = {\n",
        "      'abs_selectivity': abs_selectivity_,\n",
        "      'sorted_indexes': sorted_indexes_,\n",
        "      'units_to_leison': units_to_leison_,\n",
        "      'unleisoned_full_testing_data': unleisoned_full_testing_data_,\n",
        "      'leisoned_full_testing_data': leisoned_full_testing_data_\n",
        "  }\n",
        "  if return_results:\n",
        "    return all_results_\n",
        "  else:\n",
        "    print('Done')\n",
        "\n"
      ],
      "metadata": {
        "id": "xBy3V4Cu0iAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SELECTIVITY AND LEISONING Changes for EI and BICS"
      ],
      "metadata": {
        "id": "D5lRPN5N9f0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selectivity - For BICS"
      ],
      "metadata": {
        "id": "PwmXll-v_Es0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_selectivity_indexes_BIC(task_condition_1_data_dict, task_condition_2_data_dict):\n",
        "  \"\"\"\n",
        "  Calculates a selectivity index for each hidden unit between two task conditions.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Uses absolute selectivity.\n",
        "\n",
        "  mean_activity = []\n",
        "  std_activity = []\n",
        "\n",
        "  # Iterate through the two task condition data dictionaries\n",
        "  for task_condition in [task_condition_1_data_dict, task_condition_2_data_dict]:\n",
        "    # Concatenate network activity across all trials for the current condition\n",
        "    task_condition_activity = np.concatenate([value['network_activity'] for value in task_condition.values()], axis=0)\n",
        "\n",
        "    # Calculate the mean activity for each unit across all time steps and trials\n",
        "    mean_activity.append(np.mean(task_condition_activity, axis=0))\n",
        "\n",
        "    # Calculate the standard deviation of activity for each unit\n",
        "    std_activity.append(np.std(task_condition_activity, axis=0))\n",
        "\n",
        "  # Calculate the absolute difference between the mean activities of the two conditions\n",
        "  selectivity_for_cond1xcond2 = (mean_activity[0] - mean_activity[1])\n",
        "\n",
        "  # Normalise the absolute difference by the pooled standard deviation\n",
        "  # Adding a small to the denominator to prevent division by zero\n",
        "  selectivity_for_cond1xcond2 /= np.sqrt((std_activity[0]**2 + std_activity[1]**2 + 1e-7)/2)\n",
        "\n",
        "  # Get the indices of the units sorted by their selectivity in ascending order\n",
        "  abs_sorted_indexes = np.argsort(abs(selectivity_for_cond1xcond2))\n",
        "  E_Prop = 0.8\n",
        "  e_size = int(E_Prop * len(abs_sorted_indexes))\n",
        "  ei_sorted_indexes = (np.argsort(selectivity_for_cond1xcond2[:e_size]), np.argsort(selectivity_for_cond1xcond2[e_size:]+e_size))\n",
        "  # Return the selectivity values and the sorted unit indexes\n",
        "\n",
        "  # now returns the raw selectivity (directional) and then the absolute indexes for leisoning and ei sorted indexes for further analysis if needed (DOES THIS REGARDLESS OF EI OR NOT)\n",
        "  return selectivity_for_cond1xcond2, abs_sorted_indexes, ei_sorted_indexes"
      ],
      "metadata": {
        "id": "C4IJ2MJu_GhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leisoning for BICs"
      ],
      "metadata": {
        "id": "321qQw7a_Jwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note - UNCHANGED for BICs\n",
        "def lesion_network_BIC(trained_network, units_to_lesion): # layer_to_leison=None,  Actually fine. Only need to change if multi layer (use f string for has attr 'rnn')\n",
        "  # May not work for all network configs (designed on LRNN NB 1 HL(LeakyRNN))\n",
        "    try:\n",
        "        # Create a deep copy of the network\n",
        "        lesioned_network = deepcopy(trained_network)\n",
        "        print(\"Created a deep copy of the network.\")\n",
        "\n",
        "        # Locate the h2h Linear layer\n",
        "        if hasattr(lesioned_network, 'rnn') and hasattr(lesioned_network.rnn, 'h2h'):\n",
        "            h2h_layer = lesioned_network.rnn.h2h # Direct ref problematic?\n",
        "            print(f\"Found h2h layer: {h2h_layer}\")\n",
        "\n",
        "            # Get the weight tensor\n",
        "            h2h_weights = h2h_layer.weight.data.cpu().numpy()\n",
        "            print(f\"Original h2h weights shape: {h2h_weights.shape}\")\n",
        "\n",
        "            # Check if the provided unit indices are valid\n",
        "            hidden_size = h2h_weights.shape[0] # Assuming output dim == input dim for recurrent weights (note)\n",
        "            valid_units_to_lesion = [u for u in units_to_lesion if 0 <= u < hidden_size]\n",
        "\n",
        "            if len(valid_units_to_lesion) != len(units_to_lesion): # some warnings for bug fixing\n",
        "                print(\"Warning: Some provided unit indices were out of bounds.\")\n",
        "                print(f\"Valid hidden unit range is [0, {hidden_size - 1}].\")\n",
        "                print(f\"Lesioning units: {valid_units_to_lesion}\")\n",
        "            else:\n",
        "                print(f\"Lesioning recurrent connections for units: {valid_units_to_lesion}\")\n",
        "\n",
        "\n",
        "            # Set incoming and outgoing recurrent weights for the specified units to zero\n",
        "            # Recurrent weights shape: (output_features, input_features) or (to_units, from_units)\n",
        "            for unit_index in valid_units_to_lesion:\n",
        "                # Set weights to this unit from all other units in the h2h layer\n",
        "                h2h_weights[unit_index, :] = 0\n",
        "\n",
        "                # Set weights from this unit to all other units in the h2h layer\n",
        "                h2h_weights[:, unit_index] = 0\n",
        "            print(\"Recurrent weights for specified units set to zero.\")\n",
        "\n",
        "            # Update the weight tensor in the lesioned network\n",
        "            h2h_layer.weight.data = torch.from_numpy(h2h_weights).to(h2h_layer.weight.data.device) # Depends on if h2h_layer is direct ref or copy (wouldve seen probs in non BIC)\n",
        "\n",
        "\n",
        "            return lesioned_network\n",
        "\n",
        "        else:\n",
        "            print(\"Error: The network structure is not as expected (missing .rnn.h2h).\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during network lesioning: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "zzO8rJfR_LKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Selectivity and Leisoning (Accomodate for BICs)"
      ],
      "metadata": {
        "id": "p79wAfEa_RHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leison_network_for_top_n_and_test_BIC(trained_network, list_of_task_cond_1_cond_2_data_dicts_for_selectivity, testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = None, fig_file_name = 'leisoned_unleisoned' , file_ext='.png', unleisoned_PCA_2d = None, return_results = True):\n",
        "  ## Note:\n",
        "  # calculate_selectivity_indexes is expecting the dicts in list_of_task... to be <trial_num>: 'network_activity',... i.e. testing_trial_and_activity structured so use data func with return like input = false\n",
        "\n",
        "  # Produce Leisoned Network\n",
        "  # Fine for BICs\n",
        "\n",
        "  selectivity_for_cond1xcond2_, abs_sorted_indexes_, ei_sorted_indexes_ = calculate_selectivity_indexes_BIC(list_of_task_cond_1_cond_2_data_dicts_for_selectivity[0], list_of_task_cond_1_cond_2_data_dicts_for_selectivity[1])\n",
        "  units_to_leison_ = abs_sorted_indexes_[-int(len(abs_sorted_indexes_)*n_perc_leison/100):]\n",
        "\n",
        "\n",
        "  leisoned_network_ = lesion_network_BIC(trained_network, units_to_leison_)\n",
        "\n",
        "  # Test uneleisoned network\n",
        "  unleisoned_full_testing_data_ = bic_testing_w_state_tracking(trained_network, testing_data_set, num_trials=2000)\n",
        "  # Test Leisoned Network\n",
        "  leisoned_full_testing_data_ = bic_testing_w_state_tracking(leisoned_network_, testing_data_set, num_trials=2000)\n",
        "\n",
        "\n",
        "  testing_env_info_ = unleisoned_full_testing_data_['testing_env_info']\n",
        "\n",
        "  print(f\"Unleisoned Network Performance: {unleisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Leisoned Network Performance: {leisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Performance Difference: {((unleisoned_full_testing_data_['testing_trial_performance'] - leisoned_full_testing_data_['testing_trial_performance'])/(unleisoned_full_testing_data_['testing_trial_performance'])) * 100} %\")\n",
        "\n",
        "  # Print a PCA Transformed Plot of the test activities for both networks\n",
        "\n",
        "  #### ------WONT WORK FOR Attn\n",
        "  if unleisoned_PCA_1d:\n",
        "    one_d_pca_filename = fig_file_name + '_1d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets(unleisoned_PCA_1d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1 across t', save_filename=one_d_pca_filename, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "  #------WONT WORK FOR Attn\n",
        "  if unleisoned_PCA_2d:\n",
        "    two_d_pca_filename = fig_file_name + '_2d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets_2d(unleisoned_PCA_2d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1xPC2', save_filename=two_d_pca_filename, add_phase_markers=True, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  all_results_ = {\n",
        "      'raw_selectivity': selectivity_for_cond1xcond2_,\n",
        "      'abs_sorted_indexes': abs_sorted_indexes_,\n",
        "      'ei_sorted_indexes': ei_sorted_indexes_,\n",
        "      'units_to_leison': units_to_leison_,\n",
        "      'unleisoned_full_testing_data': unleisoned_full_testing_data_,\n",
        "      'leisoned_full_testing_data': leisoned_full_testing_data_\n",
        "  }\n",
        "  if return_results:\n",
        "    return all_results_\n",
        "  else:\n",
        "    print('Done')\n",
        "\n"
      ],
      "metadata": {
        "id": "mqYZCbIhG6tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FULL FPF FUCNTION LIBRARY"
      ],
      "metadata": {
        "id": "oMJpr7pkeU14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import code stub"
      ],
      "metadata": {
        "id": "_JQs02fl2iku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WHEN RUNNING FPF NEED TO DO THIS FIRST (LUCKILY SEEMS TO WORK IN THIS NOTEBOOK re package versions UNLIKE DPCA)\n",
        "# also need to add fixed point finder package folder from wd to notebook drive thing\n",
        "# import sys\n",
        "# sys.path.append('/fixed-point-finder-master')\n",
        "# %cd fixed-point-finder-master\n",
        "# from FixedPointFinderTorch import FixedPointFinderTorch as FixedPointFinder\n",
        "# import torch"
      ],
      "metadata": {
        "id": "avA9mfOJesIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRIAL DATA EXTRACTION HELPER (NEW ONE)"
      ],
      "metadata": {
        "id": "ZSh2Vp642kA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### FINE FOR BICs. Fine for new task (CONDITIONAL ON Testing (-> full_testing_data) being fixed for new task), Needs changes for el gordo for layer selection for activity slicing.\n",
        "\n",
        "\n",
        "# Maybe move this to the top of testing and see if we can integrate with other funcs (or at least ensure we are not relying on the weird nestedplex dict approach)\n",
        "# Recreating helper function with deepcopy and task phase period selection / specific index selection\n",
        "\n",
        "#### REALLY IMPORTANT HELPER FUNC ####\n",
        "def extract_dict_of_trial_data_for_conds_and_hla_index(full_testing_data_dict, dict_of_conds, hla_index=None, return_like_full = False):\n",
        "  # hla_index can be:\n",
        "  # int -> single index position to extract trial activity data from\n",
        "  # tuple -> two ints that determine the min:max slice of trial activity data\n",
        "  # str -> a dictionary key for the trial period inds dictionary to produce the tuple style slice automatically\n",
        "  # list of strings ->  a list of dict keys to creat the tuple from the min of the starting inds : max of the endings inds for the listed period keys\n",
        "  # slices the hidden layer activity data\n",
        "  # Also applies conditions to filter for trials\n",
        "  # this replaces that stupid data proc function i made fml spent so long on it\n",
        "\n",
        "  full_testing_data_dict_ = deepcopy(full_testing_data_dict)\n",
        "  env_info = full_testing_data_dict_['testing_env_info'] # must be there\n",
        "  trial_testing_data_dict_ = full_testing_data_dict_['testing_trial_and_activity'] # must be there\n",
        "\n",
        "\n",
        "  slicer = None\n",
        "  if isinstance(hla_index, int):\n",
        "    slicer = hla_index\n",
        "  if isinstance(hla_index, tuple):\n",
        "    if hla_index[0] < hla_index[1]:\n",
        "      slicer = slice(hla_index[0], hla_index[1])\n",
        "    else:\n",
        "      slicer = slice(hla_index[1], hla_index[0])\n",
        "  if isinstance(hla_index, str):\n",
        "    if hla_index in env_info['trial_start_ind'] and hla_index in env_info['trial_end_ind']:\n",
        "      slicer = slice(env_info['trial_start_ind'][hla_index], env_info['trial_end_ind'][hla_index])\n",
        "  if isinstance(hla_index, list):\n",
        "    items_in_list_in_env_info = [item for item in hla_index if item in env_info['trial_start_ind'] and item in env_info['trial_end_ind']]\n",
        "    if items_in_list_in_env_info:\n",
        "      slicer = slice(min([env_info['trial_start_ind'][i] for i in hla_index]), max([env_info['trial_end_ind'][i] for i in hla_index]))\n",
        "\n",
        "  cond_filtered_dict = {}\n",
        "  for trial_id, trial_data in trial_testing_data_dict_.items():\n",
        "    if all([trial_data[f'{cond_key}'] == cond_value for cond_key, cond_value in dict_of_conds.items()]):\n",
        "      if slicer:\n",
        "        trial_data['network_activity'] = trial_data['network_activity'][slicer]\n",
        "\n",
        "\n",
        "      cond_filtered_dict[trial_id] = trial_data\n",
        "\n",
        "  if return_like_full: # adding this in so i can reuse output of just conditional to perform the index slicing too!\n",
        "    return {'testing_trial_and_activity': cond_filtered_dict, 'testing_env_info': env_info}\n",
        "  else:\n",
        "    return cond_filtered_dict\n"
      ],
      "metadata": {
        "id": "7Jgrf5xGeU15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### FINE FOR BICs. Fine for new task (CONDITIONAL ON Testing (-> full_testing_data) being fixed for new task), Needs changes for layer selection for activity slicing if using in attention.\n",
        "\n",
        "\n",
        "# Maybe move this to the top of testing and see if we can integrate with other funcs (or at least ensure we are not relying on the weird nested^plex dict approach) - solved\n",
        "# Recreating helper function with deepcopy and task phase period selection / specific index selection\n",
        "\n",
        "#### REALLY IMPORTANT HELPER FUNC ####\n",
        "def extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(full_testing_data_dict, dict_of_conds, hla_index=None, return_like_full = False):\n",
        "  # hla_index can be:\n",
        "  # int -> single index position to extract trial activity data from\n",
        "  # tuple -> two ints that determine the min:max slice of trial activity data\n",
        "  # str -> a dictionary key for the trial period inds dictionary to produce the tuple style slice automatically\n",
        "  # list of strings ->  a list of dict keys to creat the tuple from the min of the starting inds : max of the endings inds for the listed period keys\n",
        "  # slices the hidden layer activity data\n",
        "  # Also applies conditions to filter for trials\n",
        "  # this replaces that stupid data proc function i made fml spent so long on it\n",
        "\n",
        "  full_testing_data_dict_ = deepcopy(full_testing_data_dict)\n",
        "  env_info = full_testing_data_dict_['testing_env_info'] # must be there\n",
        "  trial_testing_data_dict_ = full_testing_data_dict_['testing_trial_and_activity'] # must be there\n",
        "\n",
        "\n",
        "  slicer = None\n",
        "  if isinstance(hla_index, int):\n",
        "    slicer = hla_index\n",
        "  if isinstance(hla_index, tuple):\n",
        "    if hla_index[0] < hla_index[1]:\n",
        "      slicer = slice(hla_index[0], hla_index[1])\n",
        "    else:\n",
        "      slicer = slice(hla_index[1], hla_index[0])\n",
        "  if isinstance(hla_index, str):\n",
        "    if hla_index in env_info['trial_start_ind'] and hla_index in env_info['trial_end_ind']:\n",
        "      slicer = slice(env_info['trial_start_ind'][hla_index], env_info['trial_end_ind'][hla_index])\n",
        "  if isinstance(hla_index, list):\n",
        "    items_in_list_in_env_info = [item for item in hla_index if item in env_info['trial_start_ind'] and item in env_info['trial_end_ind']]\n",
        "    if items_in_list_in_env_info:\n",
        "      slicer = slice(min([env_info['trial_start_ind'][i] for i in hla_index]), max([env_info['trial_end_ind'][i] for i in hla_index]))\n",
        "\n",
        "  cond_filtered_dict = {}\n",
        "  for trial_id, trial_data in trial_testing_data_dict_.items():\n",
        "    if all([trial_data[f'{cond_key}'] == cond_value for cond_key, cond_value in dict_of_conds.items()]):\n",
        "      if slicer:\n",
        "        trial_data['network_activity'] = trial_data['network_activity'][slicer] # is hidden state if trial dict was made via bic tester (non fpf bic tester), is hidden activity otherwise\n",
        "        network_hidden_state_ = trial_data.get('network_hidden_state', None) # is hidden state if trial dict was made via bic tester (non fpf bic tester), is hidden activity otherwise\n",
        "        if network_hidden_state_ is not None:\n",
        "          trial_data['network_hidden_state'] = network_hidden_state_[slicer]\n",
        "\n",
        "        # is hidden activity if trial dict was made via bic tester (non fpf bic tester), is hidden state otherwise\n",
        "\n",
        "      cond_filtered_dict[trial_id] = trial_data\n",
        "\n",
        "  if return_like_full: # adding this in so i can reuse output of just conditional to perform the index slicing too!\n",
        "    return {'testing_trial_and_activity': cond_filtered_dict, 'testing_env_info': env_info}\n",
        "  else:\n",
        "    return cond_filtered_dict\n"
      ],
      "metadata": {
        "id": "t43zzY63Wg7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF Specific Helper Funcs"
      ],
      "metadata": {
        "id": "HvHFRufh2rl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_samples_with_opt_noise(list_of_arrays, num_samples, std_pc=0.0, random=False, random_range_modifier = 0.0, protected_indexes=None):\n",
        "    # random range modifier is the decimal above the upper range and below the lower range to extend the random range by e.g. 0.1 = 10%\n",
        "\n",
        "    if not isinstance(list_of_arrays, np.ndarray):\n",
        "        list_of_arrays_np = np.array(list_of_arrays)\n",
        "    else:\n",
        "        list_of_arrays_np = list_of_arrays\n",
        "\n",
        "    # Determine n_dim from the first array's shape\n",
        "    n_dim = list_of_arrays_np.shape[-1] if list_of_arrays_np.ndim > 1 else list_of_arrays_np.shape[0]\n",
        "\n",
        "    # Random Initial Conditions (random=True)\n",
        "    if random:\n",
        "\n",
        "        # Establish plausible ranges for each unit\n",
        "        # min/max across all samples for each dimension * 1 +/- modifier\n",
        "        min_per_unit = np.min(list_of_arrays_np, axis=0) * (1.0 - random_range_modifier)\n",
        "        max_per_unit = np.max(list_of_arrays_np, axis=0) * (1.0 + random_range_modifier)\n",
        "\n",
        "        # Create new random arrays within these ranges\n",
        "        # np.random.uniform(low, high, size)\n",
        "        sampled_arrays = np.random.uniform(low=min_per_unit,\n",
        "                                           high=max_per_unit,\n",
        "                                           size=(num_samples, n_dim))\n",
        "        return sampled_arrays\n",
        "\n",
        "    # Sample from list_of_arrays and then add std based noise (std_pc)\n",
        "    # Samples with replacement\n",
        "    random_indices = np.random.choice(len(list_of_arrays_np), size=num_samples)\n",
        "    sampled_arrays = list_of_arrays_np[random_indices]\n",
        "    # Add noise based on std_pc\n",
        "    if std_pc > 0.0:\n",
        "\n",
        "        # Calculate standard deviation for each unit individually\n",
        "        std_dev_per_unit = np.std(list_of_arrays_np, axis=0)\n",
        "\n",
        "        # Calculate noise scale per unit based on std_pc percentage\n",
        "        noise_scale_per_unit = std_pc * std_dev_per_unit\n",
        "\n",
        "        # Generate Gaussian noise (mean 0, std dev = noise_scale_per_unit)\n",
        "        noise = np.random.randn(num_samples, n_dim) * noise_scale_per_unit\n",
        "\n",
        "        if protected_indexes is not None:\n",
        "            noise[:, protected_indexes] = 0.0 # Apply 0 noise to protected units\n",
        "        sampled_arrays += noise\n",
        "        return sampled_arrays\n",
        "\n",
        "\n",
        "    # Default: Just straight sampled, no noise\n",
        "    return sampled_arrays"
      ],
      "metadata": {
        "id": "hsW52VVKwSSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input and IC Data Construction Func"
      ],
      "metadata": {
        "id": "NM7lAtJr2vsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def obtain_data_for_fpf_setup_bic(filtered_trial_data_dict, num_init_conds, noise_std_or_random_range_modifier = 0.0, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key='network_activity'):\n",
        "\n",
        "  # passing a list of 1 input array if doing for now. (not sure on FPF and traceability of fixed input that produced FP)\n",
        "\n",
        "  if list_of_input_arrays is None:\n",
        "    # look at all inputs!\n",
        "    list_of_input_arrays = [np.array([0.0, 0.0, 1.0]),np.array([0.0,1.0,0.0]), np.array([1.0,0.0,0.0])]\n",
        "  # Assuming all trial activity data is sequences (seq_len, hidden_size) or (hidden_size,) for sampling\n",
        "\n",
        "  list_of_hidden_activity = [trial_data[f'{hidden_key}'] for trial_data in filtered_trial_data_dict.values()] ### Wont work for el G\n",
        "  list_of_hidden_activity_proc = []\n",
        "\n",
        "  for hla_arr in list_of_hidden_activity:\n",
        "    # If shaped (n, hidden_layer_size) Convert to a list of n (hidden_layer_size,) arrays and concatenate this with proc list\n",
        "    if hla_arr.ndim == 2:\n",
        "      list_of_hidden_activity_proc.extend([arr for arr in hla_arr])\n",
        "    # Otherwise (assume already (hidden_layer_size,) and append\n",
        "    else:\n",
        "      list_of_hidden_activity_proc.append(hla_arr)\n",
        "\n",
        "  list_of_hidden_activity_proc = np.array(list_of_hidden_activity_proc)\n",
        "  # handles for random ic creation bounded by a range based on the plausible unit activity ranges\n",
        "  if random_ics:\n",
        "    init_hla_cond_array = get_random_samples_with_opt_noise(list_of_hidden_activity_proc, num_init_conds, std_pc=0.0, random=True, random_range_modifier = noise_std_or_random_range_modifier, protected_indexes=None)\n",
        "  # handles for sample with noise and straigh sampling\n",
        "  else:\n",
        "    init_hla_cond_array = get_random_samples_with_opt_noise(list_of_hidden_activity_proc, num_init_conds, std_pc=noise_std_or_random_range_modifier, random=False, random_range_modifier = 0.0, protected_indexes=noise_protected_indexes_hla)\n",
        "\n",
        "\n",
        "\n",
        "  input_arrays = get_random_samples_with_opt_noise(list_of_input_arrays, num_init_conds) # set as num init conds for dimension consistency\n",
        "\n",
        "  return init_hla_cond_array, input_arrays\n",
        "  # Should return the (n_conds,vector_size) arrays where vector_size is hidden_layer_size for initial_hla_conditions and input_size for input_arrays\n"
      ],
      "metadata": {
        "id": "K-646PlpzJHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed Point Finding"
      ],
      "metadata": {
        "id": "NV2ugkEK2zoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_fixed_point_finding(rnn_layer, initial_hla_array, fixed_input_array, n_iters_fpf = 20000):\n",
        "  # Requires rnn_layer object provided as input to return in shape (batch_size, hidden_size) and have batch_first = False in init\n",
        "  # Which for LRNN it does as seq_len = 1 and so output is collapsed to (batch,hidden) instead of (seq_len,bs,hs)\n",
        "  ## But still need to indicate to FPF batch_first = False due to the way it performs iterations on the network when minimising the objective function to find fps.\n",
        "  fp_finder = None\n",
        "  fp_finder = FixedPointFinder(rnn_layer, max_iters = n_iters_fpf)\n",
        "\n",
        "  # If torch, Convert from torch to numpy # shouldnt be because of our func :)\n",
        "  if torch.is_tensor(initial_hla_array):\n",
        "    initial_hla_array = initial_hla_array.cpu().numpy()\n",
        "  if torch.is_tensor(fixed_input_array):\n",
        "    fixed_input_array = fixed_input_array.cpu().numpy()\n",
        "\n",
        "  if fixed_input_array.shape[0] != initial_hla_array.shape[0] and fixed_input_array.shape[0] != 1:\n",
        "    print('Fixed input should either be 1 vector (1,n_input_dim) shaped, or have same number of \"rows\" as initial conditions')\n",
        "    print('Expect error but continuing.') # change to return or raise if problematic (not sure on FPFs handling for this case)\n",
        "\n",
        "\n",
        "  unique_fps, all_fps = fp_finder.find_fixed_points(initial_hla_array, fixed_input_array)\n",
        "  fp_finder = None # clean up\n",
        "  # change to all_fps if needed, hasn't been so far\n",
        "  print(unique_fps.xstar.shape)\n",
        "  print(all_fps.xstar.shape)\n",
        "  return unique_fps\n"
      ],
      "metadata": {
        "id": "Gs8gO_8TeU18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed Point PCA Plotter"
      ],
      "metadata": {
        "id": "QxzpezHJ22k1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------WONT WORK FOR DIFF TASK------"
      ],
      "metadata": {
        "id": "z6u7HqJXz_3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_with_fps_BICS(\n",
        "    fixed_points_obj,    # A single FixedPoints object\n",
        "    pca_object,          # fitted PCA object (assumed n_components>=2)\n",
        "    trial_data_dict=None,# pre-filtered dict of trial data for the specific scenario\n",
        "    trial_env_info=None, # env info (dt, trial_start_ind, trial_end_ind)\n",
        "    task_phase_str=None, # e.g., 'delay', 'sample' - corresponds to the scenario's phase\n",
        "    plot_prev=True,      # If True, plot pre-phase activity in faint black\n",
        "    plot_title=None,     # Optional plot title (ignored)\n",
        "    filename=None,       # Optional filename to save (triggers save and close)\n",
        "    max_trials_to_plot=100, # Max number of trial trajectories to plot\n",
        "    fixed_axis_limits=None, # (xmin, xmax, ymin, ymax) tuple for fixed axis limits\n",
        "    activate_fps = False\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Plots fixed points and mean PCA trajectories for a specific task phase, styled\n",
        "\n",
        "    Args:\n",
        "        (Arguments are unchanged from the original function)\n",
        "    \"\"\"\n",
        "    # --- Style Guide Definitions ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    STYLE_GUIDE_MARKERS = {\n",
        "        'stable_fp':    {'marker': 'D', 'color': 'g', 'label': 'Stable Fixed Point', 'size': 120},\n",
        "        'unstable_fp':  {'marker': 'o', 'color': 'r', 'label': 'Unstable Fixed Point', 'size': 120},\n",
        "        'start':        {'marker': 's', 'color': 'k', 'label': 'Start', 'size': 64},\n",
        "        'phase_trans':  {'marker': '*', 'color': 'gold', 'label': 'Phase Transition', 'size': 144}\n",
        "    }\n",
        "\n",
        "    # --- Plotting Setup ---\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    legend_handles = []\n",
        "    plotted_fp_types = set()\n",
        "    plotted_conditions = set()\n",
        "\n",
        "    # --- 1. Plot Fixed Points ---\n",
        "    if fixed_points_obj:\n",
        "        fp_activity = fixed_points_obj.xstar\n",
        "        if activate_fps:\n",
        "             fp_activity = np.maximum(0, fp_activity) # Assumes ReLU\n",
        "\n",
        "        transformed_fps = pca_object.transform(fp_activity)[:, :2]\n",
        "\n",
        "        for i in range(len(transformed_fps)):\n",
        "            is_stable = fixed_points_obj.is_stable[i]\n",
        "            style_key = 'stable_fp' if is_stable else 'unstable_fp'\n",
        "            style = STYLE_GUIDE_MARKERS[style_key]\n",
        "\n",
        "            ax.scatter(transformed_fps[i, 0], transformed_fps[i, 1],\n",
        "                       marker=style['marker'], facecolor=style['color'], s=style['size'],\n",
        "                       edgecolor='k', linewidth=1.0, zorder=10)\n",
        "            plotted_fp_types.add(style_key)\n",
        "\n",
        "    # --- 2. Plot Mean Trial Trajectories ---\n",
        "    if trial_data_dict and trial_env_info and task_phase_str:\n",
        "        phase_start_idx = trial_env_info['trial_start_ind'].get(task_phase_str)\n",
        "        phase_end_idx = trial_env_info['trial_end_ind'].get(task_phase_str)\n",
        "        phase_order = list(trial_env_info.get('trial_start_ind', {}).keys())\n",
        "\n",
        "        if phase_start_idx is not None and phase_end_idx is not None:\n",
        "            grouped_trajectories = defaultdict(list)\n",
        "            limited_trials = dict(list(trial_data_dict.items())[:max_trials_to_plot])\n",
        "\n",
        "            for trial_dict in limited_trials.values():\n",
        "                stim_condition = (round(trial_dict['sample_stim_value'], 2), round(trial_dict['test_stim_value'], 2))\n",
        "                if stim_condition in STYLE_GUIDE_COLORS:\n",
        "                    activity = np.array(trial_dict['network_activity'])\n",
        "                    grouped_trajectories[stim_condition].append(pca_object.transform(activity)[:, :2])\n",
        "\n",
        "            for condition, trajectories in grouped_trajectories.items():\n",
        "                if not trajectories: continue\n",
        "                plotted_conditions.add(condition)\n",
        "                mean_traj = np.mean(np.array(trajectories), axis=0)\n",
        "\n",
        "                # Plot preceding phase segment\n",
        "                if plot_prev and phase_start_idx > 0:\n",
        "                    pre_phase_seg = mean_traj[0:phase_start_idx]\n",
        "                    ax.plot(pre_phase_seg[:, 0], pre_phase_seg[:, 1], color='k', lw=1.0, alpha=0.8)\n",
        "\n",
        "                # Plot in-phase segment\n",
        "                in_phase_seg = mean_traj[phase_start_idx-1:phase_end_idx]\n",
        "                ax.plot(in_phase_seg[:, 0], in_phase_seg[:, 1], color=STYLE_GUIDE_COLORS[condition]['color'], lw=2.5)\n",
        "\n",
        "                # Plot Start Marker (always at the beginning of the full trajectory)\n",
        "                start_style = STYLE_GUIDE_MARKERS['start']\n",
        "                ax.plot(mean_traj[0, 0], mean_traj[0, 1], marker=start_style['marker'], color=start_style['color'],\n",
        "                        markersize=np.sqrt(start_style['size']), linestyle='None', zorder=5)\n",
        "\n",
        "\n",
        "\n",
        "                # --- Plot Phase Transition Markers for ALL phases before + inc current  ---\n",
        "                indices_to_mark = []\n",
        "                if task_phase_str in phase_order:\n",
        "                    # Find the index of the current phase to determine which phases came before it.\n",
        "                    current_phase_position = phase_order.index(task_phase_str)\n",
        "\n",
        "                    # Always add the end of the current phase.\n",
        "                    indices_to_mark.append(phase_end_idx - 1)\n",
        "\n",
        "                    # If plotting previous segments, add markers for all preceding phases.\n",
        "                    if plot_prev:\n",
        "                        # Iterate through all phases that come before the current one.\n",
        "                        for i in range(current_phase_position):\n",
        "                            prev_phase_name = phase_order[i]\n",
        "                            prev_end_idx = trial_env_info['trial_end_ind'].get(prev_phase_name)\n",
        "                            if prev_end_idx:\n",
        "                                indices_to_mark.append(prev_end_idx - 1)\n",
        "\n",
        "                phase_trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "                # Use set to plot each unique index only once.\n",
        "                for end_idx in set(filter(None, indices_to_mark)):\n",
        "                    if end_idx >= 0 and end_idx < len(mean_traj):\n",
        "                        ax.plot(mean_traj[end_idx, 0], mean_traj[end_idx, 1],\n",
        "                                marker=phase_trans_style['marker'],\n",
        "                                color=phase_trans_style['color'],\n",
        "                                markersize=np.sqrt(phase_trans_style['size']),\n",
        "                                linestyle='None', zorder=5)\n",
        "    # --- 3. Build Hierarchical Legend ---\n",
        "    # Part 1: Fixed Points\n",
        "    for fp_type in sorted(list(plotted_fp_types)):\n",
        "        style = STYLE_GUIDE_MARKERS[fp_type]\n",
        "        legend_handles.append(Line2D([0], [0], marker=style['marker'], color='w', label=style['label'],\n",
        "                                     markerfacecolor=style['color'], markeredgecolor='k', markersize=np.sqrt(style['size'])))\n",
        "    if plotted_fp_types: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # Part 2: Trial Conditions\n",
        "    for condition in sorted(list(plotted_conditions)):\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "    if plotted_conditions: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # Part 3: Trajectory Markers\n",
        "    if plotted_conditions:\n",
        "        start_style = STYLE_GUIDE_MARKERS['start']\n",
        "        legend_handles.append(Line2D([0], [0], marker=start_style['marker'], color='w', label=start_style['label'],\n",
        "                                     markerfacecolor=start_style['color'], markersize=np.sqrt(start_style['size'])))\n",
        "        trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "        legend_handles.append(Line2D([0], [0], marker=trans_style['marker'], color='w', label=trans_style['label'],\n",
        "                                     markerfacecolor=trans_style['color'], markersize=np.sqrt(trans_style['size'])))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # --- 4. Final Touches ---\n",
        "    if fixed_axis_limits:\n",
        "        ax.set_xlim(fixed_axis_limits[0], fixed_axis_limits[1])\n",
        "        ax.set_ylim(fixed_axis_limits[2], fixed_axis_limits[3])\n",
        "\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- 5. Save or Display ---\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename) and not os.path.exists(os.path.dirname(filename)):\n",
        "                os.makedirs(os.path.dirname(filename))\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "dTl-powehne5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_with_fps_BICS(\n",
        "    fixed_points_obj,    # A single FixedPoints object\n",
        "    pca_object,          # fitted PCA object (assumed n_components>=2)\n",
        "    trial_data_dict=None,# pre-filtered dict of trial data for the specific scenario\n",
        "    trial_env_info=None, # env info (dt, trial_start_ind, trial_end_ind)\n",
        "    task_phase_str=None, # e.g., 'delay', 'stimulus' - corresponds to the scenario's phase\n",
        "    plot_prev=True,      # If True, plot pre-phase activity in faint black\n",
        "    plot_title=None,     # Optional plot title (ignored)\n",
        "    filename=None,       # Optional filename to save (triggers save and close)\n",
        "    max_trials_to_plot=100, # Max number of trial trajectories to plot\n",
        "    fixed_axis_limits=None, # (xmin, xmax, ymin, ymax) tuple for fixed axis limits\n",
        "    activate_fps = False\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Plots fixed points and mean PCA trajectories for a specific task phase,\n",
        "    adapted for the new task.\n",
        "\n",
        "    Args:\n",
        "        (Arguments are unchanged from the original function)\n",
        "    \"\"\"\n",
        "    # --- Updated Style Guide Definitions ---\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        1: {'color': '#e69010', 'label': 'Stim 1 > Stim 2'},  # Orange\n",
        "        2: {'color': '#6b08bd', 'label': 'Stim 2 > Stim 1'},  # Purple\n",
        "    }\n",
        "    STYLE_GUIDE_MARKERS = {\n",
        "        'stable_fp':    {'marker': 'D', 'color': 'g', 'label': 'Stable Fixed Point', 'size': 120},\n",
        "        'unstable_fp':  {'marker': 'o', 'color': 'r', 'label': 'Unstable Fixed Point', 'size': 120},\n",
        "        'start':        {'marker': 's', 'color': 'k', 'label': 'Start', 'size': 64},\n",
        "        'phase_trans':  {'marker': '*', 'color': 'gold', 'label': 'Phase Transition', 'size': 144}\n",
        "    }\n",
        "\n",
        "    # --- Plotting Setup ---\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    legend_handles = []\n",
        "    plotted_fp_types = set()\n",
        "    plotted_conditions = set()\n",
        "\n",
        "    # --- 1. Plot Fixed Points (No changes needed) ---\n",
        "    if fixed_points_obj:\n",
        "        fp_activity = fixed_points_obj.xstar\n",
        "        if activate_fps:\n",
        "             fp_activity = np.maximum(0, fp_activity) # Assumes ReLU\n",
        "\n",
        "        transformed_fps = pca_object.transform(fp_activity)[:, :2]\n",
        "\n",
        "        for i in range(len(transformed_fps)):\n",
        "            is_stable = fixed_points_obj.is_stable[i]\n",
        "            style_key = 'stable_fp' if is_stable else 'unstable_fp'\n",
        "            style = STYLE_GUIDE_MARKERS[style_key]\n",
        "\n",
        "            ax.scatter(transformed_fps[i, 0], transformed_fps[i, 1],\n",
        "                       marker=style['marker'], facecolor=style['color'], s=style['size'],\n",
        "                       edgecolor='k', linewidth=1.0, zorder=10)\n",
        "            plotted_fp_types.add(style_key)\n",
        "\n",
        "    # --- 2. Plot Mean Trial Trajectories ---\n",
        "    if trial_data_dict and trial_env_info and task_phase_str:\n",
        "        phase_start_idx = trial_env_info['trial_start_ind'].get(task_phase_str)\n",
        "        phase_end_idx = trial_env_info['trial_end_ind'].get(task_phase_str)\n",
        "        phase_order = list(trial_env_info.get('trial_start_ind', {}).keys())\n",
        "\n",
        "        if phase_start_idx is not None and phase_end_idx is not None:\n",
        "            grouped_trajectories = defaultdict(list)\n",
        "            limited_trials = dict(list(trial_data_dict.items())[:max_trials_to_plot])\n",
        "\n",
        "            for trial_dict in limited_trials.values():\n",
        "                # MODIFIED: Use 'ground_truth' as the key for grouping conditions\n",
        "                stim_condition = trial_dict.get('ground_truth')\n",
        "                if stim_condition is not None and stim_condition in STYLE_GUIDE_COLORS:\n",
        "                    activity = np.array(trial_dict['network_activity'])\n",
        "                    grouped_trajectories[stim_condition].append(pca_object.transform(activity)[:, :2])\n",
        "\n",
        "            for condition, trajectories in grouped_trajectories.items():\n",
        "                if not trajectories: continue\n",
        "                plotted_conditions.add(condition)\n",
        "                mean_traj = np.mean(np.array(trajectories), axis=0)\n",
        "\n",
        "                # Plot preceding phase segment\n",
        "                if plot_prev and phase_start_idx > 0:\n",
        "                    pre_phase_seg = mean_traj[0:phase_start_idx]\n",
        "                    ax.plot(pre_phase_seg[:, 0], pre_phase_seg[:, 1], color='k', lw=1.0, alpha=0.8)\n",
        "\n",
        "                # Plot in-phase segment\n",
        "                in_phase_seg = mean_traj[phase_start_idx-1:phase_end_idx]\n",
        "                ax.plot(in_phase_seg[:, 0], in_phase_seg[:, 1], color=STYLE_GUIDE_COLORS[condition]['color'], lw=2.5)\n",
        "\n",
        "                # Plot Start Marker\n",
        "                start_style = STYLE_GUIDE_MARKERS['start']\n",
        "                ax.plot(mean_traj[0, 0], mean_traj[0, 1], marker=start_style['marker'], color=start_style['color'],\n",
        "                        markersize=np.sqrt(start_style['size']), linestyle='None', zorder=5)\n",
        "\n",
        "                # Plot Phase Transition Markers for ALL relevant phases\n",
        "                indices_to_mark = []\n",
        "                if task_phase_str in phase_order:\n",
        "                    current_phase_position = phase_order.index(task_phase_str)\n",
        "                    indices_to_mark.append(phase_end_idx - 1)\n",
        "                    if plot_prev:\n",
        "                        for i in range(current_phase_position):\n",
        "                            prev_phase_name = phase_order[i]\n",
        "                            prev_end_idx = trial_env_info['trial_end_ind'].get(prev_phase_name)\n",
        "                            if prev_end_idx:\n",
        "                                indices_to_mark.append(prev_end_idx - 1)\n",
        "\n",
        "                phase_trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "                for end_idx in set(filter(None, indices_to_mark)):\n",
        "                    if end_idx >= 0 and end_idx < len(mean_traj):\n",
        "                        ax.plot(mean_traj[end_idx, 0], mean_traj[end_idx, 1],\n",
        "                                marker=phase_trans_style['marker'], color=phase_trans_style['color'],\n",
        "                                markersize=np.sqrt(phase_trans_style['size']), linestyle='None', zorder=5)\n",
        "\n",
        "    # --- 3. Build Hierarchical Legend (Logic remains the same) ---\n",
        "    for fp_type in sorted(list(plotted_fp_types)):\n",
        "        style = STYLE_GUIDE_MARKERS[fp_type]\n",
        "        legend_handles.append(Line2D([0], [0], marker=style['marker'], color='w', label=style['label'],\n",
        "                                     markerfacecolor=style['color'], markeredgecolor='k', markersize=np.sqrt(style['size'])))\n",
        "    if plotted_fp_types: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    for condition in sorted(list(plotted_conditions)):\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "    if plotted_conditions: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    if plotted_conditions:\n",
        "        start_style = STYLE_GUIDE_MARKERS['start']\n",
        "        legend_handles.append(Line2D([0], [0], marker=start_style['marker'], color='w', label=start_style['label'],\n",
        "                                     markerfacecolor=start_style['color'], markersize=np.sqrt(start_style['size'])))\n",
        "        trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "        legend_handles.append(Line2D([0], [0], marker=trans_style['marker'], color='w', label=trans_style['label'],\n",
        "                                     markerfacecolor=trans_style['color'], markersize=np.sqrt(trans_style['size'])))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # --- 4. Final Touches (No changes needed) ---\n",
        "    if fixed_axis_limits:\n",
        "        ax.set_xlim(fixed_axis_limits[0], fixed_axis_limits[1])\n",
        "        ax.set_ylim(fixed_axis_limits[2], fixed_axis_limits[3])\n",
        "\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # --- 5. Save or Display (No changes needed) ---\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename) and not os.path.exists(os.path.dirname(filename)):\n",
        "                os.makedirs(os.path.dirname(filename))\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "jEY-HY8RpT5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to run full FPF (based on our implementation)"
      ],
      "metadata": {
        "id": "rCCg6zd1i_ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------WONT WORK FOR DIFF TASK------"
      ],
      "metadata": {
        "id": "u98Br_6d0HV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fpf_2d_pca_plot_BIC(rnn_for_fpf, testing_trial_data_for_fpa, testing_trial_env_for_fpa, pca_object_for_plotting = None, ic_period = 'stimulus', fixed_input_array_ = [[1.0,0.0,1.0]], trial_cond_for_plot = {'ground_truth': 2, 'network_correct':True,}, use_random_ics=False, use_noisey_ics = False, filename_for_plot = 'figure.png', title_for_plot = 'Sample Period 0.0 Stimulus Input Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_hidden_state'):\n",
        "\n",
        "\n",
        "  _activate_fps = True if hidden_key == 'network_hidden_state' else False\n",
        "\n",
        "  # Very hacky, consider not reading to avoid headache\n",
        "\n",
        "  ### SO THIS IS TO BE USED IF I RUN THE TESTING AND PCA FUNCS WITH THE HIDDEN LAYER STATE, AND PLOT ALONGSIDE HIDDEN LAYER STATE TRANSFORMED BY PCAS FIT ON THE HIDDEN LAYER STATE (I.e. FOR TESTING FUNC WITH Key = 'hidden_activity' == hidden_state_tensor (this notebook))\n",
        "  ## so hidden_key == 'network_activity' iff ['network_activity'] = hidden_state_tensor in the testing function  ->  find fps using hidden state ics, have pcas fit on hidden state (from rest of analysis), plotting the fps WITHOUT modification using the pcas (and trial data to plot is hidden state trial data located at 'network_activity' key in trial dict)\n",
        "  ## hidden_key == 'network_hidden_state' iff ['network_activity'] = hidden_activity in the testing function  ->  find fps using hidden state ics, have pcas fit on hidden layer output activity (from rest of analysis), plotting the fps WITH RELU activiation using the pcas ((and trial data to plot is hidden output activity trial data located at 'network_activity' key in trial dict)\n",
        "\n",
        "\n",
        "  ## so if hidden_key == 'network_activity' -> activate_fps == False,\n",
        "  ## so if hidden_key == 'network_hidden_state' -> activate_fps == True, and no other changes\n",
        "\n",
        "  # NEED TO ENSURE rnn_for_fpf points to the helper func specifically designed for this\n",
        "\n",
        "  period_i_data_test_period = extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(testing_trial_data_for_fpa, {'network_correct': True}, return_like_full=True, hla_index= ic_period)\n",
        "  period_i_0_trial_data = extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(period_i_data_test_period, {'network_correct': True}, return_like_full=False, hla_index=0)\n",
        "\n",
        "  # Sample fixed inputs for pdm? dont really have fixed inputs except delay....?\n",
        "  # maybe use fixed inputs sampled at different coherences? or just a single input of median coherence for stim2>stim1 and stim1>stim2\n",
        "\n",
        "  # Produce ICs\n",
        "  list_of_ic_arrs = []\n",
        "  ## See Obtain Data Fixes\n",
        "  ic_arr_0, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds=1000, noise_std_or_random_range_modifier = 0.0, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "  list_of_ic_arrs.append(ic_arr_0)\n",
        "  if use_random_ics:\n",
        "    ic_arr_1, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds = 100, noise_std_or_random_range_modifier = 0.1, random_ics = True, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "    list_of_ic_arrs.append(ic_arr_1)\n",
        "  if use_noisey_ics:\n",
        "    ic_arr_2, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds = 100, noise_std_or_random_range_modifier = 0.1, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "    list_of_ic_arrs.append(ic_arr_2)\n",
        "  period_i_0_init_conds = np.concatenate(list_of_ic_arrs, axis=0)\n",
        "  # Run Fixed Point Finding\n",
        "  unique_fps_period_i_input_j = perform_fixed_point_finding(rnn_layer=rnn_for_fpf, initial_hla_array=period_i_0_init_conds, fixed_input_array=fixed_input_array_)\n",
        "  # Creating the prefiltered dict of trial data\n",
        "  period_cond_trial_data = extract_dict_of_trial_data_for_conds_and_hla_index(testing_trial_data_for_fpa, trial_cond_for_plot, return_like_full=False)\n",
        "  # Plot in 2D PCA with custom title and max_trials, and save to filename if given\n",
        "\n",
        "  #### SEE FIXES FOR PLOT PCA TRAJ WITH FPS\n",
        "  # First Attempt with flexible PCA func\n",
        "  plot_pca_trajectories_with_fps_BICS(\n",
        "    fixed_points_obj = unique_fps_period_i_input_j,\n",
        "    pca_object = pca_object_for_plotting,            # fitted PCA object (assumed n_components=2 but could add err check)\n",
        "    trial_data_dict=period_cond_trial_data,# pre-filtered dict of trial data for the specific scenario!\n",
        "    trial_env_info=testing_trial_env_for_fpa, # env info (dt, trial_start_ind, trial_end_ind etc.)\n",
        "    task_phase_str= ic_period, # e.g., 'delay', 'stimulus' - corresponds to the scenario's phase from which we will sample ics for fpf\n",
        "    plot_prev=plot_prev,      # If True, it will plot pre-'phase of interest' activity in faint black\n",
        "    plot_title=title_for_plot,    # Optional plot title - dont use for writeup\n",
        "    filename=filename_for_plot,        # Optional filename to save (triggers save and show)\n",
        "    max_trials_to_plot=max_trials_to_plot, # Max number of trial trajectories to plot # averages now anyway\n",
        "    activate_fps=_activate_fps\n",
        "    )"
      ],
      "metadata": {
        "id": "kEXiqPdThaWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Trial Run with 'Functionised' Notebook ---\n"
      ],
      "metadata": {
        "id": "G-3WMCKFqDSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINING NBIC NETWORKS"
      ],
      "metadata": {
        "id": "6HfrDvwBeWQt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAI8fAKFabC4"
      },
      "source": [
        "## LeakyRNN Layer - No BICs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9Hk8gM10j49"
      },
      "outputs": [],
      "source": [
        "# # Leaky RNN\n",
        "# class LeakyRNN(nn.Module):\n",
        "#     \"\"\"Leaky RNN.\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: Number of input neurons\n",
        "#         hidden_size: Number of hidden neurons\n",
        "#         dt: discretization time step in ms.\n",
        "#             If None, dt equals time constant tau\n",
        "\n",
        "#     Inputs:\n",
        "#         input: tensor of shape (seq_len, batch, input_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "#             if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "#     Outputs:\n",
        "#         output: tensor of shape (seq_len, batch, hidden_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, input_size, hidden_size, dt=50, tau=100, **kwargs): # dt is now required\n",
        "#         super().__init__()\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.tau = tau\n",
        "#         self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "#         self.batch_first = False # For fixed point finder\n",
        "#         # Check for stability (/biological plausibility)\n",
        "#         if self.alpha > 1.0:\n",
        "#             print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0.\")\n",
        "\n",
        "#         self.input2h = nn.Linear(input_size, hidden_size)\n",
        "#         self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "#     def init_hidden(self, input_shape):\n",
        "#         batch_size = input_shape[1]\n",
        "#         return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "#     def recurrence(self, input, hidden):\n",
        "#         \"\"\"Run network for one time step.\n",
        "\n",
        "#         Inputs:\n",
        "#             input: tensor of shape (batch, input_size)\n",
        "#             hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "#         Outputs:\n",
        "#             h_new: tensor of shape (batch, hidden_size),\n",
        "#                 network activity at the next time step\n",
        "#         \"\"\"\n",
        "#         h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
        "#         h_new = hidden * (1 - self.alpha) + h_new * self.alpha\n",
        "#         return h_new\n",
        "\n",
        "#     def forward(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "#         # If hidden activity is not provided, initialise it\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "#         # Loop through time\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden)\n",
        "\n",
        "#         # Stack together output from all time steps\n",
        "#         output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "#         # Hidden is the final step state of this layers activity, output is all step states (including final)\n",
        "\n",
        "#         return output, hidden\n",
        "#     def forward_helper_fpf(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "#         # If hidden activity is not provided, initialise it\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input.shape).to(input.device)\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden)\n",
        "#         output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "#         return output, hidden\n",
        "#     def forward_helper_fpf_ICs(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "#         # If hidden activity is not provided, initialise it\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input.shape).to(input.device)\n",
        "#         output = []\n",
        "#         hidden_s = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden)\n",
        "#             hidden_s.append(hidden)\n",
        "#         output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "#         hidden_tensor = torch.stack(hidden_s, dim=0)  # (seq_len, batch, hidden_size)\n",
        "#         return output, hidden_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXDegRCV1bBi"
      },
      "outputs": [],
      "source": [
        "# Leaky RNN\n",
        "class LeakyRNN(nn.Module):\n",
        "    \"\"\"Leaky RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=50, tau=100, **kwargs): # dt is now required\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "        self.batch_first = False # For fixed point finder\n",
        "        # Check for stability (/biological plausibility)\n",
        "        if self.alpha > 1.0:\n",
        "            print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0. This can lead to numerical instability.\")\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      # Initialize input-to-hidden layer with Kaiming Uniform\n",
        "      init.kaiming_uniform_(self.input2h.weight, a=math.sqrt(5))\n",
        "      if self.input2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.input2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.input2h.bias, -bound, bound)\n",
        "\n",
        "      # Initialize hidden-to-hidden layer with Orthogonal\n",
        "      init.orthogonal_(self.h2h.weight)\n",
        "      if self.h2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.h2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.h2h.bias, -bound, bound)\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = input_shape[1]\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "        h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
        "        h_new = hidden * (1 - self.alpha) + h_new * self.alpha\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        # Hidden is the final step state of this layers activity, output is all step states (including final)\n",
        "        # change for using bic code:\n",
        "\n",
        "        return output, hidden\n",
        "    def forward_helper_fpf(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "    def forward_helper_fpf_ICs(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "        output = []\n",
        "        hidden_s = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "            hidden_s.append(hidden)\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        hidden_tensor = torch.stack(hidden_s, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NBIC : Main Network"
      ],
      "metadata": {
        "id": "fXkIF_fseqNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnp-_hrR0jJk"
      },
      "outputs": [],
      "source": [
        "# class RNNNet(nn.Module):\n",
        "#     \"\"\"Full Network with a Leaky Recurrent Layer.\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: int, input size\n",
        "#         hidden_size: int, hidden size\n",
        "#         output_size: int, output size\n",
        "\n",
        "#     Inputs:\n",
        "#         x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "#     Outputs:\n",
        "#         out: tensor of shape (Seq Len, Batch, Output size)\n",
        "#         rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.num_layers = 1\n",
        "#         self.output_size = output_size\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         # Leaky RNN\n",
        "#         self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "#         # Add an output layer\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         rnn_output, _ = self.rnn(x)\n",
        "#         out = self.fc(rnn_output)\n",
        "#         return out, rnn_output\n",
        "\n",
        "#     def forward_for_fpf_ics(self, x):\n",
        "#       rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "#       out = self.fc(rnn_outputs)\n",
        "#       return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YuX48ckM6to"
      },
      "outputs": [],
      "source": [
        "class RNNNet(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # Leaky RNN\n",
        "        self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.all_layers = [self.fc]\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      for layer in self.all_layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "          init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "        if layer.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All BIC Model Defs"
      ],
      "metadata": {
        "id": "p2RmTXSnEC2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMMENTED OUT - DEFINING BIC NETWORKS (LAST UPDATE : 1507_7:07pm)"
      ],
      "metadata": {
        "id": "y83yaG_CEUks"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvZugrm2l4zd"
      },
      "source": [
        "## LeakyRNN Layer - No Self Connections, State,Output Separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70yOyEMH4wcI"
      },
      "outputs": [],
      "source": [
        "# # Leaky RNN with No Self connections\n",
        "# from torch.nn import functional as F\n",
        "\n",
        "# class LeakyRNN_NSC_MS(nn.Module):\n",
        "#     \"\"\"Leaky RNN No Self Connections and Maintained Unit State\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: Number of input neurons\n",
        "#         hidden_size: Number of hidden neurons\n",
        "#         dt: discretization time step in ms.\n",
        "#             If None, dt equals time constant tau\n",
        "\n",
        "#     Inputs:\n",
        "#         input: tensor of shape (seq_len, batch, input_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "#             if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "#     Outputs:\n",
        "#         output: tensor of shape (seq_len, batch, hidden_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, input_size, hidden_size, dt, tau=100, **kwargs): # dt is now required\n",
        "#         super().__init__()\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.tau = tau\n",
        "#         self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "#         self.batch_first = False # For fixed point finder\n",
        "#         # Check for stability\n",
        "#         if self.alpha > 1.0:\n",
        "#             print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0.\")\n",
        "\n",
        "#         # self.nsc_mask = self.create_no_self_conn_mask()\n",
        "#         mask = torch.ones(self.hidden_size, self.hidden_size) - torch.eye(self.hidden_size, self.hidden_size)\n",
        "#         self.register_buffer('nsc_mask', mask)\n",
        "#         self.input2h = nn.Linear(input_size, hidden_size)\n",
        "#         self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "#     def init_hidden(self, input):\n",
        "#       batch_size = input.shape[1]\n",
        "#       return (torch.zeros(batch_size, self.hidden_size).to(input.device), torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "\n",
        "\n",
        "#     def recurrence(self, input, hidden):\n",
        "#         \"\"\"Run network for one time step. (Now using a maintained internal state)\n",
        "\n",
        "#         Inputs:\n",
        "#             input: tensor of shape (batch, input_size)\n",
        "#             hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "#         Outputs:\n",
        "#             h_new: tensor of shape (batch, hidden_size),\n",
        "#                 network activity at the next time step\n",
        "#         \"\"\"\n",
        "\n",
        "#         state, output = hidden\n",
        "\n",
        "#         effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "\n",
        "#         recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "\n",
        "#         total_input = self.input2h(input) + recurrent_component\n",
        "#         state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "#         output = torch.relu(state)\n",
        "#         return state, output\n",
        "\n",
        "#     def forward(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "#         # If hidden activity is not provided, initialise it\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input)\n",
        "\n",
        "#         # Loop through time\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden[1])\n",
        "\n",
        "#         # Stack together output from all time steps\n",
        "#         output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "\n",
        "\n",
        "#         return output, hidden # Note, hidden is now tuple with: (final state, final output) which are (shape?) (previously it was just (final output))\n",
        "\n",
        "#     def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "#       state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "#       effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "#       recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "#       total_input = self.input2h(input) + recurrent_component\n",
        "#       state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "#       return state\n",
        "\n",
        "\n",
        "#     def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "#       if hidden_state_only is None:\n",
        "#           hidden_state_only = self.init_hidden(input)[1]\n",
        "#       elif isinstance(hidden_state_only, tuple):\n",
        "#           hidden_state_only = hidden_state_only[1]\n",
        "\n",
        "#       output = []\n",
        "#       steps = range(input.size(0))\n",
        "#       for i in steps:\n",
        "#           hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#           hidden_output = torch.relu(hidden_state_only)\n",
        "#           output.append(hidden_output)\n",
        "#       output = torch.stack(output, dim=0)\n",
        "#       return output, hidden_state_only\n",
        "\n",
        "#     def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "#         if hidden_state_only is None:\n",
        "#             hidden_state_only = self.init_hidden(input)[0]\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         hidden_state_only_list = []\n",
        "#         # hidden_state_only_list.append(hidden_state_only) # cause of alignment mismatch\n",
        "#         for i in steps:\n",
        "#             hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#             hidden_state_only_list.append(hidden_state_only)\n",
        "#             hidden_output = torch.relu(hidden_state_only)\n",
        "#             output.append(hidden_output)\n",
        "#         output = torch.stack(output, dim=0)\n",
        "#         hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "#         return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Wa-CszCOGDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5gF1ILNNUz-"
      },
      "outputs": [],
      "source": [
        "# # Leaky RNN with No Self connections\n",
        "# from torch.nn import functional as F\n",
        "\n",
        "# class LeakyRNN_NSC_MS(nn.Module):\n",
        "#     \"\"\"Leaky RNN No Self Connections and Maintained Unit State\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: Number of input neurons\n",
        "#         hidden_size: Number of hidden neurons\n",
        "#         dt: discretization time step in ms.\n",
        "#             If None, dt equals time constant tau\n",
        "\n",
        "#     Inputs:\n",
        "#         input: tensor of shape (seq_len, batch, input_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "#             if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "#     Outputs:\n",
        "#         output: tensor of shape (seq_len, batch, hidden_size)\n",
        "#         hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, input_size, hidden_size, dt, tau=100, **kwargs): # dt is now required\n",
        "#         super().__init__()\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.tau = tau\n",
        "#         self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "#         self.batch_first = False # For fixed point finder\n",
        "#         # Check for stability (/biological plausibility)\n",
        "#         if self.alpha > 1.0:\n",
        "#             print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0. This can lead to numerical instability.\")\n",
        "\n",
        "#         # self.nsc_mask = self.create_no_self_conn_mask()\n",
        "#         mask = torch.ones(self.hidden_size, self.hidden_size) - torch.eye(self.hidden_size, self.hidden_size)\n",
        "#         self.register_buffer('nsc_mask', mask)\n",
        "#         self.input2h = nn.Linear(input_size, hidden_size)\n",
        "#         self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "#         self.reset_parameters()\n",
        "\n",
        "\n",
        "#     def reset_parameters(self):\n",
        "#       # Initialise input-to-hidden layer with Kaiming Uniform\n",
        "#       init.kaiming_uniform_(self.input2h.weight, a=math.sqrt(5))\n",
        "#       if self.input2h.bias is not None:\n",
        "#           fan_in, _ = init._calculate_fan_in_and_fan_out(self.input2h.weight)\n",
        "#           bound = 1 / math.sqrt(fan_in)\n",
        "#           init.uniform_(self.input2h.bias, -bound, bound)\n",
        "\n",
        "#       # Initialise hidden-to-hidden layer with Orthogonal\n",
        "#       init.orthogonal_(self.h2h.weight)\n",
        "#       if self.h2h.bias is not None:\n",
        "#           fan_in, _ = init._calculate_fan_in_and_fan_out(self.h2h.weight)\n",
        "#           bound = 1 / math.sqrt(fan_in)\n",
        "#           init.uniform_(self.h2h.bias, -bound, bound)\n",
        "\n",
        "\n",
        "#     def init_hidden(self, input):\n",
        "#       batch_size = input.shape[1]\n",
        "#       return (torch.zeros(batch_size, self.hidden_size).to(input.device), torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "\n",
        "\n",
        "#     def recurrence(self, input, hidden):\n",
        "#         \"\"\"Run network for one time step. (Now using a maintained internal state)\n",
        "\n",
        "#         Inputs:\n",
        "#             input: tensor of shape (batch, input_size)\n",
        "#             hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "#         Outputs:\n",
        "#             h_new: tensor of shape (batch, hidden_size),\n",
        "#                 network activity at the next time step\n",
        "#         \"\"\"\n",
        "\n",
        "#         state, output = hidden\n",
        "\n",
        "#         effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "\n",
        "#         recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "\n",
        "#         total_input = self.input2h(input) + recurrent_component\n",
        "#         state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "#         output = torch.relu(state)\n",
        "#         return state, output\n",
        "\n",
        "#     def forward(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "#         # If hidden activity is not provided, initialise it\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input)\n",
        "\n",
        "#         # Loop through time\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden[1])\n",
        "\n",
        "#         # Stack together output from all time steps\n",
        "#         output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "\n",
        "\n",
        "#         return output, hidden # Note, hidden is now tuple with: (final state, final output) which are (shape?) (previously it was just (final output))\n",
        "\n",
        "#     def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "#       state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "#       effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "#       recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "#       total_input = self.input2h(input) + recurrent_component\n",
        "#       state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "#       return state\n",
        "\n",
        "\n",
        "#     def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "#       if hidden_state_only is None:\n",
        "#           hidden_state_only = self.init_hidden(input)[1]\n",
        "#       elif isinstance(hidden_state_only, tuple):\n",
        "#           hidden_state_only = hidden_state_only[1]\n",
        "\n",
        "#       output = []\n",
        "#       steps = range(input.size(0))\n",
        "#       for i in steps:\n",
        "#           hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#           hidden_output = torch.relu(hidden_state_only)\n",
        "#           output.append(hidden_output)\n",
        "#       output = torch.stack(output, dim=0)\n",
        "#       return output, hidden_state_only\n",
        "\n",
        "#     def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "#         if hidden_state_only is None:\n",
        "#             hidden_state_only = self.init_hidden(input)[0]\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         hidden_state_only_list = []\n",
        "#         # hidden_state_only_list.append(hidden_state_only)\n",
        "#         for i in steps:\n",
        "#             hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#             hidden_state_only_list.append(hidden_state_only)\n",
        "#             hidden_output = torch.relu(hidden_state_only)\n",
        "#             output.append(hidden_output)\n",
        "#         output = torch.stack(output, dim=0)\n",
        "#         hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "#         return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NSC : Main Network (s/o sep)"
      ],
      "metadata": {
        "id": "KOgxEAXjl4zg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGfTkthSexQp"
      },
      "outputs": [],
      "source": [
        "# class RNNNet_MS(nn.Module):\n",
        "#     \"\"\"Full Network with a Leaky Recurrent Layer. That uses the NSC and Maintained State version of the LRNN Layer\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: int, input size\n",
        "#         hidden_size: int, hidden size\n",
        "#         output_size: int, output size\n",
        "\n",
        "#     Inputs:\n",
        "#         x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "#     Outputs:\n",
        "#         out: tensor of shape (Seq Len, Batch, Output size)\n",
        "#         rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.num_layers = 1\n",
        "#         self.output_size = output_size\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         # Leaky RNN\n",
        "#         self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "#         # Add an output layer\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         rnn_output, _ = self.rnn(x)\n",
        "#         out = self.fc(rnn_output)\n",
        "#         return out, rnn_output # So this is actually unchanged except for the self.rnn = LeakyRNN_NSC_MS(..)\n",
        "\n",
        "\n",
        "#     def forward_for_fpf_ics(self, x):\n",
        "#       rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "#       out = self.fc(rnn_outputs)\n",
        "#       return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class RNNNet_MS(nn.Module):\n",
        "#     \"\"\"Full Network with a Leaky Recurrent Layer. That uses the NSC and Maintained State version of the LRNN Layer\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: int, input size\n",
        "#         hidden_size: int, hidden size\n",
        "#         output_size: int, output size\n",
        "\n",
        "#     Inputs:\n",
        "#         x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "#     Outputs:\n",
        "#         out: tensor of shape (Seq Len, Batch, Output size)\n",
        "#         rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.num_layers = 1\n",
        "#         self.output_size = output_size\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         # Leaky RNN\n",
        "#         self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "#         # Add an output layer\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "#         self.all_layers = [self.fc]\n",
        "#         self.reset_parameters()\n",
        "#     def forward(self, x):\n",
        "#         rnn_output, _ = self.rnn(x)\n",
        "#         out = self.fc(rnn_output)\n",
        "#         return out, rnn_output # So this is actually unchanged except for the self.rnn = LeakyRNN_NSC_MS(..)\n",
        "\n",
        "#     def reset_parameters(self):\n",
        "#       for layer in self.all_layers:\n",
        "#         if isinstance(layer, nn.Linear):\n",
        "#           init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "#         if layer.bias is not None:\n",
        "#           fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "#           bound = 1 / math.sqrt(fan_in)\n",
        "#           init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "#     def forward_for_fpf_ics(self, x):\n",
        "#       rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "#       out = self.fc(rnn_outputs)\n",
        "#       return out, rnn_outputs, hidden_state_tensor"
      ],
      "metadata": {
        "id": "AHjDhD80ON0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial Embedding with WD Penalty"
      ],
      "metadata": {
        "id": "W7cJa-Ime4Hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Approach - WD Regulariser Module (used in training with other network)"
      ],
      "metadata": {
        "id": "XgC5yYHBe7Ua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_ubcU_ZXsOZ"
      },
      "outputs": [],
      "source": [
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "# import scipy.spatial\n",
        "# class Reg_WD(torch.nn.Module):\n",
        "\n",
        "#     \"\"\"A regulariser for spatially embedded RNNs.\n",
        "#   Applies L1 regularisation to recurrent kernel of\n",
        "#   RNN which is weighted by the distance of units\n",
        "#   in predefined 3D space.\n",
        "#   Calculation:\n",
        "#       reg_WD * sum[distance_matrix o recurrent_kernel]\n",
        "#   Attributes:\n",
        "#       reg_WD: Float; Weighting of Reg_WD regularisation term.\n",
        "#       network_structure: Defines a 3D grid specifying the\n",
        "#       dimensions of a 3D space where neurons are placed.\n",
        "#       The tuple specifies the range of coordinates along\n",
        "#       each of the three axes in this 3D space.\n",
        "#   \"\"\"\n",
        "\n",
        "#     def __init__(self, reg_WD=0.01, neuron_num=64, network_structure=(4,4,4), coordinates_list=None, distance_power=1, distance_metric='euclidean'):\n",
        "#         super(Reg_WD, self).__init__()\n",
        "\n",
        "#         self.distance_power = distance_power\n",
        "#         self.reg_WD = torch.tensor([reg_WD], dtype=torch.float32)\n",
        "\n",
        "#         # Set up tensor with distance matrix\n",
        "#         nx = np.arange(network_structure[0])\n",
        "#         ny = np.arange(network_structure[1])\n",
        "#         nz = np.arange(network_structure[2])\n",
        "\n",
        "#         # Set up coordinate grid\n",
        "#         x, y, z = np.meshgrid(nx, ny, nz)\n",
        "#         self.coordinates = [x.ravel(), y.ravel(), z.ravel()]\n",
        "\n",
        "#         # Override coordinate grid if provided in init\n",
        "#         if coordinates_list is not None:\n",
        "#             self.coordinates = coordinates_list\n",
        "\n",
        "#         # Check neuron number / number of coordinates\n",
        "#         if (len(self.coordinates[0]) == neuron_num) and (len(self.coordinates[1]) == neuron_num) and (len(self.coordinates[2]) == neuron_num):\n",
        "#             pass\n",
        "#         else:\n",
        "#             raise ValueError('Network / coordinate structure does not match the number of neurons.')\n",
        "\n",
        "#         # Calculate the euclidean distance matrix\n",
        "#         euclidean_vector = scipy.spatial.distance.pdist(np.transpose(self.coordinates), metric=distance_metric)\n",
        "#         euclidean = scipy.spatial.distance.squareform(euclidean_vector ** self.distance_power)\n",
        "#         self.distance_matrix = torch.tensor(euclidean, dtype=torch.float32)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         abs_weight_matrix = torch.abs(x)\n",
        "#         WD_loss = self.reg_WD * torch.sum(abs_weight_matrix * self.distance_matrix)\n",
        "#         return WD_loss\n",
        "\n",
        "#     def _check_penalty_number(self, x):\n",
        "#         if not isinstance(x, (float, int)):\n",
        "#             raise ValueError(('Value: {} is not a valid regularization penalty number, '\n",
        "#                               'expected an int or float value').format(x))\n",
        "\n",
        "#     def visualise_distance_matrix(self):\n",
        "#         plt.imshow(self.distance_matrix.numpy())\n",
        "#         plt.colorbar()\n",
        "#         plt.show()\n",
        "\n",
        "#     def visualise_neuron_structure(self):\n",
        "#         fig = plt.figure()\n",
        "#         ax = Axes3D(fig)\n",
        "#         ax.scatter(self.coordinates[0], self.coordinates[1], self.coordinates[2], c='b', marker='.')\n",
        "#         ax.set_xlabel('x')\n",
        "#         ax.set_ylabel('y')\n",
        "#         ax.set_zlabel('z')\n",
        "#         plt.show()\n",
        "\n",
        "#     def get_config(self):\n",
        "#         return {'reg_WD': float(self.reg_WD)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2D Approach - SE_RNNNet (a Main Network)"
      ],
      "metadata": {
        "id": "Opd-aiUMe_wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCv2Tz1BxEZC"
      },
      "outputs": [],
      "source": [
        "# class SE_RNNNet(nn.Module):\n",
        "#     \"\"\"Full Network with a Leaky Recurrent Layer. (ALSO UPDATED FOR Maintained State Version)\n",
        "\n",
        "#     Parameters:\n",
        "#         input_size: int, input size\n",
        "#         hidden_size: int, hidden size\n",
        "#         output_size: int, output size\n",
        "\n",
        "#     Inputs:\n",
        "#         x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "#     Outputs:\n",
        "#         out: tensor of shape (Seq Len, Batch, Output size)\n",
        "#         rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_size, hidden_size, output_size, spatial_embedding_dim = 2 , **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.num_layers = 1\n",
        "#         self.output_size = output_size\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.ndim = spatial_embedding_dim\n",
        "#         self.spatial_embedding_arrangement = self.spatial_embedding()\n",
        "#         self.distance_matrix_computed = self.distance_matrix()\n",
        "#         # Leaky RNN\n",
        "#         # self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "#         self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "#         # Add an output layer\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "#     def spatial_embedding(self):\n",
        "#       len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "#       print(len_dimensions)\n",
        "#       spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "#       _unit = 0\n",
        "#       for i in range(len_dimensions):\n",
        "#         for j in range(len_dimensions):\n",
        "#           spatial_embedding_arrangement[i,j] = _unit\n",
        "#           _unit += 1\n",
        "#       return spatial_embedding_arrangement\n",
        "\n",
        "#     def distance_matrix(self):\n",
        "\n",
        "#       len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "#       spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "#       _unit = 0\n",
        "#       for i in range(len_dimensions):\n",
        "#         for j in range(len_dimensions):\n",
        "#           spatial_embedding_arrangement[i,j] = _unit\n",
        "#           _unit += 1\n",
        "\n",
        "#       distance_matrix = np.zeros((self.hidden_size, self.hidden_size))\n",
        "#       # distance matrix i_j = distance from i to j in the spatial embedding\n",
        "#       for i in range(self.hidden_size):\n",
        "#         [unit_i_location_x,unit_i_location_y] = np.where(spatial_embedding_arrangement == i)\n",
        "#         unit_i_location = np.array([unit_i_location_x,unit_i_location_y])\n",
        "#         for j in range(self.hidden_size):\n",
        "#           [unit_j_location_x,unit_j_location_y] = np.where(spatial_embedding_arrangement == j)\n",
        "#           unit_j_location = np.array([unit_j_location_x,unit_j_location_y])\n",
        "#           distance_matrix[i,j] = np.linalg.norm(unit_i_location - unit_j_location)\n",
        "#       return torch.from_numpy(distance_matrix.T).float() # For consistency as Pytorch .weights (for h2h linear) is arranged such that weight from i to j = W[j,i] #here are distance matrix is symmetric so doesnt matter but good for understanding\n",
        "\n",
        "#     def penalise_weight_distance(self):\n",
        "#       # Hidden Layer Weight Matrix\n",
        "#       weight_matrix_penalty = torch.abs(self.rnn.effective_h2h_weights)\n",
        "#       # Weight Distance elementwise product\n",
        "#       # wd_penalty_raw =  weight_matrix_penalty * torch.square(self.distance_matrix_computed)\n",
        "#       wd_penalty_raw =  weight_matrix_penalty * self.distance_matrix_computed # try L1\n",
        "#       L2_penalty_term = torch.sum(wd_penalty_raw)\n",
        "#       return L2_penalty_term\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         rnn_output, _ = self.rnn(x)\n",
        "#         out = self.fc(rnn_output)\n",
        "#         return out, rnn_output\n",
        "\n",
        "#     def forward_for_fpf_ics(self, x):\n",
        "#       rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "#       out = self.fc(rnn_outputs)\n",
        "#       return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function that accomodates wiring cost"
      ],
      "metadata": {
        "id": "1MgUxm5ufIf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(not used due to pre-training in dev notebook)"
      ],
      "metadata": {
        "id": "c-y1t9MufN_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZjW7nRYSVRa"
      },
      "outputs": [],
      "source": [
        "# import math\n",
        "# def training_with_early_stop_wiring(model, training_set, validation_set_dict, WD_approach = False, WD_regularizer=None, wiring_beta = 0.001, max_steps = 10000, min_validation_perf = 0.8, patience = 5, num_steps_for_early_stop_check = 500, num_validation_trials = 200, model_name = 'model_name', tr_output_mode = False):\n",
        "\n",
        "#       # validation_set_dict is like = {'Short': <neurogym dataset object> , ... }\n",
        "#       # training set is like <neurogym dataset object>\n",
        "\n",
        "#       # PERFORMANCE is each individual validation set accuracy\n",
        "#       # ACCURACY is the overall average of these\n",
        "#       # ES is for early stopping, i.e. perf/accuracy of validations that meet the es conditions (>threshold)\n",
        "#       # all is for all i.e. perf/accuracy of validations that haven't met the es conditions\n",
        "#       beta = wiring_beta\n",
        "#       output_size = model.output_size\n",
        "\n",
        "#       # we need to retain running loss / validation performances for plotting learning curves\n",
        "#       # Learning tracking\n",
        "#       # Training Loss Tracking\n",
        "#       tr_epochs_loss = []\n",
        "#       tr_loss = []\n",
        "\n",
        "#       # Validation Performance Tracking\n",
        "#       tr_epochs_valid_perf = []\n",
        "#       tr_valid_perfs_list_of_dicts = []\n",
        "#       tr_valid_perfs_avg = []\n",
        "#       n_steps_first_th = 0\n",
        "#       n_steps_final = 0\n",
        "\n",
        "#       # Setup\n",
        "#       optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
        "#       criterion = nn.CrossEntropyLoss()\n",
        "#       running_loss = 0\n",
        "#       running_task_loss = 0\n",
        "#       running_wiring_loss = 0\n",
        "#       running_acc = 0\n",
        "#       start_time = time.time()\n",
        "\n",
        "#       # Loop over training batches\n",
        "#       print('Training network...')\n",
        "\n",
        "#       current_best_valid_accuracy_es = 0.0\n",
        "#       current_best_valid_accuracy_all = 0.0\n",
        "\n",
        "\n",
        "#       # set best_valid_performance_es to a list of len n containing zeros where n is number of keys in validation_set_dict\n",
        "#       best_valid_performance_all = [0 for _ in validation_set_dict.keys()]\n",
        "#       best_valid_performance_es = [0 for _ in validation_set_dict.keys()]\n",
        "#       surpassed_threshold = False\n",
        "#       current_patience = patience\n",
        "#       model.train()\n",
        "#       model_save_name = f'{model_name}_best.pth'\n",
        "#       for i in range(max_steps):\n",
        "\n",
        "\n",
        "\n",
        "#           # Generate input and target, convert to pytorch tensor\n",
        "#           # inputs, labels = dataset()\n",
        "#           inputs, labels = training_set()\n",
        "#           inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "#           labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "#                   # boiler plate pytorch training:\n",
        "#           optimiser.zero_grad()   # zero the gradient buffers\n",
        "#           output, _ = model(inputs)\n",
        "#           # Reshape to (SeqLen x Batch, OutputSize)\n",
        "#           output = output.view(-1, output_size)\n",
        "\n",
        "#           task_loss = criterion(output, labels)\n",
        "\n",
        "#           if WD_approach:\n",
        "#             wiring_loss = WD_regularizer(model.rnn.effective_h2h_weights)\n",
        "#             loss = task_loss + wiring_loss\n",
        "\n",
        "#           else:\n",
        "#             wiring_loss = model.penalise_weight_distance()\n",
        "#             modified_wiring_loss = beta * wiring_loss\n",
        "#             loss = task_loss + modified_wiring_loss\n",
        "\n",
        "\n",
        "#           loss.backward()\n",
        "#           optimiser.step()    # Does the update\n",
        "#           # Print whats going on\n",
        "#           if (i == 0) or (i == 1):\n",
        "#             print(f'Initial Loss: {loss.item()}')\n",
        "#             print(f'Initial Task Loss: {task_loss.item()}')\n",
        "#             print(f'Initial Wiring Loss: {modified_wiring_loss.item()}') if not WD_approach else print(f'Initial Wiring Loss: {wiring_loss.item()}')\n",
        "\n",
        "#           running_loss += loss.item()\n",
        "#           running_task_loss += task_loss.item()\n",
        "#           running_wiring_loss = running_wiring_loss + modified_wiring_loss.item() if not WD_approach else running_wiring_loss + wiring_loss.item()\n",
        "#           if i % 100 == 99:\n",
        "#             running_loss /= 100\n",
        "#             running_task_loss /= 100\n",
        "#             running_wiring_loss /= 100\n",
        "#             print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "#                 i+1, running_loss, time.time() - start_time))\n",
        "#             print('Task Loss {:0.4f}, Wiring Loss {:0.4f}'.format(\n",
        "#                 running_task_loss, running_wiring_loss))\n",
        "#             tr_epochs_loss.append(i+1)\n",
        "#             tr_loss.append(running_loss)\n",
        "\n",
        "#             running_loss = 0\n",
        "#             running_task_loss = 0\n",
        "#             running_wiring_loss = 0\n",
        "#           if (i + 1) % num_steps_for_early_stop_check == 0:\n",
        "#             model.eval()\n",
        "#             with torch.no_grad():\n",
        "#               current_perf_dict = early_stop_validation(model, validation_set_dict, num_validation_trials)\n",
        "#               print(f'Current Performance Dict: {current_perf_dict}')\n",
        "#               list_avg_perfs = list(current_perf_dict.values())\n",
        "#               average_perf = np.mean(list_avg_perfs)\n",
        "\n",
        "#               tr_epochs_valid_perf.append(i+1)\n",
        "#               tr_valid_perfs_list_of_dicts.append(current_perf_dict) # Means we retain labels for performance scores for the plot\n",
        "#               tr_valid_perfs_avg.append(average_perf)\n",
        "\n",
        "#               print(f'Current Average Performance: {average_perf}')\n",
        "#               status_list = [i>min_validation_perf for i in list_avg_perfs]\n",
        "\n",
        "#               performance_th_list = [i>j for i,j in zip(list_avg_perfs, best_valid_performance_all)]\n",
        "\n",
        "#               best_valid_performance_all = list_avg_perfs if all(performance_th_list) else best_valid_performance_all\n",
        "\n",
        "#               current_best_valid_accuracy_all = average_perf if average_perf > current_best_valid_accuracy_all else current_best_valid_accuracy_all\n",
        "#               if all(status_list):\n",
        "#                 surpassed_threshold = True\n",
        "#                 n_steps_first_th = i+1\n",
        "#                 num_steps_for_early_stop_check = 100\n",
        "#                 if average_perf > current_best_valid_accuracy_es:\n",
        "#                   current_best_valid_accuracy_es = average_perf\n",
        "#                   best_valid_performance_es = list_avg_perfs\n",
        "#                   # create a file of current best model\n",
        "#                   torch.save(model.state_dict(), model_save_name)\n",
        "#                   # Reset patience\n",
        "#                   current_patience = patience\n",
        "#                 elif ((average_perf == current_best_valid_accuracy_es) and (current_patience > 0)):\n",
        "#                   current_best_valid_accuracy_es = average_perf\n",
        "#                   best_valid_performance_es = list_avg_perfs\n",
        "#                   # create a file of current best model\n",
        "#                   torch.save(model.state_dict(), model_save_name)\n",
        "#                   # Dont Reset patience, continue to decrease (model trains a bit more beyond first attempt at 100)\n",
        "#                   current_patience -= 1\n",
        "\n",
        "#                 else:\n",
        "#                   if current_patience <= 0:\n",
        "#                     n_steps_final = i+1\n",
        "#                     print('Early Stopping. I have run out of patience Grrr' )\n",
        "#                     break\n",
        "#                   else:\n",
        "#                     current_patience -= 1\n",
        "#             model.train()\n",
        "#       learning_curve_dict = {\n",
        "#             'training_loss_epochs_list': tr_epochs_loss,\n",
        "#             'training_loss_values_list' : tr_loss,\n",
        "#             'validation_perf_epochs_list': tr_epochs_valid_perf,\n",
        "#             'validation_perf_dicts_list' : tr_valid_perfs_list_of_dicts,\n",
        "#             'validation_perf_avg_values_list' : tr_valid_perfs_avg,\n",
        "#             'n_steps_first_th' : n_steps_first_th,\n",
        "#             'n_steps_final' : n_steps_final\n",
        "#               }\n",
        "#       # Try to Load best model from last saved file. Handle for if it doesn't exist!\n",
        "#       try:\n",
        "#         model.load_state_dict(torch.load(model_save_name))\n",
        "#         print('Best model loaded')\n",
        "#         # Print best performance stats\n",
        "#         for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_es):\n",
        "#           print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "#         if tr_output_mode:\n",
        "#           return model, learning_curve_dict\n",
        "\n",
        "#         return model\n",
        "#       except:\n",
        "#         print('No best model that satisfies validation threshold found')\n",
        "#         print(f'Best all time performance: {current_best_valid_accuracy_all}')\n",
        "#         for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_all):\n",
        "#           print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "#         if tr_output_mode:\n",
        "#           return model, learning_curve_dict\n",
        "\n",
        "#         return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E-I RNN"
      ],
      "metadata": {
        "id": "qQ8ROpFvfUdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Effective Weight Module"
      ],
      "metadata": {
        "id": "Ng4OLcsRfzfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liYep7yXTo7f"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.nn import init\n",
        "# from torch.nn import functional as F\n",
        "# import math\n",
        "\n",
        "\n",
        "# class EIRecLinear(nn.Module):\n",
        "\n",
        "#     \"\"\"Recurrent E-I Linear transformation.\n",
        "\n",
        "#     This module implements a linear transformation with recurrent E-I dynamics,\n",
        "#     where part of the units are excitatory and the rest are inhibitory.\n",
        "\n",
        "#     Args:\n",
        "#         hidden_size: int, the number of units in the layer.\n",
        "#         e_prop: float between 0 and 1, the proportion of excitatory units.\n",
        "#         bias: bool, if True, adds a learnable bias to the output.\n",
        "#     \"\"\"\n",
        "\n",
        "#     __constants__ = ['bias', 'hidden_size', 'e_prop']\n",
        "\n",
        "#     def __init__(self, hidden_size, e_prop, bias=True):\n",
        "#         super().__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.e_prop = e_prop\n",
        "#         self.e_size = int(e_prop * hidden_size) # Number of excitatory units\n",
        "#         self.i_size = hidden_size - self.e_size # Number of inhibitory units\n",
        "\n",
        "#         # Weight matrix for the recurrent connections\n",
        "#         self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "#         # Create a mask to define the E-I interactions\n",
        "#         # The mask has ones for E to E/I and negative ones for I to E/I, except the diagonal\n",
        "\n",
        "#         mask_no_diag = np.ones((self.hidden_size,self.hidden_size)) -  np.diag(np.ones((self.hidden_size)))\n",
        "\n",
        "#         E_I_unit_list = np.concatenate((np.ones((self.e_size,1)),-1*np.ones((self.i_size,1)))).T\n",
        "\n",
        "#         mask = mask_no_diag*E_I_unit_list\n",
        "#         # self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32))\n",
        "#         self.mask = torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "#         # Optionally add a bias term\n",
        "#         if bias:\n",
        "#             self.bias = nn.Parameter(torch.Tensor(hidden_size))\n",
        "#         else:\n",
        "#             self.register_parameter('bias', None)\n",
        "#         self.reset_parameters()\n",
        "\n",
        "#     def reset_parameters(self):\n",
        "#         # Initialise weights and biases\n",
        "#         init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "#         # Scale the weights for the excitatory neurons\n",
        "#         self.weight.data[:, :self.e_size] /= (self.e_size/self.i_size)\n",
        "\n",
        "#         # Initialise biases\n",
        "#         if self.bias is not None:\n",
        "#             fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "#             bound = 1 / math.sqrt(fan_in)\n",
        "#             init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "#     def effective_weight(self):\n",
        "#         # Apply the mask you have already created to the weights after applying rectification to get the effective weight\n",
        "#         # This ensures that weights from excitatory neurons are positive,\n",
        "#         # and weights from inhibitory neurons are negative.\n",
        "#         eff_W = F.relu(self.weight)*self.mask\n",
        "#         return eff_W\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         # Apply the linear transformation using the effective weights and biases\n",
        "#         # The weights used are non-negative due to the absolute value in effective_weight.\n",
        "#         return F.linear(input, self.effective_weight(), self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - RNN Layer"
      ],
      "metadata": {
        "id": "1b-feEuUf6HU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIVaftSaHatf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class EIRNN(nn.Module):\n",
        "#     \"\"\"E-I RNN.\n",
        "\n",
        "#     Reference:\n",
        "#         Song, H.F., Yang, G.R. and Wang, X.J., 2016.\n",
        "#         Training excitatory-inhibitory recurrent neural networks\n",
        "#         for cognitive tasks: a simple and flexible framework.\n",
        "#         PLoS computational biology, 12(2).\n",
        "\n",
        "#     Args:\n",
        "#         input_size: Number of input neurons\n",
        "#         hidden_size: Number of hidden neurons\n",
        "\n",
        "#     Inputs:\n",
        "#         input: (seq_len, batch, input_size)\n",
        "#         hidden: (batch, hidden_size)\n",
        "#         e_prop: float between 0 and 1, proportion of excitatory neurons\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, input_size, hidden_size, dt=None,\n",
        "#                  e_prop=0.8, sigma_rec=0, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.e_size = int(hidden_size * e_prop)\n",
        "#         self.i_size = hidden_size - self.e_size\n",
        "#         self.num_layers = 1\n",
        "#         self.tau = 100\n",
        "#         if dt is None:\n",
        "#             alpha = 1\n",
        "#         else:\n",
        "#             alpha = dt / self.tau\n",
        "#         self.alpha = alpha\n",
        "#         self.oneminusalpha = 1 - alpha\n",
        "#         # Recurrent noise parameter, scaled by the discretization (sqrt(2*alpha)) and noise level (sigma_rec)\n",
        "#         # This adds stochasticity to the recurrent dynamics, possibly simulating biological neural variability\n",
        "#         self._sigma_rec = np.sqrt(2*alpha) * sigma_rec\n",
        "\n",
        "#         self.input2h = nn.Linear(input_size, hidden_size)\n",
        "#         self.h2h = EIRecLinear(hidden_size, e_prop=0.8)\n",
        "\n",
        "#     def init_hidden(self, input):\n",
        "#         batch_size = input.shape[1]\n",
        "#         return (torch.zeros(batch_size, self.hidden_size).to(input.device),\n",
        "#                 torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "#     def recurrence(self, input, hidden):\n",
        "#         \"\"\"Recurrence helper.\"\"\"\n",
        "#         state, output = hidden\n",
        "#         total_input = self.input2h(input) + self.h2h(output)\n",
        "#         state = state * self.oneminusalpha + total_input * self.alpha\n",
        "#         state += self._sigma_rec * torch.randn_like(state)\n",
        "#         output = torch.relu(state)\n",
        "#         return state, output\n",
        "\n",
        "\n",
        "#     def forward(self, input, hidden=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "#         if hidden is None:\n",
        "#             hidden = self.init_hidden(input)\n",
        "\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden = self.recurrence(input[i], hidden)\n",
        "#             output.append(hidden[1])\n",
        "#         output = torch.stack(output, dim=0)\n",
        "#         return output, hidden\n",
        "\n",
        "\n",
        "#     def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "#         \"\"\"Recurrence helper.\"\"\"\n",
        "#         state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "#         total_input = self.input2h(input) + self.h2h(output)\n",
        "#         state = state * self.oneminusalpha + total_input * self.alpha\n",
        "#         state += self._sigma_rec * torch.randn_like(state)\n",
        "#         return state\n",
        "\n",
        "#     def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "#         if hidden_state_only is None:\n",
        "#             hidden_state_only = self.init_hidden(input)[0]\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         for i in steps:\n",
        "#             hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#             hidden_output = torch.relu(hidden_state_only)\n",
        "#             output.append(hidden_output)\n",
        "#         output = torch.stack(output, dim=0)\n",
        "#         return output, hidden_state_only\n",
        "#     def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "#         \"\"\"Propogate input through the network.\"\"\"\n",
        "#         if hidden_state_only is None:\n",
        "#             hidden_state_only = self.init_hidden(input)[0]\n",
        "#         output = []\n",
        "#         steps = range(input.size(0))\n",
        "#         hidden_state_only_list = []\n",
        "#         # hidden_state_only_list.append(hidden_state_only)\n",
        "#         for i in steps:\n",
        "#             hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "#             hidden_state_only_list.append(hidden_state_only)\n",
        "#             hidden_output = torch.relu(hidden_state_only)\n",
        "#             output.append(hidden_output)\n",
        "#         output = torch.stack(output, dim=0)\n",
        "#         hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "#         return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Main Network"
      ],
      "metadata": {
        "id": "AHau3cdef8VN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH6ZaJM_HZQV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class EINet(nn.Module):\n",
        "#     \"\"\"Recurrent network model.\n",
        "\n",
        "#     Args:\n",
        "#         input_size: int, input size\n",
        "#         hidden_size: int, hidden size\n",
        "#         output_size: int, output size\n",
        "#         rnn: str, type of RNN, lstm, rnn, ctrnn, or eirnn\n",
        "#     \"\"\"\n",
        "#     def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.output_size = output_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.input_size = input_size\n",
        "#         # Excitatory-inhibitory RNN\n",
        "#         self.rnn = EIRNN(input_size, hidden_size, **kwargs)\n",
        "#         self.fc = nn.Linear(self.rnn.e_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         rnn_activity, _ = self.rnn(x)\n",
        "#         rnn_e = rnn_activity[:, :, :self.rnn.e_size]\n",
        "#         out = self.fc(rnn_e)\n",
        "#         return out, rnn_activity\n",
        "\n",
        "#     def forward_for_fpf_ics(self, x):\n",
        "#         rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "#         rnn_e = rnn_outputs[:, :, :self.rnn.e_size]\n",
        "#         out = self.fc(rnn_e)\n",
        "#         return out, rnn_outputs, hidden_state_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xn6mvpsIPgyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINING BIC NETWORKS (LAST UPDATE : 2607_8:37pm)"
      ],
      "metadata": {
        "id": "vkaIr1JVPhPj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VEIZQq0PhPk"
      },
      "source": [
        "## LeakyRNN Layer - No Self Connections, State,Output Separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPb-BcLLPhPo"
      },
      "outputs": [],
      "source": [
        "# Leaky RNN with No Self connections\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class LeakyRNN_NSC_MS(nn.Module):\n",
        "    \"\"\"Leaky RNN No Self Connections and Maintained Unit State\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt, tau=100, **kwargs): # dt is now required\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "        self.batch_first = False # For fixed point finder\n",
        "        # Check for stability (/biological plausibility)\n",
        "        if self.alpha > 1.0:\n",
        "            print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0. This can lead to numerical instability.\")\n",
        "\n",
        "        # self.nsc_mask = self.create_no_self_conn_mask()\n",
        "        mask = torch.ones(self.hidden_size, self.hidden_size) - torch.eye(self.hidden_size, self.hidden_size)\n",
        "        self.register_buffer('nsc_mask', mask)\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      # Initialise input-to-hidden layer with Kaiming Uniform\n",
        "      init.kaiming_uniform_(self.input2h.weight, a=math.sqrt(5))\n",
        "      if self.input2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.input2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.input2h.bias, -bound, bound)\n",
        "\n",
        "      # Initialise hidden-to-hidden layer with Orthogonal\n",
        "      init.orthogonal_(self.h2h.weight)\n",
        "      if self.h2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.h2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.h2h.bias, -bound, bound)\n",
        "\n",
        "\n",
        "    def init_hidden(self, input):\n",
        "      batch_size = input.shape[1]\n",
        "      return (torch.zeros(batch_size, self.hidden_size).to(input.device), torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step. (Now using a maintained internal state)\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "\n",
        "        state, output = hidden\n",
        "\n",
        "        effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "\n",
        "        recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "\n",
        "        total_input = self.input2h(input) + recurrent_component\n",
        "        state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "        output = torch.relu(state)\n",
        "        return state, output\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden[1])\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "\n",
        "\n",
        "        return output, hidden # Note, hidden is now tuple with: (final state, final output) which are (shape?) (previously it was just (final output))\n",
        "\n",
        "    def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "      state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "      effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "      recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "      total_input = self.input2h(input) + recurrent_component\n",
        "      state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "      return state\n",
        "\n",
        "\n",
        "    def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "      if hidden_state_only is None:\n",
        "          hidden_state_only = self.init_hidden(input)[1]\n",
        "      elif isinstance(hidden_state_only, tuple):\n",
        "          hidden_state_only = hidden_state_only[1]\n",
        "\n",
        "      output = []\n",
        "      steps = range(input.size(0))\n",
        "      for i in steps:\n",
        "          hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "          hidden_output = torch.relu(hidden_state_only)\n",
        "          output.append(hidden_output)\n",
        "      output = torch.stack(output, dim=0)\n",
        "      return output, hidden_state_only\n",
        "\n",
        "    def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        hidden_state_only_list = []\n",
        "        # hidden_state_only_list.append(hidden_state_only)\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_state_only_list.append(hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "        return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NSC : Main Network (s/o sep)"
      ],
      "metadata": {
        "id": "cnthybp4PhPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrwNkJDHPhPq"
      },
      "outputs": [],
      "source": [
        "class RNNNet_MS(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer. That uses the NSC and Maintained State version of the LRNN Layer\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # Leaky RNN\n",
        "        self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.all_layers = [self.fc]\n",
        "        self.reset_parameters()\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output # So this is actually unchanged except for the self.rnn = LeakyRNN_NSC_MS(..)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      for layer in self.all_layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "          init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "        if layer.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial Embedding with WD Penalty"
      ],
      "metadata": {
        "id": "9wPY9SmMPhPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Approach - WD Regulariser Module (used in training with other network)"
      ],
      "metadata": {
        "id": "5HiXhBPjPhPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVZD-mb_PhPs"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import scipy.spatial\n",
        "class Reg_WD(torch.nn.Module):\n",
        "\n",
        "    \"\"\"A regulariser for spatially embedded RNNs.\n",
        "  Applies L1 regularisation to recurrent kernel of\n",
        "  RNN which is weighted by the distance of units\n",
        "  in predefined 3D space.\n",
        "  Calculation:\n",
        "      reg_WD * sum[distance_matrix o recurrent_kernel]\n",
        "  Attributes:\n",
        "      reg_WD: Float; Weighting of Reg_WD regularisation term.\n",
        "      network_structure: Defines a 3D grid specifying the\n",
        "      dimensions of a 3D space where neurons are placed.\n",
        "      The tuple specifies the range of coordinates along\n",
        "      each of the three axes in this 3D space.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, reg_WD=0.01, neuron_num=64, network_structure=(4,4,4), coordinates_list=None, distance_power=1, distance_metric='euclidean'):\n",
        "        super(Reg_WD, self).__init__()\n",
        "\n",
        "        self.distance_power = distance_power\n",
        "        self.reg_WD = torch.tensor([reg_WD], dtype=torch.float32)\n",
        "\n",
        "        # Set up tensor with distance matrix\n",
        "        nx = np.arange(network_structure[0])\n",
        "        ny = np.arange(network_structure[1])\n",
        "        nz = np.arange(network_structure[2])\n",
        "\n",
        "        # Set up coordinate grid\n",
        "        x, y, z = np.meshgrid(nx, ny, nz)\n",
        "        self.coordinates = [x.ravel(), y.ravel(), z.ravel()]\n",
        "\n",
        "        # Override coordinate grid if provided in init\n",
        "        if coordinates_list is not None:\n",
        "            self.coordinates = coordinates_list\n",
        "\n",
        "        # Check neuron number / number of coordinates\n",
        "        if (len(self.coordinates[0]) == neuron_num) and (len(self.coordinates[1]) == neuron_num) and (len(self.coordinates[2]) == neuron_num):\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError('Network / coordinate structure does not match the number of neurons.')\n",
        "\n",
        "        # Calculate the euclidean distance matrix\n",
        "        euclidean_vector = scipy.spatial.distance.pdist(np.transpose(self.coordinates), metric=distance_metric)\n",
        "        euclidean = scipy.spatial.distance.squareform(euclidean_vector ** self.distance_power)\n",
        "        self.distance_matrix = torch.tensor(euclidean, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, net):\n",
        "        eff_weight_matrix = net.rnn.h2h.weight * net.rnn.nsc_mask\n",
        "        abs_weight_matrix = torch.abs(eff_weight_matrix)\n",
        "        WD_loss = self.reg_WD * torch.sum(abs_weight_matrix * self.distance_matrix)\n",
        "        return WD_loss\n",
        "\n",
        "    def _check_penalty_number(self, x):\n",
        "        if not isinstance(x, (float, int)):\n",
        "            raise ValueError(('Value: {} is not a valid regularization penalty number, '\n",
        "                              'expected an int or float value').format(x))\n",
        "\n",
        "    def visualise_distance_matrix(self):\n",
        "        plt.imshow(self.distance_matrix.numpy())\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    def visualise_neuron_structure(self):\n",
        "        fig = plt.figure()\n",
        "        ax = Axes3D(fig)\n",
        "        ax.scatter(self.coordinates[0], self.coordinates[1], self.coordinates[2], c='b', marker='.')\n",
        "        ax.set_xlabel('x')\n",
        "        ax.set_ylabel('y')\n",
        "        ax.set_zlabel('z')\n",
        "        plt.show()\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'reg_WD': float(self.reg_WD)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2D Approach - SE_RNNNet (a Main Network)"
      ],
      "metadata": {
        "id": "_-3ORSE3PhPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Oa_xCNPhPv"
      },
      "outputs": [],
      "source": [
        "class SE_RNNNet(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer. (ALSO UPDATED FOR Maintained State Version)\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, spatial_embedding_dim = 2 , **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.ndim = spatial_embedding_dim\n",
        "        self.spatial_embedding_arrangement = self.spatial_embedding() # Renamed to avoid conflict with method name\n",
        "        self.distance_matrix_computed = self.distance_matrix() # Renamed to avoid conflict with method name\n",
        "        # Leaky RNN\n",
        "        # self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "        self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.all_layers = [self.fc]\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      for layer in self.all_layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "          init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "        if layer.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "    def spatial_embedding(self):\n",
        "      len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "      print(len_dimensions)\n",
        "      spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "      _unit = 0\n",
        "      for i in range(len_dimensions):\n",
        "        for j in range(len_dimensions):\n",
        "          spatial_embedding_arrangement[i,j] = _unit\n",
        "          _unit += 1\n",
        "      return spatial_embedding_arrangement\n",
        "\n",
        "    def distance_matrix(self):\n",
        "\n",
        "      len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "      spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "      _unit = 0\n",
        "      for i in range(len_dimensions):\n",
        "        for j in range(len_dimensions):\n",
        "          spatial_embedding_arrangement[i,j] = _unit\n",
        "          _unit += 1\n",
        "\n",
        "      distance_matrix = np.zeros((self.hidden_size, self.hidden_size))\n",
        "      # distance matrix i_j = distance from i to j in the spatial embedding\n",
        "      for i in range(self.hidden_size):\n",
        "        [unit_i_location_x,unit_i_location_y] = np.where(spatial_embedding_arrangement == i)\n",
        "        unit_i_location = np.array([unit_i_location_x,unit_i_location_y])\n",
        "        for j in range(self.hidden_size):\n",
        "          [unit_j_location_x,unit_j_location_y] = np.where(spatial_embedding_arrangement == j)\n",
        "          unit_j_location = np.array([unit_j_location_x,unit_j_location_y])\n",
        "          distance_matrix[i,j] = np.linalg.norm(unit_i_location - unit_j_location)\n",
        "      return torch.from_numpy(distance_matrix.T).float() # For consistency as Pytorch .weights (for h2h linear) is arranged such that weight from i to j = W[j,i] #here are distance matrix is symmetric so doesnt matter but good for understanding\n",
        "\n",
        "    def penalise_weight_distance(self):\n",
        "\n",
        "      # Hidden Layer Weight Matrix\n",
        "      # Effective Weight Matrix\n",
        "      eff_weight_matrix = self.rnn.h2h.weight * self.rnn.nsc_mask\n",
        "      weight_matrix_penalty = torch.abs(eff_weight_matrix)\n",
        "      # Weight Distance elementwise product\n",
        "      # wd_penalty_raw =  weight_matrix_penalty * torch.square(self.distance_matrix_computed)\n",
        "      wd_penalty_raw =  weight_matrix_penalty * self.distance_matrix_computed # try L1\n",
        "      L2_penalty_term = torch.sum(wd_penalty_raw)\n",
        "      return L2_penalty_term\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E-I RNN"
      ],
      "metadata": {
        "id": "CD8CAu52PhPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Effective Weight Module"
      ],
      "metadata": {
        "id": "fZ9WGwQAPhPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_Itiwt4PhP0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class EIRecLinear(nn.Module):\n",
        "\n",
        "    \"\"\"Recurrent E-I Linear transformation.\n",
        "\n",
        "    This module implements a linear transformation with recurrent E-I dynamics,\n",
        "    where part of the units are excitatory and the rest are inhibitory.\n",
        "\n",
        "    Args:\n",
        "        hidden_size: int, the number of units in the layer.\n",
        "        e_prop: float between 0 and 1, the proportion of excitatory units.\n",
        "        bias: bool, if True, adds a learnable bias to the output.\n",
        "    \"\"\"\n",
        "\n",
        "    __constants__ = ['bias', 'hidden_size', 'e_prop']\n",
        "\n",
        "    def __init__(self, hidden_size, e_prop, bias=True):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.e_prop = e_prop\n",
        "        self.e_size = int(e_prop * hidden_size) # Number of excitatory units\n",
        "        self.i_size = hidden_size - self.e_size # Number of inhibitory units\n",
        "\n",
        "        # Weight matrix for the recurrent connections\n",
        "        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "        # Create a mask to define the E-I interactions\n",
        "        # The mask has ones for E to E/I and negative ones for I to E/I, except the diagonal\n",
        "\n",
        "        mask_no_diag = np.ones((self.hidden_size,self.hidden_size)) -  np.diag(np.ones((self.hidden_size)))\n",
        "\n",
        "        E_I_unit_list = np.concatenate((np.ones((self.e_size,1)),-1*np.ones((self.i_size,1)))).T\n",
        "\n",
        "        mask = mask_no_diag*E_I_unit_list\n",
        "        # self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32))\n",
        "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "        # Optionally add a bias term\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialise weights and biases\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        # Scale the weights for the excitatory neurons\n",
        "        self.weight.data[:, :self.e_size] /= (self.e_size/self.i_size)\n",
        "\n",
        "        # Initialise biases\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def effective_weight(self):\n",
        "        # Apply the mask you have already created to the weights after applying rectification to get the effective weight\n",
        "        # This ensures that weights from excitatory neurons are positive,\n",
        "        # and weights from inhibitory neurons are negative.\n",
        "        eff_W = F.relu(self.weight)*self.mask\n",
        "        return eff_W\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Apply the linear transformation using the effective weights and biases\n",
        "        # The weights used are non-negative due to the absolute value in effective_weight.\n",
        "        return F.linear(input, self.effective_weight(), self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - RNN Layer"
      ],
      "metadata": {
        "id": "wwOVoOajPhP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OoRUbeUPhP0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EIRNN(nn.Module):\n",
        "    \"\"\"E-I RNN.\n",
        "\n",
        "    Reference:\n",
        "        Song, H.F., Yang, G.R. and Wang, X.J., 2016.\n",
        "        Training excitatory-inhibitory recurrent neural networks\n",
        "        for cognitive tasks: a simple and flexible framework.\n",
        "        PLoS computational biology, 12(2).\n",
        "\n",
        "    Args:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "\n",
        "    Inputs:\n",
        "        input: (seq_len, batch, input_size)\n",
        "        hidden: (batch, hidden_size)\n",
        "        e_prop: float between 0 and 1, proportion of excitatory neurons\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=None,\n",
        "                 e_prop=0.8, sigma_rec=0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.e_size = int(hidden_size * e_prop)\n",
        "        self.i_size = hidden_size - self.e_size\n",
        "        self.num_layers = 1\n",
        "        self.tau = 100\n",
        "        if dt is None:\n",
        "            alpha = 1\n",
        "        else:\n",
        "            alpha = dt / self.tau\n",
        "        self.alpha = alpha\n",
        "        self.oneminusalpha = 1 - alpha\n",
        "        # Recurrent noise parameter, scaled by the discretization (sqrt(2*alpha)) and noise level (sigma_rec)\n",
        "        # This adds stochasticity to the recurrent dynamics, possibly simulating biological neural variability\n",
        "        self._sigma_rec = np.sqrt(2*alpha) * sigma_rec\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = EIRecLinear(hidden_size, e_prop=0.8)\n",
        "\n",
        "    def init_hidden(self, input):\n",
        "        batch_size = input.shape[1]\n",
        "        return (torch.zeros(batch_size, self.hidden_size).to(input.device),\n",
        "                torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Recurrence helper.\"\"\"\n",
        "        state, output = hidden\n",
        "        total_input = self.input2h(input) + self.h2h(output)\n",
        "        state = state * self.oneminusalpha + total_input * self.alpha\n",
        "        state += self._sigma_rec * torch.randn_like(state)\n",
        "        output = torch.relu(state)\n",
        "        return state, output\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input)\n",
        "\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden[1])\n",
        "        output = torch.stack(output, dim=0)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "    def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "        \"\"\"Recurrence helper.\"\"\"\n",
        "        state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "        total_input = self.input2h(input) + self.h2h(output)\n",
        "        state = state * self.oneminusalpha + total_input * self.alpha\n",
        "        state += self._sigma_rec * torch.randn_like(state)\n",
        "        return state\n",
        "\n",
        "    def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        return output, hidden_state_only\n",
        "    def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        hidden_state_only_list = []\n",
        "        # hidden_state_only_list.append(hidden_state_only)\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_state_only_list.append(hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "        return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Main Network"
      ],
      "metadata": {
        "id": "vhhKpfy4PhP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGpyKlhMPhP1"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EINet(nn.Module):\n",
        "    \"\"\"Recurrent network model.\n",
        "\n",
        "    Args:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "        rnn: str, type of RNN, lstm, rnn, ctrnn, or eirnn\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        # Excitatory-inhibitory RNN\n",
        "        self.rnn = EIRNN(input_size, hidden_size, **kwargs)\n",
        "        self.fc = nn.Linear(self.rnn.e_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_activity, _ = self.rnn(x)\n",
        "        rnn_e = rnn_activity[:, :, :self.rnn.e_size]\n",
        "        out = self.fc(rnn_e)\n",
        "        return out, rnn_activity\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "        rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "        rnn_e = rnn_outputs[:, :, :self.rnn.e_size]\n",
        "        out = self.fc(rnn_e)\n",
        "        return out, rnn_outputs, hidden_state_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialising for BIC Networks"
      ],
      "metadata": {
        "id": "wfk6ZruZdaiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting From Pretrained // TRAINING"
      ],
      "metadata": {
        "id": "-fNC_ly7d1zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training for LRNN_NBIC"
      ],
      "metadata": {
        "id": "6o0u8SqbZMN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### SHARED ACROSS TRAINING VALID TEST\n",
        "timestep = 50 #ms\n",
        "noise = 1.0\n",
        "batch_size = 64\n",
        "\n",
        "# Assign Timing for each task period (same as default but enables calculation of sequence length)\n",
        "timing_valid_s = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': 300,\n",
        "            'decision': 900}\n",
        "timing_valid_m = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': 500,\n",
        "            'decision': 900}\n",
        "timing_valid_l = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': 900,\n",
        "            'decision': 900}\n",
        "\n",
        "timing_valid_ll = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': 1000,\n",
        "            'decision': 900}\n",
        "\n",
        "timing_training = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': ('choice', (300, 400, 500, 600, 700, 800, 900)),\n",
        "            'decision': 900}\n",
        "\n",
        "# Assign Time step size and calculate sequence length of a full trial\n",
        "# Short\n",
        "trial_time_s = sum(timing_valid_s.values()) #ms\n",
        "seq_len_valid_s = int(trial_time_s/timestep)\n",
        "# Medium\n",
        "trial_time_m = sum(timing_valid_m.values()) #ms\n",
        "seq_len_valid_m = int(trial_time_m/timestep)\n",
        "# Long\n",
        "trial_time_l = sum(timing_valid_l.values()) #ms\n",
        "seq_len_valid_l = int(trial_time_l/timestep)\n",
        "# X-Long\n",
        "trial_time_ll = sum(timing_valid_ll.values()) #ms\n",
        "seq_len_valid_ll = int(trial_time_ll/timestep)\n",
        "\n",
        "task_name = 'PerceptualDecisionMaking-v0'\n",
        "\n",
        "stim_scale=1.0\n",
        "PDM_cohs = np.array([0.5, 6.4, 12.8, 25.6, 51.2])\n",
        "# ensure changed the cohs assignment logic in the package first\n",
        "PDM_cohs *= stim_scale\n",
        "PDM_cohs = PDM_cohs.tolist()\n",
        "\n",
        "kwargs_valid_s = {'dt' : timestep, 'timing': timing_valid_s, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "kwargs_valid_m = {'dt' : timestep, 'timing': timing_valid_m, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "kwargs_valid_l = {'dt' : timestep, 'timing': timing_valid_l, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "kwargs_valid_ll = {'dt' : timestep, 'timing': timing_valid_ll, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "kwargs_training = {'dt' : timestep, 'timing': timing_training, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "\n",
        "dataset_valid_s = ngym.Dataset(task_name, env_kwargs=kwargs_valid_s, batch_size=batch_size, seq_len=seq_len_valid_s)\n",
        "dataset_valid_m = ngym.Dataset(task_name, env_kwargs=kwargs_valid_m, batch_size=batch_size, seq_len=seq_len_valid_m)\n",
        "dataset_valid_l = ngym.Dataset(task_name, env_kwargs=kwargs_valid_l, batch_size=batch_size, seq_len=seq_len_valid_l)\n",
        "dataset_valid_ll = ngym.Dataset(task_name, env_kwargs=kwargs_valid_ll, batch_size=batch_size, seq_len=seq_len_valid_ll)\n",
        "dataset_training = ngym.Dataset(task_name, env_kwargs=kwargs_training, batch_size=batch_size, seq_len=124)\n",
        "\n",
        "validation_set_dictionary = {\n",
        "    'Short': dataset_valid_s,\n",
        "    'Medium': dataset_valid_m,\n",
        "    'Long': dataset_valid_l,\n",
        "    'UnseenLong' : dataset_valid_ll\n",
        "}"
      ],
      "metadata": {
        "id": "CUO18YpGHwRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-NBIC from .pth / TRAINING"
      ],
      "metadata": {
        "id": "WnmK7O0pgNve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Parameters\n",
        "hidden_size_NBIC = 64\n",
        "input_size_NBIC = 3\n",
        "output_size_NBIC = 3\n",
        "dt_NBIC = 50\n",
        "tau_NBIC = 100\n",
        "# Initialising base model\n",
        "LRNN_NBIC = RNNNet(input_size=input_size_NBIC, hidden_size = hidden_size_NBIC, output_size = output_size_NBIC, dt=dt_NBIC, tau=tau_NBIC)\n",
        "MODEL_IO_NBIC = True\n",
        "if MODEL_IO_NBIC:\n",
        "  LRNN_NBIC_TRAINED = LRNN_NBIC\n",
        "  LRNN_NBIC_TRAINED.load_state_dict(torch.load('PDM_LRNN_NBIC/LRNN_NBIC.pth'))\n",
        "  LRNN_NBIC_TRAINED.eval()\n",
        "else:\n",
        "  # consider like:\n",
        "  LRNN_NBIC_TRAINED, LRNN_NBIC_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_NBIC,\n",
        "    training_set = dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=False,\n",
        "    activity_beta=0.1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_NBIC',\n",
        "    tr_output_mode=True\n",
        "    )\n",
        "  plot_learning_curve(LRNN_NBIC_learning_curve_info, average_only=True, filename='PDM_LRNN_NBIC/learning_curve_avg.png', show_legend=True, legend_location='center right')\n",
        "  plot_learning_curve(LRNN_NBIC_learning_curve_info, average_only=False, filename='PDM_LRNN_NBIC/learning_curve_all.png', show_legend=True, legend_location='center right')\n"
      ],
      "metadata": {
        "id": "9KnZin-NlhJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-NSC from .pth / TRAINING"
      ],
      "metadata": {
        "id": "2vOEJwF6tPD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialising Parameters\n",
        "hidden_size_NSC = 64\n",
        "input_size_NSC = 3\n",
        "output_size_NSC = 3\n",
        "dt_NSC = 50\n",
        "tau_NSC = 100\n",
        "# Initialising base model\n",
        "LRNN_NSC = RNNNet_MS(input_size=input_size_NSC, hidden_size = hidden_size_NSC, output_size = output_size_NSC, dt=dt_NSC, tau=tau_NSC)\n",
        "MODEL_IO_NSC = True\n",
        "if MODEL_IO_NSC:\n",
        "  LRNN_NSC_TRAINED = LRNN_NSC\n",
        "  # LRNN_NSC_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/NSC_LRNN_MODEL.pth'))\n",
        "  LRNN_NSC_TRAINED.load_state_dict(torch.load('PDM_LRNN_NSC/LRNN_NSC.pth'))\n",
        "  LRNN_NSC_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_NSC_TRAINED, LRNN_NSC_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_NSC,\n",
        "    training_set = dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_NSC',\n",
        "    tr_output_mode=True)\n",
        "  # plot_learning_curve(LRNN_NSC_learning_curve_info, average_only=False, filename='PDM_LRNN_NSC/learning_curve_all.png', show_legend=True, legend_location='lower left') # if using 10 x non task loss\n",
        "  # plot_learning_curve(LRNN_NSC_learning_curve_info, average_only= True, filename='PDM_LRNN_NSC/learning_curve_avg.png', show_legend=True, legend_location='lower left')\n",
        "  plot_learning_curve(LRNN_NSC_learning_curve_info, average_only=False, filename='PDM_LRNN_NSC/learning_curve_all.png', show_legend=True, legend_location='center left') # otherwise\n",
        "  plot_learning_curve(LRNN_NSC_learning_curve_info, average_only= True, filename='PDM_LRNN_NSC/learning_curve_avg.png', show_legend=True, legend_location='center left')"
      ],
      "metadata": {
        "id": "97qmkGhntSpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-SE2D from .pth // TRAINING"
      ],
      "metadata": {
        "id": "Ifauvm6ZtXzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialising LRNN-SE2D from .pth\n",
        "\n",
        "# Initialising Parameters\n",
        "hidden_size_SE2D = 64\n",
        "input_size_SE2D = 3\n",
        "output_size_SE2D = 3\n",
        "dt_SE2D = 50\n",
        "tau_SE2D = 100\n",
        "# Initialising base model\n",
        "LRNN_SE2D = SE_RNNNet(input_size=input_size_SE2D, hidden_size = hidden_size_SE2D, output_size = output_size_SE2D, dt=dt_SE2D, tau=tau_SE2D)\n",
        "MODEL_IO_SE2D = True\n",
        "if MODEL_IO_SE2D:\n",
        "  LRNN_SE2D_TRAINED = LRNN_SE2D\n",
        "  # LRNN_SE2D_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/SE2D_LRNN_MODEL.pth'))\n",
        "  LRNN_SE2D_TRAINED.load_state_dict(torch.load('PDM_LRNN_SE2D/LRNN_SE2D.pth'))\n",
        "  LRNN_SE2D_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_SE2D_TRAINED, LRNN_SE2D_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_SE2D,\n",
        "    training_set = dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.0001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_SE2D',\n",
        "    tr_output_mode=True)\n",
        "\n",
        "  plot_learning_curve(LRNN_SE2D_learning_curve_info, average_only=False, filename='PDM_LRNN_SE2D/learning_curve_all.png', show_legend=True, legend_location='best')\n",
        "  plot_learning_curve(LRNN_SE2D_learning_curve_info, average_only=True, filename='PDM_LRNN_SE2D/learning_curve_avg.png', show_legend=True, legend_location='best')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkawet5LtbuE",
        "outputId": "88e2ee88-9c48-48c0-f917-13c3199222a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-SE3D from .pth file // TRAINING"
      ],
      "metadata": {
        "id": "8jGqJelFtjNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialising LRNN-SE3D from .pth\n",
        "\n",
        "# Initialising Parameters\n",
        "hidden_size_SE3D = 64\n",
        "input_size_SE3D = 3\n",
        "output_size_SE3D = 3\n",
        "dt_SE3D = 50\n",
        "tau_SE3D = 100\n",
        "# Initialising base model\n",
        "LRNN_SE3D = RNNNet_MS(input_size=input_size_SE3D, hidden_size = hidden_size_SE3D, output_size = output_size_SE3D, dt=dt_SE3D, tau=tau_SE3D)\n"
      ],
      "metadata": {
        "id": "ukardYjGtnMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WD_regulariser = Reg_WD(reg_WD=0.00001, neuron_num=64, network_structure=(4,4,4))"
      ],
      "metadata": {
        "id": "iNz74RYkaXBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_IO_SE3D = True\n",
        "if MODEL_IO_SE3D:\n",
        "  LRNN_SE3D_TRAINED = LRNN_SE3D\n",
        "  # LRNN_SE3D_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/SE3D_LRNN_MODEL.pth'))\n",
        "  LRNN_SE3D_TRAINED.load_state_dict(torch.load('PDM_LRNN_SE3D/LRNN_SE3D.pth'))\n",
        "  LRNN_SE3D_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_SE3D_TRAINED, LRNN_SE3D_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_SE3D,\n",
        "    training_set = dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=True,\n",
        "    WD_regulariser=WD_regulariser,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=0.1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_SE3D',\n",
        "    tr_output_mode=True)\n",
        "  plot_learning_curve(LRNN_SE3D_learning_curve_info, average_only=False, filename='PDM_LRNN_SE3D/learning_curve_all.png', show_legend=True, legend_location='best')\n",
        "  plot_learning_curve(LRNN_SE3D_learning_curve_info, average_only=True, filename='PDM_LRNN_SE3D/learning_curve_avg.png', show_legend=True, legend_location='best')"
      ],
      "metadata": {
        "id": "jryfb6jcQfje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-EI from .pth file // TRAINING"
      ],
      "metadata": {
        "id": "vJm16OJluBuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialising LRNN-EI from .pth\n",
        "\n",
        "# Initialising Parameters\n",
        "hidden_size_EI = 64\n",
        "input_size_EI = 3\n",
        "output_size_EI = 3\n",
        "dt_EI = 50\n",
        "tau_EI = 100\n",
        "# Initialising base model\n",
        "LRNN_EI = EINet(input_size=input_size_EI, hidden_size = hidden_size_EI, output_size = output_size_EI, dt=dt_EI, tau=tau_EI)\n",
        "MODEL_IO_EI = True\n",
        "if MODEL_IO_EI:\n",
        "  LRNN_EI_TRAINED = LRNN_EI\n",
        "  # LRNN_EI_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/EI_LRNN_MODEL.pth'))\n",
        "  LRNN_EI_TRAINED.load_state_dict(torch.load('PDM_LRNN_EI/LRNN_EI.pth'))\n",
        "  LRNN_EI_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_EI_TRAINED, LRNN_EI_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_EI,\n",
        "    training_set = dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_EI',\n",
        "    tr_output_mode=True)\n",
        "  plot_learning_curve(LRNN_EI_learning_curve_info, average_only=False, filename='PDM_LRNN_EI/learning_curve_all.png', show_legend=True, legend_location='lower right')\n",
        "  plot_learning_curve(LRNN_EI_learning_curve_info, average_only=True, filename='PDM_LRNN_EI/learning_curve_avg.png', show_legend=True, legend_location='lower right')\n"
      ],
      "metadata": {
        "id": "mHlqMO2EuEG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Testing"
      ],
      "metadata": {
        "id": "oRZcQyaVrBdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising Testing Dataset"
      ],
      "metadata": {
        "id": "DBVY3jxsrEqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset for testing\n",
        "# Using Unseen 'delay' at 1100 : extrapolation on delay time period -> memory?\n",
        "timing_testing = {\n",
        "            'fixation': 300,\n",
        "            'stimulus': 500,\n",
        "            'delay': 1100,\n",
        "            'decision': 900}\n",
        "# just using 1 (median) coherence for testing # and no noise\n",
        "PDM_cohs = np.array([12.8])\n",
        "PDM_cohs *= stim_scale\n",
        "PDM_cohs = PDM_cohs.tolist()\n",
        "timestep = 50\n",
        "noise = 0.0 # Consider setting to 0\n",
        "batch_size = 64 # Consistent with training (dont think it has that much of an effect due to .new_trial)\n",
        "# Testing Trials\n",
        "trial_time_testing = sum(timing_testing.values()) #ms\n",
        "seq_len_testing = int(trial_time_testing/timestep)\n",
        "\n",
        "task_name = 'PerceptualDecisionMaking-v0'\n",
        "\n",
        "\n",
        "kwargs_testing = {'dt' : timestep, 'timing': timing_testing, 'sigma': noise, 'cohs': PDM_cohs}\n",
        "\n",
        "dataset_testing = ngym.Dataset(task_name, env_kwargs=kwargs_testing, batch_size=batch_size, seq_len=seq_len_testing)"
      ],
      "metadata": {
        "id": "AVld-yNorEVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Testing for Each Network"
      ],
      "metadata": {
        "id": "nzdORMbDriBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for all LRNN"
      ],
      "metadata": {
        "id": "3U-jRlj2roUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_full_testing_data = bic_testing_w_state_tracking(LRNN_NBIC_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "id": "3lzJIqyNrkdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1929ab9d-eb40-4682-bfc7-f5a1c3992fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NSC_full_testing_data = bic_testing_w_state_tracking(LRNN_NSC_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6OmQ6M7twMr",
        "outputId": "ea3578c8-5825-4de9-cb46-dc81638d4c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE2D_full_testing_data = bic_testing_w_state_tracking(LRNN_SE2D_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPG4nXn_t6F4",
        "outputId": "30f03579-3b20-4c50-f05a-3302d3561c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE3D_full_testing_data = bic_testing_w_state_tracking(LRNN_SE3D_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wHfEUXMt9ee",
        "outputId": "3b24610d-3a8a-4fc8-dc18-d2cdc4aa7606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_EI_full_testing_data = bic_testing_w_state_tracking(LRNN_EI_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX8yI8GduQgu",
        "outputId": "a63eb396-2882-46ca-8dab-71211a960977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Data Partitioning for Each Network's Testing Data"
      ],
      "metadata": {
        "id": "fI92cs44xkRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - NBIC"
      ],
      "metadata": {
        "id": "cDQALmGYxpfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "cond_dict_correct = {\n",
        "    'network_correct' : True\n",
        "}\n",
        "cond_dict_incorrect = {\n",
        "    'network_correct' : False\n",
        "}\n",
        "\n",
        "# trial_activity_stim1>stim2\n",
        "cond_dict_stim1 = {\n",
        "    'ground_truth' : 1\n",
        "}\n",
        "\n",
        "LRNN_NBIC_full_testing_data_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NBIC_testing_data_stim1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, cond_dict_stim1, return_like_full=True)\n",
        "\n",
        "LRNN_NBIC_testing_data_stim1_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim1, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NBIC_testing_data_stim1_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim1, cond_dict_incorrect, return_like_full=True)\n",
        "\n",
        "# trial_activity_stim2>21\n",
        "\n",
        "cond_dict_stim2 = {\n",
        "    'ground_truth' : 2\n",
        "}\n",
        "LRNN_NBIC_testing_data_stim2 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, cond_dict_stim2, return_like_full=True)\n",
        "\n",
        "LRNN_NBIC_testing_data_stim2_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim2, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NBIC_testing_data_stim2_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim2, cond_dict_incorrect, return_like_full=True)"
      ],
      "metadata": {
        "id": "eIOm7xDI1j28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - NSC"
      ],
      "metadata": {
        "id": "YEPxnYk0ucC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Partitioning LRNN - NSC\n",
        "\n",
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "cond_dict_correct = {\n",
        "    'network_correct' : True\n",
        "}\n",
        "cond_dict_incorrect = {\n",
        "    'network_correct' : False\n",
        "}\n",
        "\n",
        "# trial_activity_stim1>stim2\n",
        "cond_dict_stim1 = {\n",
        "    'ground_truth' : 1\n",
        "}\n",
        "\n",
        "LRNN_NSC_full_testing_data_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NSC_testing_data_stim1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, cond_dict_stim1, return_like_full=True)\n",
        "\n",
        "LRNN_NSC_testing_data_stim1_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim1, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NSC_testing_data_stim1_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim1, cond_dict_incorrect, return_like_full=True)\n",
        "\n",
        "# trial_activity_stim2>21\n",
        "\n",
        "cond_dict_stim2 = {\n",
        "    'ground_truth' : 2\n",
        "}\n",
        "LRNN_NSC_testing_data_stim2 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, cond_dict_stim2, return_like_full=True)\n",
        "\n",
        "LRNN_NSC_testing_data_stim2_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim2, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_NSC_testing_data_stim2_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim2, cond_dict_incorrect, return_like_full=True)"
      ],
      "metadata": {
        "id": "pk_-QGeAugZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - SE2D"
      ],
      "metadata": {
        "id": "Yw2L_-SsugfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Partitioning LRNN - SE2D\n",
        "\n",
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "cond_dict_correct = {\n",
        "    'network_correct' : True\n",
        "}\n",
        "cond_dict_incorrect = {\n",
        "    'network_correct' : False\n",
        "}\n",
        "\n",
        "# trial_activity_stim1>stim2\n",
        "cond_dict_stim1 = {\n",
        "    'ground_truth' : 1\n",
        "}\n",
        "\n",
        "LRNN_SE2D_full_testing_data_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE2D_testing_data_stim1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, cond_dict_stim1, return_like_full=True)\n",
        "\n",
        "LRNN_SE2D_testing_data_stim1_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim1, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE2D_testing_data_stim1_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim1, cond_dict_incorrect, return_like_full=True)\n",
        "\n",
        "# trial_activity_stim2>21\n",
        "\n",
        "cond_dict_stim2 = {\n",
        "    'ground_truth' : 2\n",
        "}\n",
        "LRNN_SE2D_testing_data_stim2 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, cond_dict_stim2, return_like_full=True)\n",
        "\n",
        "LRNN_SE2D_testing_data_stim2_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim2, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE2D_testing_data_stim2_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim2, cond_dict_incorrect, return_like_full=True)"
      ],
      "metadata": {
        "id": "gyZXnSrBup0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - SE3D"
      ],
      "metadata": {
        "id": "DhvczSxsugsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Partitioning LRNN - SE3D\n",
        "\n",
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "cond_dict_correct = {\n",
        "    'network_correct' : True\n",
        "}\n",
        "cond_dict_incorrect = {\n",
        "    'network_correct' : False\n",
        "}\n",
        "\n",
        "# trial_activity_stim1>stim2\n",
        "cond_dict_stim1 = {\n",
        "    'ground_truth' : 1\n",
        "}\n",
        "\n",
        "LRNN_SE3D_full_testing_data_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE3D_testing_data_stim1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, cond_dict_stim1, return_like_full=True)\n",
        "\n",
        "LRNN_SE3D_testing_data_stim1_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim1, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE3D_testing_data_stim1_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim1, cond_dict_incorrect, return_like_full=True)\n",
        "\n",
        "# trial_activity_stim2>21\n",
        "\n",
        "cond_dict_stim2 = {\n",
        "    'ground_truth' : 2\n",
        "}\n",
        "LRNN_SE3D_testing_data_stim2 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, cond_dict_stim2, return_like_full=True)\n",
        "\n",
        "LRNN_SE3D_testing_data_stim2_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim2, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_SE3D_testing_data_stim2_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim2, cond_dict_incorrect, return_like_full=True)"
      ],
      "metadata": {
        "id": "vp0nl2dmuvz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - EI"
      ],
      "metadata": {
        "id": "3nAsOaN9ug36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Partitioning LRNN - EI\n",
        "\n",
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "cond_dict_correct = {\n",
        "    'network_correct' : True\n",
        "}\n",
        "cond_dict_incorrect = {\n",
        "    'network_correct' : False\n",
        "}\n",
        "\n",
        "# trial_activity_stim1>stim2\n",
        "cond_dict_stim1 = {\n",
        "    'ground_truth' : 1\n",
        "}\n",
        "\n",
        "LRNN_EI_full_testing_data_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_EI_testing_data_stim1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, cond_dict_stim1, return_like_full=True)\n",
        "\n",
        "LRNN_EI_testing_data_stim1_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim1, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_EI_testing_data_stim1_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim1, cond_dict_incorrect, return_like_full=True)\n",
        "\n",
        "# trial_activity_stim2>stim1\n",
        "\n",
        "cond_dict_stim2 = {\n",
        "    'ground_truth' : 2\n",
        "}\n",
        "LRNN_EI_testing_data_stim2 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, cond_dict_stim2, return_like_full=True)\n",
        "\n",
        "LRNN_EI_testing_data_stim2_correct = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim2, cond_dict_correct, return_like_full=True)\n",
        "\n",
        "LRNN_EI_testing_data_stim2_incorrect = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim2, cond_dict_incorrect, return_like_full=True)"
      ],
      "metadata": {
        "id": "lTPQrcF4u3MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Unit Activity"
      ],
      "metadata": {
        "id": "-deNZfFHuEzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN NBIC"
      ],
      "metadata": {
        "id": "U62YUUzpuHBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NBIC - Single Trial Unit Activity"
      ],
      "metadata": {
        "id": "LUNow4c31PAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_NBIC_one_trial_stim1_correct = LRNN_NBIC_testing_data_stim1_correct['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_stim1_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_NBIC_one_trial_stim1_incorrect = LRNN_NBIC_testing_data_stim1_incorrect['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_stim1_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_NBIC_one_trial_stim1_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_NBIC_one_trial_stim2_correct = LRNN_NBIC_testing_data_stim2_correct['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_stim2_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_NBIC_one_trial_stim2_incorrect = LRNN_NBIC_testing_data_stim2_incorrect['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_stim2_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_NBIC_one_trial_stim2_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_NBIC_one_trial_plot_env_info = LRNN_NBIC_testing_data_stim1['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "msU4bhye7Y-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427bd11f-241c-4ce9-be48-27dac02bdae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Incorrect Trials\n",
            "No Incorrect Trials\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stim1\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_stim1_correct, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NBIC/1trial_stim1correct_LRNN_NBIC.png') # plot all units, no legend for now\n",
        "#stim2\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_stim2_correct, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NBIC/1trial_stim2correct_LRNN_NBIC.png') # plot all units, no legend for now\n",
        "\n",
        "if LRNN_NBIC_one_trial_stim1_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_NBIC_one_trial_stim1_incorrect, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NBIC/1trial_stim1incorrect_LRNN_NBIC.png') # plot all units, no legend for now\n",
        "if LRNN_NBIC_one_trial_stim2_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_NBIC_one_trial_stim2_incorrect, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NBIC/1trial_stim2incorrect_LRNN_NBIC.png') # plot all units, no legend for now\n"
      ],
      "metadata": {
        "id": "FZ5Ggj6H7Uyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e0181b-831d-4548-ad4f-94e0d6206305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/1trial_stim1correct_LRNN_NBIC.png\n",
            "Figure saved to PDM_LRNN_NBIC/1trial_stim2correct_LRNN_NBIC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NBIC - Average Unit Activity Plot"
      ],
      "metadata": {
        "id": "Er2j5bAC1Smd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_NBIC_all_trial_stim1_correct = LRNN_NBIC_testing_data_stim1_correct['testing_trial_and_activity']\n",
        "LRNN_NBIC_all_trial_stim2_correct = LRNN_NBIC_testing_data_stim2_correct['testing_trial_and_activity']\n",
        "\n",
        "LRNN_NBIC_all_trial_plot_env_info = LRNN_NBIC_testing_data_stim1_correct['testing_env_info'] # Same for each\n"
      ],
      "metadata": {
        "id": "1RdCK8oi7b6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#stim1\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_stim1_correct, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_NBIC/avg_stim1correct_LRNN_NBIC.png')\n",
        "\n",
        "#stim2\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_stim2_correct, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_NBIC/avg_stim2correct_LRNN_NBIC.png')\n"
      ],
      "metadata": {
        "id": "daTuDYVb7d1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373d3b7d-ff7d-47b7-e2f1-a7da79339c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/avg_stim1correct_LRNN_NBIC.png\n",
            "Figure saved to PDM_LRNN_NBIC/avg_stim2correct_LRNN_NBIC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN NSC\n"
      ],
      "metadata": {
        "id": "o8tx2Db4vA51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting Unit Activity - LRNN NSC\n",
        "\n",
        "### LRNN NSC - Single Trial Unit Activity\n",
        "\n",
        "#Single trial of each sample x test combination\n",
        "LRNN_NSC_one_trial_stim1_correct = LRNN_NSC_testing_data_stim1_correct['testing_trial_and_activity'][list(LRNN_NSC_testing_data_stim1_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_NSC_one_trial_stim1_incorrect = LRNN_NSC_testing_data_stim1_incorrect['testing_trial_and_activity'][list(LRNN_NSC_testing_data_stim1_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_NSC_one_trial_stim1_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_NSC_one_trial_stim2_correct = LRNN_NSC_testing_data_stim2_correct['testing_trial_and_activity'][list(LRNN_NSC_testing_data_stim2_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_NSC_one_trial_stim2_incorrect = LRNN_NSC_testing_data_stim2_incorrect['testing_trial_and_activity'][list(LRNN_NSC_testing_data_stim2_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_NSC_one_trial_stim2_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_NSC_one_trial_plot_env_info = LRNN_NSC_testing_data_stim1['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "# stim1\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_stim1_correct, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NSC/1trial_stim1correct_LRNN_NSC.png') # plot all units, no legend for now\n",
        "#stim2\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_stim2_correct, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NSC/1trial_stim2correct_LRNN_NSC.png') # plot all units, no legend for now\n",
        "\n",
        "if LRNN_NSC_one_trial_stim1_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_NSC_one_trial_stim1_incorrect, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NSC/1trial_stim1incorrect_LRNN_NSC.png') # plot all units, no legend for now\n",
        "if LRNN_NSC_one_trial_stim2_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_NSC_one_trial_stim2_incorrect, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_NSC/1trial_stim2incorrect_LRNN_NSC.png') # plot all units, no legend for now\n",
        "\n",
        "\n",
        "### LRNN NSC - Average Unit Activity Plot\n",
        "\n",
        "\n",
        "LRNN_NSC_all_trial_stim1_correct = LRNN_NSC_testing_data_stim1_correct['testing_trial_and_activity']\n",
        "LRNN_NSC_all_trial_stim2_correct = LRNN_NSC_testing_data_stim2_correct['testing_trial_and_activity']\n",
        "\n",
        "LRNN_NSC_all_trial_plot_env_info = LRNN_NSC_testing_data_stim1_correct['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "#stim1\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_stim1_correct, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_NSC/avg_stim1correct_LRNN_NSC.png')\n",
        "\n",
        "#stim2\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_stim2_correct, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_NSC/avg_stim2correct_LRNN_NSC.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb68U0ZivEd0",
        "outputId": "00cfdf8e-dd2a-4d9c-ea36-47ae6215e747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Incorrect Trials\n",
            "No Incorrect Trials\n",
            "Figure saved to PDM_LRNN_NSC/1trial_stim1correct_LRNN_NSC.png\n",
            "Figure saved to PDM_LRNN_NSC/1trial_stim2correct_LRNN_NSC.png\n",
            "Figure saved to PDM_LRNN_NSC/avg_stim1correct_LRNN_NSC.png\n",
            "Figure saved to PDM_LRNN_NSC/avg_stim2correct_LRNN_NSC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN SE2D"
      ],
      "metadata": {
        "id": "_tSXBBjqvEkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting Unit Activity - LRNN SE2D\n",
        "\n",
        "### LRNN SE2D - Single Trial Unit Activity\n",
        "\n",
        "#Single trial of each sample x test combination\n",
        "LRNN_SE2D_one_trial_stim1_correct = LRNN_SE2D_testing_data_stim1_correct['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_stim1_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_SE2D_one_trial_stim1_incorrect = LRNN_SE2D_testing_data_stim1_incorrect['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_stim1_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_SE2D_one_trial_stim1_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_SE2D_one_trial_stim2_correct = LRNN_SE2D_testing_data_stim2_correct['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_stim2_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_SE2D_one_trial_stim2_incorrect = LRNN_SE2D_testing_data_stim2_incorrect['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_stim2_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_SE2D_one_trial_stim2_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_SE2D_one_trial_plot_env_info = LRNN_SE2D_testing_data_stim1['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "# stim1\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_stim1_correct, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE2D/1trial_stim1correct_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "#stim2\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_stim2_correct, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE2D/1trial_stim2correct_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "\n",
        "if LRNN_SE2D_one_trial_stim1_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_SE2D_one_trial_stim1_incorrect, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE2D/1trial_stim1incorrect_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "if LRNN_SE2D_one_trial_stim2_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_SE2D_one_trial_stim2_incorrect, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE2D/1trial_stim2incorrect_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "\n",
        "\n",
        "### LRNN SE2D - Average Unit Activity Plot\n",
        "\n",
        "\n",
        "LRNN_SE2D_all_trial_stim1_correct = LRNN_SE2D_testing_data_stim1_correct['testing_trial_and_activity']\n",
        "LRNN_SE2D_all_trial_stim2_correct = LRNN_SE2D_testing_data_stim2_correct['testing_trial_and_activity']\n",
        "\n",
        "LRNN_SE2D_all_trial_plot_env_info = LRNN_SE2D_testing_data_stim1_correct['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "#stim1\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_stim1_correct, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_SE2D/avg_stim1correct_LRNN_SE2D.png')\n",
        "\n",
        "#stim2\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_stim2_correct, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_SE2D/avg_stim2correct_LRNN_SE2D.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5m89ZkxvOmZ",
        "outputId": "03ba5918-59f5-4207-e194-f1d78c445a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Incorrect Trials\n",
            "No Incorrect Trials\n",
            "Figure saved to PDM_LRNN_SE2D/1trial_stim1correct_LRNN_SE2D.png\n",
            "Figure saved to PDM_LRNN_SE2D/1trial_stim2correct_LRNN_SE2D.png\n",
            "Figure saved to PDM_LRNN_SE2D/avg_stim1correct_LRNN_SE2D.png\n",
            "Figure saved to PDM_LRNN_SE2D/avg_stim2correct_LRNN_SE2D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN SE3D"
      ],
      "metadata": {
        "id": "_k8yBxvYvEt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting Unit Activity - LRNN SE3D\n",
        "\n",
        "### LRNN SE3D - Single Trial Unit Activity\n",
        "\n",
        "#Single trial of each sample x test combination\n",
        "LRNN_SE3D_one_trial_stim1_correct = LRNN_SE3D_testing_data_stim1_correct['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_stim1_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_SE3D_one_trial_stim1_incorrect = LRNN_SE3D_testing_data_stim1_incorrect['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_stim1_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_SE3D_one_trial_stim1_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_SE3D_one_trial_stim2_correct = LRNN_SE3D_testing_data_stim2_correct['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_stim2_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_SE3D_one_trial_stim2_incorrect = LRNN_SE3D_testing_data_stim2_incorrect['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_stim2_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_SE3D_one_trial_stim2_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_SE3D_one_trial_plot_env_info = LRNN_SE3D_testing_data_stim1['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "# stim1\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_stim1_correct, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE3D/1trial_stim1correct_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "#stim2\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_stim2_correct, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE3D/1trial_stim2correct_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "\n",
        "if LRNN_SE3D_one_trial_stim1_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_SE3D_one_trial_stim1_incorrect, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE3D/1trial_stim1incorrect_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "if LRNN_SE3D_one_trial_stim2_incorrect is not None:\n",
        "  plot_unit_activity_over_time(LRNN_SE3D_one_trial_stim2_incorrect, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_SE3D/1trial_stim2incorrect_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "\n",
        "\n",
        "### LRNN SE3D - Average Unit Activity Plot\n",
        "\n",
        "\n",
        "LRNN_SE3D_all_trial_stim1_correct = LRNN_SE3D_testing_data_stim1_correct['testing_trial_and_activity']\n",
        "LRNN_SE3D_all_trial_stim2_correct = LRNN_SE3D_testing_data_stim2_correct['testing_trial_and_activity']\n",
        "\n",
        "LRNN_SE3D_all_trial_plot_env_info = LRNN_SE3D_testing_data_stim1_correct['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "#stim1\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_stim1_correct, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_SE3D/avg_stim1correct_LRNN_SE3D.png')\n",
        "\n",
        "#stim2\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_stim2_correct, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='PDM_LRNN_SE3D/avg_stim2correct_LRNN_SE3D.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y89R8ZlgvTwi",
        "outputId": "6e452251-cd07-4976-a01d-ccd0e53452d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Incorrect Trials\n",
            "No Incorrect Trials\n",
            "Figure saved to PDM_LRNN_SE3D/1trial_stim1correct_LRNN_SE3D.png\n",
            "Figure saved to PDM_LRNN_SE3D/1trial_stim2correct_LRNN_SE3D.png\n",
            "Figure saved to PDM_LRNN_SE3D/avg_stim1correct_LRNN_SE3D.png\n",
            "Figure saved to PDM_LRNN_SE3D/avg_stim2correct_LRNN_SE3D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN EI"
      ],
      "metadata": {
        "id": "aM6Jh-zsvE2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom Func (from DMS)"
      ],
      "metadata": {
        "id": "53bTbvl1wNC3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YR2I5yTkwPPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ei_unit_activity_trial(trial_activity, env_info, e_size, unit_indices_to_plot=None, filename=None):\n",
        "    \"\"\"\n",
        "    Takes a single trial's data and plots the activity of E/I units over time.\n",
        "\n",
        "    Args:\n",
        "        trial_activity : (shape: seq_len x hidden_size).\n",
        "        env_info (dict): Environmental information including 'dt' and 'timing'.\n",
        "        e_size (int): The number of excitatory units. Assumes E units are first.\n",
        "        unit_indices_to_plot (list, optional): Specific unit indices to plot.\n",
        "                                            If None, all units are plotted. Defaults to None.\n",
        "        filename (str, optional): File path to save the figure. If None,\n",
        "                                  the plot is displayed directly. Defaults to None.\n",
        "    \"\"\"\n",
        "\n",
        "    seq_len, hidden_size = trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Create time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # Define E and I indices\n",
        "    e_indices = set(range(e_size))\n",
        "    i_indices = set(range(e_size, hidden_size))\n",
        "\n",
        "    # Determine which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = [i for i in unit_indices_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "    # Plot unit activities with E/I colour coding and labeling\n",
        "    e_plotted = False\n",
        "    i_plotted = False\n",
        "    for i in units_to_plot:\n",
        "        if i in e_indices:\n",
        "            label = 'Excitatory' if not e_plotted else ''\n",
        "            ax.plot(time_points, trial_activity[:, i], color='blue', alpha=0.7, label=label)\n",
        "            e_plotted = True\n",
        "        elif i in i_indices:\n",
        "            label = 'Inhibitory' if not i_plotted else ''\n",
        "            ax.plot(time_points, trial_activity[:, i], color='red', alpha=0.7, label=label)\n",
        "            i_plotted = True\n",
        "\n",
        "    # Add vertical lines for task phases\n",
        "    current_time = 0\n",
        "    phase_boundaries = [0]\n",
        "    for duration in timing.values():\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            if current_time <= (time_points[-1]+dt):\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', alpha=0.5)\n",
        "                phase_boundaries.append(current_time)\n",
        "\n",
        "    # Add phase labels inside the plot after all data is plotted\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    text_y_position = ymax - (ymax - ymin) * 0.05  # Position text near the top\n",
        "\n",
        "    phase_keys = list(timing.keys())\n",
        "    for i in range(len(phase_boundaries) - 1):\n",
        "        start_time = phase_boundaries[i]\n",
        "        end_time = phase_boundaries[i+1]\n",
        "        mid_point = start_time + (end_time - start_time) / 2\n",
        "        ax.text(mid_point, text_y_position, phase_keys[i], ha='center', va='top', fontsize=12, style='italic')\n",
        "\n",
        "    ax.set_title('E/I Network Unit Activity Over Time (Single Trial)')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Activity')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename):\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_ei_average_unit_activity(trial_data_dict, env_info, e_size, unit_indices_to_plot=None, filename=None):\n",
        "    \"\"\"\n",
        "    Calculates and plots the average activity of E/I network units over time\n",
        "    across multiple trials.\n",
        "\n",
        "    Args:\n",
        "        trial_data_dict (dict): A dictionary of multiple trials.\n",
        "        env_info (dict): Environmental information including 'dt' and 'timing'.\n",
        "        e_size (int): The number of excitatory units. Assumes E units are first.\n",
        "        unit_indices_to_plot (list, optional): Specific unit indices to plot.\n",
        "                                            If None, all units are plotted. Defaults to None.\n",
        "        filename (str, optional): File path to save the figure. If None,\n",
        "                                  the plot is displayed directly. Defaults to None.\n",
        "    \"\"\"\n",
        "    if not trial_data_dict:\n",
        "        print(\"No trial data provided for plotting.\")\n",
        "        return\n",
        "\n",
        "    first_trial_key = list(trial_data_dict.keys())[0]\n",
        "    first_trial_activity = trial_data_dict[first_trial_key]['network_activity']\n",
        "    seq_len, hidden_size = first_trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Stack all activity arrays for averaging\n",
        "    all_activities = [t['network_activity'] for t in trial_data_dict.values() if t['network_activity'].shape == (seq_len, hidden_size)]\n",
        "    if not all_activities:\n",
        "        print(\"No valid trial data found for averaging.\")\n",
        "        return\n",
        "\n",
        "    average_activity = np.mean(np.stack(all_activities, axis=0), axis=0)\n",
        "\n",
        "    # Create time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # Define E and I indices\n",
        "    e_indices = set(range(e_size))\n",
        "    i_indices = set(range(e_size, hidden_size))\n",
        "\n",
        "    # Determine which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = [i for i in unit_indices_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "    # Plot average unit activities with E/I colour-coding and labeling\n",
        "    e_plotted = False\n",
        "    i_plotted = False\n",
        "    for i in units_to_plot:\n",
        "        if i in e_indices:\n",
        "            label = 'Excitatory' if not e_plotted else ''\n",
        "            ax.plot(time_points, average_activity[:, i], color='blue', alpha=0.7, label=label)\n",
        "            e_plotted = True\n",
        "        elif i in i_indices:\n",
        "            label = 'Inhibitory' if not i_plotted else ''\n",
        "            ax.plot(time_points, average_activity[:, i], color='red', alpha=0.7, label=label)\n",
        "            i_plotted = True\n",
        "\n",
        "    # Add vertical lines for task phases\n",
        "    current_time = 0\n",
        "    phase_boundaries = [0]\n",
        "    for duration in timing.values():\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            if current_time <= (time_points[-1]+dt):\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', alpha=0.5)\n",
        "                phase_boundaries.append(current_time)\n",
        "\n",
        "    # Add phase labels inside the plot\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    text_y_position = ymax - (ymax - ymin) * 0.05\n",
        "\n",
        "    phase_keys = list(timing.keys())\n",
        "    for i in range(len(phase_boundaries) - 1):\n",
        "        start_time = phase_boundaries[i]\n",
        "        end_time = phase_boundaries[i+1]\n",
        "        mid_point = start_time + (end_time - start_time) / 2\n",
        "        ax.text(mid_point, text_y_position, phase_keys[i], ha='center', va='top', fontsize=12, style='italic')\n",
        "\n",
        "    ax.set_title('Average E/I Network Unit Activity Across Trials')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Average Activity')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename):\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "GnJ9m5cf0_Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting Unit Activity - LRNN EI\n",
        "\n",
        "### LRNN EI - Single Trial Unit Activity\n",
        "\n",
        "#Single trial of each sample x test combination\n",
        "LRNN_EI_one_trial_stim1_correct = LRNN_EI_testing_data_stim1_correct['testing_trial_and_activity'][list(LRNN_EI_testing_data_stim1_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_EI_one_trial_stim1_incorrect = LRNN_EI_testing_data_stim1_incorrect['testing_trial_and_activity'][list(LRNN_EI_testing_data_stim1_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_EI_one_trial_stim1_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_EI_one_trial_stim2_correct = LRNN_EI_testing_data_stim2_correct['testing_trial_and_activity'][list(LRNN_EI_testing_data_stim2_correct['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "try:\n",
        "  LRNN_EI_one_trial_stim2_incorrect = LRNN_EI_testing_data_stim2_incorrect['testing_trial_and_activity'][list(LRNN_EI_testing_data_stim2_incorrect['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "except:\n",
        "  LRNN_EI_one_trial_stim2_incorrect = None\n",
        "  print('No Incorrect Trials')\n",
        "\n",
        "\n",
        "LRNN_EI_one_trial_plot_env_info = LRNN_EI_testing_data_stim1['testing_env_info'] # Same for each\n",
        "\n",
        "LRNN_EI_E_SIZE = LRNN_EI_TRAINED.rnn.e_size\n",
        "print(LRNN_EI_E_SIZE)\n",
        "\n",
        "\n",
        "# stim1\n",
        "# plot_unit_activity_over_time(LRNN_EI_one_trial_stim1_correct, LRNN_EI_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='PDM_LRNN_EI/1trial_stim1correct_LRNN_EI.png') # plot all units, no legend for now\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_stim1_correct, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/1trial_stim1correct_LRNN_EI.png') # plot all units, no legend for now\n",
        "\n",
        "#stim2\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_stim2_correct, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/1trial_stim2correct_LRNN_EI.png') # plot all units, no legend for now\n",
        "if LRNN_EI_one_trial_stim1_incorrect is not None:\n",
        "  plot_ei_unit_activity_trial(LRNN_EI_one_trial_stim1_incorrect, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/1trial_stim1incorrect_LRNN_EI.png') # plot all units, no legend for now\n",
        "if LRNN_EI_one_trial_stim2_incorrect is not None:\n",
        "  plot_ei_unit_activity_trial(LRNN_EI_one_trial_stim2_incorrect, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/1trial_stim2incorrect_LRNN_EI.png') # plot all units, no legend for now\n",
        "\n",
        "\n",
        "### LRNN EI - Average Unit Activity Plot\n",
        "\n",
        "\n",
        "LRNN_EI_all_trial_stim1_correct = LRNN_EI_testing_data_stim1_correct['testing_trial_and_activity']\n",
        "LRNN_EI_all_trial_stim2_correct = LRNN_EI_testing_data_stim2_correct['testing_trial_and_activity']\n",
        "\n",
        "LRNN_EI_all_trial_plot_env_info = LRNN_EI_testing_data_stim1_correct['testing_env_info'] # Same for each\n",
        "\n",
        "\n",
        "\n",
        "#stim1\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_stim1_correct, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/avg_stim1correct_LRNN_EI.png')\n",
        "#stim2\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_stim2_correct, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='PDM_LRNN_EI/avg_stim2correct_LRNN_EI.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsEuE8SyvUbe",
        "outputId": "f877f29f-5448-4581-cd6f-d444c6dd8fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Incorrect Trials\n",
            "No Incorrect Trials\n",
            "51\n",
            "Figure saved to PDM_LRNN_EI/1trial_stim1correct_LRNN_EI.png\n",
            "Figure saved to PDM_LRNN_EI/1trial_stim2correct_LRNN_EI.png\n",
            "Figure saved to PDM_LRNN_EI/avg_stim1correct_LRNN_EI.png\n",
            "Figure saved to PDM_LRNN_EI/avg_stim2correct_LRNN_EI.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Re-) Plotting Network Structure"
      ],
      "metadata": {
        "id": "JV37O0mq8B7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot (WHY DONT WE PASS THE CORRECT WEIGHTS HERE!)"
      ],
      "metadata": {
        "id": "yc8k7gV38G0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_NBIC_TRAINED, filename='PDM_LRNN_NBIC/LRNN_NBIC_Connectivity.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "311ufb_58FrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de8f850-50a2-4f98-bbf4-1d7acd6346ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_NSC_TRAINED, mask= LRNN_NSC_TRAINED.rnn.nsc_mask , filename='PDM_LRNN_NSC/LRNN_NSC_Connectivity.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvTzTaKUvxxI",
        "outputId": "f5f7394f-85e3-44e5-a33d-6058dfaab281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_SE2D_TRAINED, mask =LRNN_SE2D_TRAINED.rnn.nsc_mask, filename='PDM_LRNN_SE2D/LRNN_SE2D_Connectivity.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu162Trav1Kf",
        "outputId": "9023c33c-98eb-4b46-c2c1-df792061bac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_SE3D_TRAINED, mask = LRNN_SE3D_TRAINED.rnn.nsc_mask, filename='PDM_LRNN_SE3D/LRNN_SE3D_Connectivity.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03_s1Iqkv5gR",
        "outputId": "15e58403-9bca-419c-e595-e51a91e28124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(net = LRNN_EI_TRAINED.rnn.h2h.effective_weight(), weights_passed=True , filename='PDM_LRNN_EI/LRNN_EI_Connectivity.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYrtPXGZv7Rh",
        "outputId": "f4b549d6-0b17-429f-8007-a91c5f7cce5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_EI/LRNN_EI_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (EXPORTING DATA)"
      ],
      "metadata": {
        "id": "IRTjjEEd_b_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-NBIC"
      ],
      "metadata": {
        "id": "CcXT-CFu_iUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_nested_dict_to_json(LRNN_NBIC_full_testing_data, filename= 'PDM_LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "id": "HSapbiXnCC1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331a587f-acd7-4b94-c472-9b249bc84d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to PDM_LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_testing_structure = import_nested_dict_from_json(filename = 'PDM_LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "id": "fghlS7pICbKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d8c15d-eb78-4e5b-af7b-b8a9caff2aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully imported from PDM_LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_from_io = compare_dicts(LRNN_NBIC_full_testing_data, temp_testing_structure)"
      ],
      "metadata": {
        "id": "c0cJ8pszCjNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c4eced-a2ff-4b3b-8ecc-0dfa0c96e541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (Importing Plots and Displaying)"
      ],
      "metadata": {
        "id": "rpQFadwbDr3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-NBIC"
      ],
      "metadata": {
        "id": "4mI6cbxiD4vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Define the directory containing the images\n",
        "image_directory = 'PDM_LRNN_NBIC/LRNN_NBIC_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "id": "RwvpmXiuDuug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52d4d9d-0a35-45b6-b267-0a2cbc948e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'PDM_LRNN_NBIC/LRNN_NBIC_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA (All Networks)"
      ],
      "metadata": {
        "id": "sHf51SslE_WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "K0pdtrLcL9fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "jesMZCwFL9fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sample period data for all conds:\n",
        "LRNN_NBIC_stimulus_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='stimulus')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_NBIC_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_NBIC_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n"
      ],
      "metadata": {
        "id": "E1JhcojbL9fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_NBIC_one_d_stimulus_pca = fit_pca_on_selected_data(LRNN_NBIC_stimulus_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_NBIC_two_d_stimulus_pca = fit_pca_on_selected_data(LRNN_NBIC_stimulus_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_NBIC_one_d_delay_pca = fit_pca_on_selected_data(LRNN_NBIC_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_NBIC_two_d_delay_pca = fit_pca_on_selected_data(LRNN_NBIC_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_NBIC_one_d_decision_pca = fit_pca_on_selected_data(LRNN_NBIC_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_NBIC_two_d_decision_pca = fit_pca_on_selected_data(LRNN_NBIC_decision_period_trials_dict, pca_components=2, report_var_expls = False)"
      ],
      "metadata": {
        "id": "fHsaQsUqL9fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "qhIOwK3-L9fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN NBIC Plot"
      ],
      "metadata": {
        "id": "B-Jmv3SxL9fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_stimulus_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_stimulus_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "7tYKYmEAL9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24b4736-b932-43c2-d9ea-0aa17389c10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_stimulus_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_delay_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_delay_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "cD6mwnJXL9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4c8fc7-ca37-41da-fdbd-d681e60283bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_delay_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_decision_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_decision_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "5obZZd_6L9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b936c5-0d38-44c1-9b9e-23f77e2b874d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN NBIC Plot"
      ],
      "metadata": {
        "id": "hCx-bizAL9f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_stimulus_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_stimulus_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "zkcy5mBRL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796aa58b-0c4f-4eb0-84a2-78f5d68a558a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_stimulus_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_delay_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "CBVsM-lkL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4cb5095-9c59-4008-db24-fca4033d667d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_delay_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_decision_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "cagekq1JL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d2d54c-630a-4553-c560-9c3bce5ad86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add All Period PCA"
      ],
      "metadata": {
        "id": "JqyZ4i1zvLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all periods all conds (correct)\n",
        "LRNN_NBIC_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_NBIC_one_d_all_pca = fit_pca_on_selected_data(LRNN_NBIC_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_NBIC_two_d_all_pca = fit_pca_on_selected_data(LRNN_NBIC_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_all_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_all_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NBIC/LRNN_NBIC_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "Gq6N07tbvKtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2db5b4-cb95-4235-d451-aee38e3c07b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_all_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN_NSC"
      ],
      "metadata": {
        "id": "mNJwX_iRwIw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PCA - LRNN NSC\n",
        "\n",
        "### Fit PCA - LRNN NSC\n",
        "\n",
        "\n",
        "# sample period data for all conds:\n",
        "LRNN_NSC_stimulus_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='stimulus')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_NSC_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_NSC_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_NSC_one_d_stimulus_pca = fit_pca_on_selected_data(LRNN_NSC_stimulus_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_NSC_two_d_stimulus_pca = fit_pca_on_selected_data(LRNN_NSC_stimulus_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_NSC_one_d_delay_pca = fit_pca_on_selected_data(LRNN_NSC_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_NSC_two_d_delay_pca = fit_pca_on_selected_data(LRNN_NSC_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_NSC_one_d_decision_pca = fit_pca_on_selected_data(LRNN_NSC_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_NSC_two_d_decision_pca = fit_pca_on_selected_data(LRNN_NSC_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "### Plot PCA - LRNN NSC\n",
        "\n",
        "#### 1D PCA - LRNN NSC Plot\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_stimulus_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_stimulus_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_delay_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_decision_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_decision_PCA_1D_full_trials.png')\n",
        "\n",
        "#### 2D PCA - LRNN NSC Plot\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_stimulus_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_stimulus_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_delay_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_decision_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "#### Add All Period PCA\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_NSC_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_NSC_one_d_all_pca = fit_pca_on_selected_data(LRNN_NSC_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_NSC_two_d_all_pca = fit_pca_on_selected_data(LRNN_NSC_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_all_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_all_pca, data_to_transform_dict=LRNN_NSC_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_NSC/LRNN_NSC_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkAI3E2wRQL",
        "outputId": "5ed9d3c9-92ea-43dc-8e40-fb05b5bb2a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_stimulus_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_delay_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_decision_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_stimulus_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_delay_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_decision_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_all_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN_SE2D"
      ],
      "metadata": {
        "id": "Dj4AJOOBwKV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PCA - LRNN SE2D\n",
        "\n",
        "### Fit PCA - LRNN SE2D\n",
        "\n",
        "\n",
        "# sample period data for all conds:\n",
        "LRNN_SE2D_stimulus_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='stimulus')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_SE2D_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_SE2D_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_SE2D_one_d_stimulus_pca = fit_pca_on_selected_data(LRNN_SE2D_stimulus_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_SE2D_two_d_stimulus_pca = fit_pca_on_selected_data(LRNN_SE2D_stimulus_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_SE2D_one_d_delay_pca = fit_pca_on_selected_data(LRNN_SE2D_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_SE2D_two_d_delay_pca = fit_pca_on_selected_data(LRNN_SE2D_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_SE2D_one_d_decision_pca = fit_pca_on_selected_data(LRNN_SE2D_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_SE2D_two_d_decision_pca = fit_pca_on_selected_data(LRNN_SE2D_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "### Plot PCA - LRNN SE2D\n",
        "\n",
        "#### 1D PCA - LRNN SE2D Plot\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_stimulus_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_stimulus_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_delay_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_decision_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_decision_PCA_1D_full_trials.png')\n",
        "\n",
        "#### 2D PCA - LRNN SE2D Plot\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_stimulus_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_stimulus_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_delay_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_decision_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "#### Add All Period PCA\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_SE2D_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_SE2D_one_d_all_pca = fit_pca_on_selected_data(LRNN_SE2D_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_SE2D_two_d_all_pca = fit_pca_on_selected_data(LRNN_SE2D_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_all_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_all_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE2D/LRNN_SE2D_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKoXtgMrwTuO",
        "outputId": "ed8519fa-d6f2-44ee-8d84-0710e9623541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_stimulus_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_delay_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_decision_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_stimulus_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_delay_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_decision_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_all_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN_SE3D"
      ],
      "metadata": {
        "id": "Gdl2QlLRwM_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PCA - LRNN SE3D\n",
        "\n",
        "### Fit PCA - LRNN SE3D\n",
        "\n",
        "\n",
        "# sample period data for all conds:\n",
        "LRNN_SE3D_stimulus_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='stimulus')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_SE3D_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_SE3D_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_SE3D_one_d_stimulus_pca = fit_pca_on_selected_data(LRNN_SE3D_stimulus_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_SE3D_two_d_stimulus_pca = fit_pca_on_selected_data(LRNN_SE3D_stimulus_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_SE3D_one_d_delay_pca = fit_pca_on_selected_data(LRNN_SE3D_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_SE3D_two_d_delay_pca = fit_pca_on_selected_data(LRNN_SE3D_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_SE3D_one_d_decision_pca = fit_pca_on_selected_data(LRNN_SE3D_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_SE3D_two_d_decision_pca = fit_pca_on_selected_data(LRNN_SE3D_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "### Plot PCA - LRNN SE3D\n",
        "\n",
        "#### 1D PCA - LRNN SE3D Plot\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_stimulus_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_stimulus_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_delay_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_decision_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_decision_PCA_1D_full_trials.png')\n",
        "\n",
        "#### 2D PCA - LRNN SE3D Plot\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_stimulus_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                              num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_stimulus_PCA_2D_full_trials.png',\n",
        "                              add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_delay_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                              num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_delay_PCA_2D_full_trials.png',\n",
        "                              add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_decision_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                              num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_decision_PCA_2D_full_trials.png',\n",
        "                              add_phase_markers=True)\n",
        "\n",
        "#### Add All Period PCA\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_SE3D_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_SE3D_one_d_all_pca = fit_pca_on_selected_data(LRNN_SE3D_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_SE3D_two_d_all_pca = fit_pca_on_selected_data(LRNN_SE3D_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_all_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_all_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                              num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_SE3D/LRNN_SE3D_all_PCA_2D_full_trials.png',\n",
        "                              add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7em3e-00wf5B",
        "outputId": "9c870568-c104-465c-ee43-a3683be4ab72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_stimulus_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_delay_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_decision_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_stimulus_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_delay_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_decision_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_all_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN_EI"
      ],
      "metadata": {
        "id": "kH5OMMB6wPee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PCA - LRNN EI\n",
        "\n",
        "### Fit PCA - LRNN EI\n",
        "\n",
        "\n",
        "# sample period data for all conds:\n",
        "LRNN_EI_stimulus_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='stimulus')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_EI_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_EI_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_EI_one_d_stimulus_pca = fit_pca_on_selected_data(LRNN_EI_stimulus_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_EI_two_d_stimulus_pca = fit_pca_on_selected_data(LRNN_EI_stimulus_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_EI_one_d_delay_pca = fit_pca_on_selected_data(LRNN_EI_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_EI_two_d_delay_pca = fit_pca_on_selected_data(LRNN_EI_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_EI_one_d_decision_pca = fit_pca_on_selected_data(LRNN_EI_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_EI_two_d_decision_pca = fit_pca_on_selected_data(LRNN_EI_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "### Plot PCA - LRNN EI\n",
        "\n",
        "#### 1D PCA - LRNN EI Plot\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_stimulus_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_stimulus_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_delay_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_decision_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_decision_PCA_1D_full_trials.png')\n",
        "\n",
        "#### 2D PCA - LRNN EI Plot\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_stimulus_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_stimulus_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_delay_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_decision_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "#### Add All Period PCA\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_EI_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_EI_one_d_all_pca = fit_pca_on_selected_data(LRNN_EI_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_EI_two_d_all_pca = fit_pca_on_selected_data(LRNN_EI_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_all_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_all_pca, data_to_transform_dict=LRNN_EI_full_testing_data_correct['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='PDM_LRNN_EI/LRNN_EI_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohQkEg1iwv2R",
        "outputId": "729f8e27-e4d8-42b0-cd74-ad858dee8c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to PDM_LRNN_EI/LRNN_EI_stimulus_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_delay_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_decision_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_stimulus_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_delay_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_decision_PCA_2D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_all_PCA_1D_full_trials.png\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selectivity and Leisoning - All BICs --- HERE"
      ],
      "metadata": {
        "id": "4rZiQCoUH-P3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables for all"
      ],
      "metadata": {
        "id": "ArlnACvMIpxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leisoning_testing_data_set = dataset_testing"
      ],
      "metadata": {
        "id": "wRmAAD_YIsri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NBIC"
      ],
      "metadata": {
        "id": "QdVEFAcYIBcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "KokoDqzOIFGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Period\n",
        "LRNN_NBIC_testing_data_stim1_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "LRNN_NBIC_testing_data_stim2_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "# LRNN_NBIC_testing_data_stim1_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# LRNN_NBIC_testing_data_stim2_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# Data from Partition\n",
        "LRNN_NBIC_stim_1_data_selec_leison = LRNN_NBIC_testing_data_stim1_stimulus_period\n",
        "LRNN_NBIC_stim_2_data_selec_leison = LRNN_NBIC_testing_data_stim2_stimulus_period\n",
        "# LRNN_NBIC_stim_1_data_selec_leison = LRNN_NBIC_testing_data_stim1_all_period\n",
        "# LRNN_NBIC_stim_2_data_selec_leison = LRNN_NBIC_testing_data_stim2_all_period\n",
        "LRNN_NBIC_sample_stim_data_dicts = [LRNN_NBIC_stim_1_data_selec_leison['testing_trial_and_activity'], LRNN_NBIC_stim_2_data_selec_leison['testing_trial_and_activity']]\n",
        "\n",
        "# LRNN_NBIC_1D_PCA_sssl = LRNN_NBIC_one_d_stimulus_pca\n",
        "# LRNN_NBIC_2D_PCA_sssl = LRNN_NBIC_two_d_stimulus_pca\n",
        "# LRNN_NBIC_1D_PCA_sssl = LRNN_NBIC_one_d_delay_pca\n",
        "# LRNN_NBIC_2D_PCA_sssl = LRNN_NBIC_two_d_delay_pca\n",
        "LRNN_NBIC_1D_PCA_sssl = LRNN_NBIC_one_d_decision_pca\n",
        "LRNN_NBIC_2D_PCA_sssl = LRNN_NBIC_two_d_decision_pca\n",
        "# LRNN_NBIC_1D_PCA_sssl = LRNN_NBIC_one_d_all_pca\n",
        "# LRNN_NBIC_2D_PCA_sssl = LRNN_NBIC_two_d_all_pca\n"
      ],
      "metadata": {
        "id": "9ZJtC5o9IQVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_stim_selec_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NBIC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NBIC_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NBIC_1D_PCA_sssl, fig_file_name = 'PDM_LRNN_NBIC/decision_leisoned_unleisoned_LRNN_NBIC_SS_sample_period' , file_ext='.png', unleisoned_PCA_2d = LRNN_NBIC_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "id": "YV6I7nBpIDGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d11ad4-38d1-4edd-e608-5feb6bbc1b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(51), np.int64(30), np.int64(24), np.int64(5), np.int64(45), np.int64(38)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.489\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 48.9 %\n",
            "Performance Difference: 51.1 %\n",
            "Figure saved to PDM_LRNN_NBIC/decision_leisoned_unleisoned_LRNN_NBIC_SS_sample_period_1d_pca.png\n",
            "Figure saved to PDM_LRNN_NBIC/decision_leisoned_unleisoned_LRNN_NBIC_SS_sample_period_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN_NSC"
      ],
      "metadata": {
        "id": "sypIjJ8ZxBep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LRNN-NSC\n",
        "\n",
        "### Sample Stimulus Selective\n",
        "\n",
        "# Sample Period\n",
        "LRNN_NSC_testing_data_stim1_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "LRNN_NSC_testing_data_stim2_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "# Data from Partition\n",
        "LRNN_NSC_stim_1_data_selec_leison = LRNN_NSC_testing_data_stim1_stimulus_period\n",
        "LRNN_NSC_stim_2_data_selec_leison = LRNN_NSC_testing_data_stim2_stimulus_period\n",
        "LRNN_NSC_sample_stim_data_dicts = [LRNN_NSC_stim_1_data_selec_leison['testing_trial_and_activity'], LRNN_NSC_stim_2_data_selec_leison['testing_trial_and_activity']]\n",
        "\n",
        "# LRNN_NSC_1D_PCA_sssl = LRNN_NSC_one_d_stimulus_pca\n",
        "# LRNN_NSC_2D_PCA_sssl = LRNN_NSC_two_d_stimulus_pca\n",
        "LRNN_NSC_1D_PCA_sssl = LRNN_NSC_one_d_delay_pca\n",
        "LRNN_NSC_2D_PCA_sssl = LRNN_NSC_two_d_delay_pca\n",
        "# LRNN_NSC_1D_PCA_sssl = LRNN_NSC_one_d_decision_pca\n",
        "# LRNN_NSC_2D_PCA_sssl = LRNN_NSC_two_d_decision_pca\n",
        "# LRNN_NSC_1D_PCA_sssl = LRNN_NSC_one_d_all_pca\n",
        "# LRNN_NSC_2D_PCA_sssl = LRNN_NSC_two_d_all_pca\n",
        "\n",
        "\n",
        "LRNN_NSC_stim_selec_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NSC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NSC_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NSC_1D_PCA_sssl, fig_file_name = 'PDM_LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_NSC_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeM25D_8xEGq",
        "outputId": "f2f23990-e69e-46d3-df85-304bf0ac283e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(7), np.int64(5), np.int64(60), np.int64(22), np.int64(2), np.int64(37)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.0\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 0.0 %\n",
            "Performance Difference: 100.0 %\n",
            "Figure saved to PDM_LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS_1d_pca.png\n",
            "Figure saved to PDM_LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN_SE2D"
      ],
      "metadata": {
        "id": "IJl0B5hKxEMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LRNN-SE2D\n",
        "\n",
        "### Sample Stimulus Selective\n",
        "\n",
        "# Sample Period\n",
        "LRNN_SE2D_testing_data_stim1_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "LRNN_SE2D_testing_data_stim2_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "# LRNN_SE2D_testing_data_stim1_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "# LRNN_SE2D_testing_data_stim2_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# Data from Partition\n",
        "LRNN_SE2D_stim_1_data_selec_leison = LRNN_SE2D_testing_data_stim1_stimulus_period\n",
        "LRNN_SE2D_stim_2_data_selec_leison = LRNN_SE2D_testing_data_stim2_stimulus_period\n",
        "\n",
        "# Data from Partition\n",
        "# LRNN_SE2D_stim_1_data_selec_leison = LRNN_SE2D_testing_data_stim1_all_period\n",
        "# LRNN_SE2D_stim_2_data_selec_leison = LRNN_SE2D_testing_data_stim2_all_period\n",
        "\n",
        "\n",
        "LRNN_SE2D_sample_stim_data_dicts = [LRNN_SE2D_stim_1_data_selec_leison['testing_trial_and_activity'], LRNN_SE2D_stim_2_data_selec_leison['testing_trial_and_activity']]\n",
        "\n",
        "# LRNN_SE2D_1D_PCA_sssl = LRNN_SE2D_one_d_stimulus_pca\n",
        "# LRNN_SE2D_2D_PCA_sssl = LRNN_SE2D_two_d_stimulus_pca\n",
        "# LRNN_SE2D_1D_PCA_sssl = LRNN_SE2D_one_d_delay_pca\n",
        "# LRNN_SE2D_2D_PCA_sssl = LRNN_SE2D_two_d_delay_pca\n",
        "LRNN_SE2D_1D_PCA_sssl = LRNN_SE2D_one_d_decision_pca\n",
        "LRNN_SE2D_2D_PCA_sssl = LRNN_SE2D_two_d_decision_pca\n",
        "# LRNN_SE2D_1D_PCA_sssl = LRNN_SE2D_one_d_all_pca\n",
        "# LRNN_SE2D_2D_PCA_sssl = LRNN_SE2D_two_d_all_pca\n",
        "\n",
        "\n",
        "LRNN_SE2D_stim_selec_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE2D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE2D_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE2D_1D_PCA_sssl, fig_file_name = 'PDM_LRNN_SE2D/decisionpca_sampleperiodstimselective_LU_LRNN_SE2D' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE2D_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsS2s2n3xFa8",
        "outputId": "adc71c42-c5c9-41ad-8253-bf78442a6925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(60), np.int64(19), np.int64(15), np.int64(31), np.int64(21), np.int64(9)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.516\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 51.6 %\n",
            "Performance Difference: 48.4 %\n",
            "Figure saved to PDM_LRNN_SE2D/decisionpca_sampleperiodstimselective_LU_LRNN_SE2D_1d_pca.png\n",
            "Figure saved to PDM_LRNN_SE2D/decisionpca_sampleperiodstimselective_LU_LRNN_SE2D_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN_SE3D"
      ],
      "metadata": {
        "id": "AKqtw8YUxEXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LRNN-SE3D\n",
        "\n",
        "### Sample Stimulus Selective\n",
        "\n",
        "# Sample Period\n",
        "LRNN_SE3D_testing_data_stim1_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "LRNN_SE3D_testing_data_stim2_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "# LRNN_SE3D_testing_data_stim1_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# LRNN_SE3D_testing_data_stim2_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "# Data from Partition\n",
        "LRNN_SE3D_stim_1_data_selec_leison = LRNN_SE3D_testing_data_stim1_stimulus_period\n",
        "LRNN_SE3D_stim_2_data_selec_leison = LRNN_SE3D_testing_data_stim2_stimulus_period\n",
        "# LRNN_SE3D_stim_1_data_selec_leison = LRNN_SE3D_testing_data_stim1_all_period\n",
        "# LRNN_SE3D_stim_2_data_selec_leison = LRNN_SE3D_testing_data_stim2_all_period\n",
        "LRNN_SE3D_sample_stim_data_dicts = [LRNN_SE3D_stim_1_data_selec_leison['testing_trial_and_activity'], LRNN_SE3D_stim_2_data_selec_leison['testing_trial_and_activity']]\n",
        "\n",
        "# LRNN_SE3D_1D_PCA_sssl = LRNN_SE3D_one_d_stimulus_pca\n",
        "# LRNN_SE3D_2D_PCA_sssl = LRNN_SE3D_two_d_stimulus_pca\n",
        "# LRNN_SE3D_1D_PCA_sssl = LRNN_SE3D_one_d_delay_pca\n",
        "# LRNN_SE3D_2D_PCA_sssl = LRNN_SE3D_two_d_delay_pca\n",
        "LRNN_SE3D_1D_PCA_sssl = LRNN_SE3D_one_d_decision_pca\n",
        "LRNN_SE3D_2D_PCA_sssl = LRNN_SE3D_two_d_decision_pca\n",
        "# LRNN_SE3D_1D_PCA_sssl = LRNN_SE3D_one_d_all_pca\n",
        "# LRNN_SE3D_2D_PCA_sssl = LRNN_SE3D_two_d_all_pca\n",
        "\n",
        "\n",
        "LRNN_SE3D_stim_selec_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE3D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE3D_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE3D_1D_PCA_sssl, fig_file_name = 'PDM_LRNN_SE3D/decisionpca_sampleperiodstimselective_LU_LRNN_SE3D' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE3D_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKdpuK4yxGHM",
        "outputId": "dc44fff0-300c-4257-b1a7-4c7e0c35b989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(63), np.int64(28), np.int64(54), np.int64(59), np.int64(57), np.int64(47)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.501\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 50.1 %\n",
            "Performance Difference: 49.9 %\n",
            "Figure saved to PDM_LRNN_SE3D/decisionpca_sampleperiodstimselective_LU_LRNN_SE3D_1d_pca.png\n",
            "Figure saved to PDM_LRNN_SE3D/decisionpca_sampleperiodstimselective_LU_LRNN_SE3D_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN_EI"
      ],
      "metadata": {
        "id": "YlLFsrTRxEj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LRNN-EI\n",
        "\n",
        "### Sample Stimulus Selective\n",
        "\n",
        "# Sample Period\n",
        "# LRNN_EI_testing_data_stim1_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "# LRNN_EI_testing_data_stim2_stimulus_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='stimulus')\n",
        "\n",
        "LRNN_EI_testing_data_stim1_delay_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='delay')\n",
        "\n",
        "LRNN_EI_testing_data_stim2_delay_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True, hla_index='delay')\n",
        "# LRNN_EI_testing_data_stim1_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim1, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# LRNN_EI_testing_data_stim2_all_period = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_testing_data_stim2, dict_of_conds= {'network_correct': True}, return_like_full=True)\n",
        "\n",
        "# Data from Partition\n",
        "# LRNN_EI_stim_1_data_selec_leison = LRNN_EI_testing_data_stim1_all_period\n",
        "# LRNN_EI_stim_2_data_selec_leison = LRNN_EI_testing_data_stim2_all_period\n",
        "# LRNN_EI_stim_1_data_selec_leison = LRNN_EI_testing_data_stim1_stimulus_period\n",
        "# LRNN_EI_stim_2_data_selec_leison = LRNN_EI_testing_data_stim2_stimulus_period\n",
        "LRNN_EI_stim_1_data_selec_leison = LRNN_EI_testing_data_stim1_delay_period\n",
        "LRNN_EI_stim_2_data_selec_leison = LRNN_EI_testing_data_stim2_delay_period\n",
        "LRNN_EI_sample_stim_data_dicts = [LRNN_EI_stim_1_data_selec_leison['testing_trial_and_activity'], LRNN_EI_stim_2_data_selec_leison['testing_trial_and_activity']]\n",
        "\n",
        "# LRNN_EI_1D_PCA_sssl = LRNN_EI_one_d_stimulus_pca\n",
        "# LRNN_EI_2D_PCA_sssl = LRNN_EI_two_d_stimulus_pca\n",
        "# LRNN_EI_1D_PCA_sssl = LRNN_EI_one_d_delay_pca\n",
        "# LRNN_EI_2D_PCA_sssl = LRNN_EI_two_d_delay_pca\n",
        "LRNN_EI_1D_PCA_sssl = LRNN_EI_one_d_decision_pca\n",
        "LRNN_EI_2D_PCA_sssl = LRNN_EI_two_d_decision_pca\n",
        "# LRNN_EI_1D_PCA_sssl = LRNN_EI_one_d_all_pca\n",
        "# LRNN_EI_2D_PCA_sssl = LRNN_EI_two_d_all_pca\n",
        "\n",
        "\n",
        "LRNN_EI_stim_selec_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_EI_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_EI_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_EI_1D_PCA_sssl, fig_file_name = 'PDM_LRNN_EI/decision_leisoned_unleisoned_LRNN_EI_SS_delay_periodsel' , file_ext='.png', unleisoned_PCA_2d = LRNN_EI_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq7SABERxGZq",
        "outputId": "6d3beb2e-e6f4-4124-c8a7-b6dce4364f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: EIRecLinear()\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(10), np.int64(49), np.int64(50), np.int64(9), np.int64(21), np.int64(28)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.483\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 48.3 %\n",
            "Performance Difference: 51.7 %\n",
            "Figure saved to PDM_LRNN_EI/decision_leisoned_unleisoned_LRNN_EI_SS_delay_periodsel_1d_pca.png\n",
            "Figure saved to PDM_LRNN_EI/decision_leisoned_unleisoned_LRNN_EI_SS_delay_periodsel_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPA"
      ],
      "metadata": {
        "id": "mswkpuZMPssl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Package Inits"
      ],
      "metadata": {
        "id": "tJsV_uxVPuQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/fixed-point-finder-master')\n",
        "%cd fixed-point-finder-master\n",
        "from FixedPointFinderTorch import FixedPointFinderTorch as FixedPointFinder\n",
        "import torch\n",
        "%cd .."
      ],
      "metadata": {
        "id": "3FwysyewPtj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b8966c-229e-441c-dd12-b72f5662b180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fixed-point-finder-master\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPF Implementation for BIC Networks"
      ],
      "metadata": {
        "id": "fGG7lM5uoa1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixation_input_array = np.array([[1.0,0.0,0.0]])\n",
        "delay_input_array = np.array([[1.0,0.0,0.0]])\n",
        "response_input_array = np.array([[0.0,0.0,0.0]])\n",
        "\n",
        "stim_1_input_array = np.array([[1.0,1.0,0.0]]) # try for now, likely need actual coherence adjusted values\n",
        "stim_2_input_array = np.array([[1.0,0.0,1.0]])\n"
      ],
      "metadata": {
        "id": "sBEn-2A3qR7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper for BIC RNN Layers"
      ],
      "metadata": {
        "id": "qQubMtF_ousL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedPointRNNWrapper_BIC(torch.nn.Module):\n",
        "    def __init__(self, rnn, batch_first=False):\n",
        "        super(FixedPointRNNWrapper_BIC, self).__init__()\n",
        "        self.rnn = rnn\n",
        "        self.batch_first = batch_first  # Ensure this matches your RNN's setting\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # # Squeeze the extra dimension from hidden state\n",
        "        # # Hidden shape transforms from [1, batch_size, hidden_size] to [batch_size, hidden_size]\n",
        "        # hidden = hidden.squeeze(0)\n",
        "\n",
        "        # # EI-RNN expects inputs of shape [seq_len, batch_size, input_size]\n",
        "        # # Since we have seq_len=1, input shape is already correct\n",
        "\n",
        "        # Forward pass through your EI-RNN\n",
        "        output, hidden = self.rnn.forward_helper_fpf(input, hidden)\n",
        "\n",
        "        # # Unsqueeze hidden to match FixedPointFinder's expectation\n",
        "        # # Hidden shape transforms from [batch_size, hidden_size] to [1, batch_size, hidden_size]\n",
        "        # hidden = hidden.unsqueeze(0)\n",
        "\n",
        "        # Return None for output as per FixedPointFinder's requirement # not a requirement\n",
        "        return None, hidden"
      ],
      "metadata": {
        "id": "_EqPKF4slEbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-NBIC"
      ],
      "metadata": {
        "id": "AH3V3OLLoiFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do state tracked testing trials\n",
        "# LRNN_NBIC_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_NBIC_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_NBIC_STATETRACKED_full_testing_data = LRNN_NBIC_full_testing_data_correct"
      ],
      "metadata": {
        "id": "glpgsyonixje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_tracked_env_info = LRNN_NBIC_STATETRACKED_full_testing_data['testing_env_info']"
      ],
      "metadata": {
        "id": "0kCWVuPbkP0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_NBIC_TRAINED.rnn)"
      ],
      "metadata": {
        "id": "BfNSPIm1mIPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC Sample Period"
      ],
      "metadata": {
        "id": "6ftp1X41o-Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim1_delaypca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim2_delaypca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim1_decisionpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim2_decisionpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim1_allpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in ALL PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim2_allpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in ALL PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "ee7keb82txo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad72e69-89f2-4e90-b2e8-4c93edbc466d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 3.27e-12 +/- 1.51e-11\n",
            "\t\tdq = 2.13e-14 +/- 1.06e-13\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.55e-03 sec\n",
            "\tIdentified 2 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 2 outliers detected (of 2).\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(0, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim1_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 4.58e-04 +/- 7.92e-03\n",
            "\t\tdq = 3.03e-11 +/- 6.08e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.51e-03 sec\n",
            "\tIdentified 40 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 39 outliers detected (of 40).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim2_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 3.18e-12 +/- 1.65e-11\n",
            "\t\tdq = 7.03e-14 +/- 2.44e-13\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.62e-03 sec\n",
            "\tIdentified 2 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 2 outliers detected (of 2).\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(0, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim1_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1772 iters\n",
            "\t\tq = 3.44e-04 +/- 6.86e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.44e-03 sec\n",
            "\tIdentified 58 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 57 outliers detected (of 58).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_FPF_Stim2_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC Delay Period"
      ],
      "metadata": {
        "id": "t50iv63wpF-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_DelayFPF_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_decision_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_DelayFPF_decisionpca.png', title_for_plot = 'Delay Fixed Points Plotted in Decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_all_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_DelayFPF_allpca.png', title_for_plot = 'Delay Fixed Points Plotted in All PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "REt5Lm1njwer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7adc9af2-02bc-43ef-d8c6-fc5d76ae0524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 8.56e-12 +/- 2.66e-11\n",
            "\t\tdq = 1.52e-14 +/- 4.61e-14\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.90e-03 sec\n",
            "\tIdentified 3 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 3).\n",
            "\tComputing recurrent Jacobian at 3 unique fixed points.\n",
            "\tComputing input Jacobian at 3 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(3, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_DelayFPF_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 8.25e-12 +/- 1.80e-11\n",
            "\t\tdq = 1.83e-14 +/- 5.86e-14\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.04e-03 sec\n",
            "\tIdentified 2 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 2).\n",
            "\tComputing recurrent Jacobian at 2 unique fixed points.\n",
            "\tComputing input Jacobian at 2 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(2, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_DelayFPF_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC - Decision Period"
      ],
      "metadata": {
        "id": "Z64wVLTtpR3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_decision_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_Decision_decisionpca.png', title_for_plot = 'Decision Fixed Points Plotted in Decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_all_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NBIC/LRNN_NBIC_Decision_allpca.png', title_for_plot = 'Decision Fixed Points Plotted in ALL PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "7DaxcC89TVk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513ba080-7093-4e3e-d233-0153e3995e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.73e-03 +/- 3.23e-03\n",
            "\t\tdq = 4.92e-10 +/- 9.73e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.18e-03 sec\n",
            "\tIdentified 212 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 212).\n",
            "\tComputing recurrent Jacobian at 212 unique fixed points.\n",
            "\tComputing input Jacobian at 212 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(212, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_Decision_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.69e-03 +/- 3.29e-03\n",
            "\t\tdq = 1.06e-09 +/- 2.20e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.02e-03 sec\n",
            "\tIdentified 222 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 222).\n",
            "\tComputing recurrent Jacobian at 222 unique fixed points.\n",
            "\tComputing input Jacobian at 222 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(222, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NBIC/LRNN_NBIC_Decision_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTHI8M4tpgxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF LRNN_NSC"
      ],
      "metadata": {
        "id": "E2W5-QjHxuYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FPF - LRNN-NSC\n",
        "\n",
        "# Do state tracked testing trials\n",
        "# LRNN_NSC_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_NSC_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_NSC_STATETRACKED_full_testing_data = LRNN_NSC_full_testing_data_correct\n",
        "\n",
        "state_tracked_env_info = LRNN_NSC_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_NSC_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_NSC_TRAINED.rnn)\n",
        "\n",
        "### FPF LRNN-NSC Sample Period\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NSC/LRNN_NSC_FPF_Stim1_delaypca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NSC/LRNN_NSC_FPF_Stim2_delaypca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-NSC Delay Period\n",
        "\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NSC/LRNN_NSC_DelayFPF_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-NSC - Decision Period\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_NSC/LRNN_NSC_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Z53Lusxv1u",
        "outputId": "dfc6859a-5248-4b90-c557-0afd5ff15aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t356 iters\n",
            "\t\tq = 4.40e-13 +/- 1.20e-13\n",
            "\t\tdq = 8.54e-14 +/- 8.68e-14\n",
            "\t\tlearning rate = 3.97e-01\n",
            "\t\tavg iter time = 2.96e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_FPF_Stim1_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t337 iters\n",
            "\t\tq = 4.38e-13 +/- 1.35e-13\n",
            "\t\tdq = 1.11e-13 +/- 1.15e-12\n",
            "\t\tlearning rate = 1.94e-01\n",
            "\t\tavg iter time = 2.91e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_FPF_Stim2_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t332 iters\n",
            "\t\tq = 2.56e-13 +/- 5.98e-14\n",
            "\t\tdq = 1.21e-13 +/- 1.88e-12\n",
            "\t\tlearning rate = 5.40e-01\n",
            "\t\tavg iter time = 2.96e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_DelayFPF_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.07e-03 +/- 1.01e-03\n",
            "\t\tdq = 4.21e-10 +/- 4.98e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.24e-03 sec\n",
            "\tIdentified 133 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 133).\n",
            "\tComputing recurrent Jacobian at 133 unique fixed points.\n",
            "\tComputing input Jacobian at 133 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(133, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_NSC/LRNN_NSC_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF LRNN_SE2D"
      ],
      "metadata": {
        "id": "pxRKIUW9xxcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FPF - LRNN-SE2D\n",
        "\n",
        "# Do state tracked testing trials\n",
        "# LRNN_SE2D_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_SE2D_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_SE2D_STATETRACKED_full_testing_data = LRNN_SE2D_full_testing_data_correct\n",
        "\n",
        "state_tracked_env_info = LRNN_SE2D_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_SE2D_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_SE2D_TRAINED.rnn)\n",
        "\n",
        "### FPF LRNN-SE2D Sample Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim1_delaypca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim2_delaypca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim1_decisionpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim2_decisionpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim1_allpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim2_allpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-SE2D Delay Period\n",
        "\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_DelayFPF_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_decision_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_DelayFPF_decisionpca.png', title_for_plot = 'Delay Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_all_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_DelayFPF_allpca.png', title_for_plot = 'Delay Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-SE2D - Decision Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_decision_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_Decision_decisionpca.png', title_for_plot = 'Decision Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_all_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE2D/LRNN_SE2D_Decision_allpca.png', title_for_plot = 'Decision Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbPvtaix8Cr",
        "outputId": "23afc5a7-a122-4710-bf1f-d33e6d123a70",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t328 iters\n",
            "\t\tq = 4.06e-13 +/- 1.24e-13\n",
            "\t\tdq = 7.78e-14 +/- 3.27e-13\n",
            "\t\tlearning rate = 3.24e-01\n",
            "\t\tavg iter time = 1.46e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim1_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t357 iters\n",
            "\t\tq = 2.80e-13 +/- 1.39e-13\n",
            "\t\tdq = 6.91e-14 +/- 1.65e-13\n",
            "\t\tlearning rate = 1.75e-01\n",
            "\t\tavg iter time = 1.95e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim2_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t301 iters\n",
            "\t\tq = 3.89e-13 +/- 8.12e-14\n",
            "\t\tdq = 1.84e-12 +/- 8.69e-12\n",
            "\t\tlearning rate = 1.94e-01\n",
            "\t\tavg iter time = 1.47e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim1_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t340 iters\n",
            "\t\tq = 4.31e-13 +/- 1.65e-13\n",
            "\t\tdq = 1.06e-13 +/- 9.25e-13\n",
            "\t\tlearning rate = 2.04e-01\n",
            "\t\tavg iter time = 1.52e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_FPF_Stim2_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t350 iters\n",
            "\t\tq = 1.42e-13 +/- 3.84e-14\n",
            "\t\tdq = 4.77e-14 +/- 1.96e-13\n",
            "\t\tlearning rate = 4.18e-01\n",
            "\t\tavg iter time = 2.29e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_DelayFPF_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t321 iters\n",
            "\t\tq = 1.44e-13 +/- 5.90e-14\n",
            "\t\tdq = 2.58e-13 +/- 7.91e-12\n",
            "\t\tlearning rate = 2.92e-01\n",
            "\t\tavg iter time = 3.13e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_DelayFPF_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.43e-03 +/- 1.22e-03\n",
            "\t\tdq = 3.57e-10 +/- 3.90e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.00e-03 sec\n",
            "\tIdentified 134 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 134).\n",
            "\tComputing recurrent Jacobian at 134 unique fixed points.\n",
            "\tComputing input Jacobian at 134 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(134, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_Decision_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.37e-03 +/- 1.20e-03\n",
            "\t\tdq = 4.82e-10 +/- 4.86e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.60e-03 sec\n",
            "\tIdentified 120 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 120).\n",
            "\tComputing recurrent Jacobian at 120 unique fixed points.\n",
            "\tComputing input Jacobian at 120 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(120, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE2D/LRNN_SE2D_Decision_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF LRNN_SE3D"
      ],
      "metadata": {
        "id": "lKW3b9mXxxkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FPF - LRNN-SE3D\n",
        "\n",
        "# Do state tracked testing trials\n",
        "# LRNN_SE3D_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_SE3D_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_SE3D_STATETRACKED_full_testing_data = LRNN_SE3D_full_testing_data_correct\n",
        "\n",
        "state_tracked_env_info = LRNN_SE3D_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_SE3D_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_SE3D_TRAINED.rnn)\n",
        "\n",
        "### FPF LRNN-SE3D Sample Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim1_delaypca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim2_delaypca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim1_decisionpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim2_decisionpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim1_allpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim2_allpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-SE3D Delay Period\n",
        "\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_DelayFPF_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_decision_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_DelayFPF_decisionpca.png', title_for_plot = 'Delay Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_all_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_DelayFPF_allpca.png', title_for_plot = 'Delay Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-SE3D - Decision Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_decision_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_Decision_decisionpca.png', title_for_plot = 'Decision Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_all_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_SE3D/LRNN_SE3D_Decision_allpca.png', title_for_plot = 'Decision Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJdTIe6JyJRD",
        "outputId": "4da97ba5-0321-4cdd-fd89-c25ed28c26b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t458 iters\n",
            "\t\tq = 5.87e-13 +/- 1.22e-13\n",
            "\t\tdq = 1.04e-13 +/- 7.34e-14\n",
            "\t\tlearning rate = 2.15e-01\n",
            "\t\tavg iter time = 2.25e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim1_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t387 iters\n",
            "\t\tq = 4.49e-13 +/- 1.69e-13\n",
            "\t\tdq = 1.45e-13 +/- 1.07e-13\n",
            "\t\tlearning rate = 3.24e-01\n",
            "\t\tavg iter time = 1.51e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim2_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t445 iters\n",
            "\t\tq = 5.81e-13 +/- 1.37e-13\n",
            "\t\tdq = 1.27e-13 +/- 7.72e-14\n",
            "\t\tlearning rate = 2.04e-01\n",
            "\t\tavg iter time = 1.57e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim1_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t393 iters\n",
            "\t\tq = 4.64e-13 +/- 1.64e-13\n",
            "\t\tdq = 1.14e-13 +/- 7.51e-14\n",
            "\t\tlearning rate = 3.07e-01\n",
            "\t\tavg iter time = 1.56e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_FPF_Stim2_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t371 iters\n",
            "\t\tq = 4.26e-13 +/- 1.20e-13\n",
            "\t\tdq = 1.12e-13 +/- 1.43e-13\n",
            "\t\tlearning rate = 4.40e-01\n",
            "\t\tavg iter time = 1.51e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_DelayFPF_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t383 iters\n",
            "\t\tq = 4.36e-13 +/- 1.28e-13\n",
            "\t\tdq = 1.06e-13 +/- 8.69e-14\n",
            "\t\tlearning rate = 4.88e-01\n",
            "\t\tavg iter time = 1.87e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_DelayFPF_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.20e-03 +/- 3.25e-03\n",
            "\t\tdq = 2.61e-10 +/- 6.61e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.61e-03 sec\n",
            "\tIdentified 145 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 145).\n",
            "\tComputing recurrent Jacobian at 145 unique fixed points.\n",
            "\tComputing input Jacobian at 145 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(145, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_Decision_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.07e-03 +/- 3.12e-03\n",
            "\t\tdq = 1.99e-10 +/- 5.53e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 1.56e-03 sec\n",
            "\tIdentified 145 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 145).\n",
            "\tComputing recurrent Jacobian at 145 unique fixed points.\n",
            "\tComputing input Jacobian at 145 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(145, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_SE3D/LRNN_SE3D_Decision_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF LRNN_EI"
      ],
      "metadata": {
        "id": "_1MWfvnexxsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FPF - LRNN-EI\n",
        "\n",
        "# Do state tracked testing trials\n",
        "# LRNN_EI_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_EI_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_EI_STATETRACKED_full_testing_data = LRNN_EI_full_testing_data_correct\n",
        "\n",
        "state_tracked_env_info = LRNN_EI_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_EI_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_EI_TRAINED.rnn)\n",
        "\n",
        "### FPF LRNN-EI Sample Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim1_delaypca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim2_delaypca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim1_decisionpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_decision_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim2_decisionpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_1_input_array, trial_cond_for_plot = {'ground_truth': 1}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim1_allpca.png', title_for_plot = 'Stimulus 1 > Stimulus 2 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_all_pca, ic_period = 'stimulus', fixed_input_array_ = stim_2_input_array, trial_cond_for_plot = {'ground_truth': 2}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_FPF_Stim2_allpca.png', title_for_plot = 'Stimulus 2 > Stimulus 1 Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-EI Delay Period\n",
        "\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_DelayFPF_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_decision_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_DelayFPF_decisionpca.png', title_for_plot = 'Delay Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_all_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_DelayFPF_allpca.png', title_for_plot = 'Delay Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "\n",
        "### FPF LRNN-EI - Decision Period\n",
        "\n",
        "# run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_decision_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_Decision_decisionpca.png', title_for_plot = 'Decision Fixed Points Plotted in decision PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_all_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'PDM_LRNN_EI/LRNN_EI_Decision_allpca.png', title_for_plot = 'Decision Fixed Points Plotted in all PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jYM_KgNx2-3",
        "outputId": "97e22ec8-108d-4d12-e4a3-b68d9b40bf08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t993 iters\n",
            "\t\tq = 4.04e-15 +/- 3.37e-14\n",
            "\t\tdq = 6.82e-16 +/- 2.07e-15\n",
            "\t\tlearning rate = 4.61e-02\n",
            "\t\tavg iter time = 1.89e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_FPF_Stim1_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t341 iters\n",
            "\t\tq = 1.19e-13 +/- 6.47e-14\n",
            "\t\tdq = 4.93e-14 +/- 7.04e-13\n",
            "\t\tlearning rate = 1.58e-01\n",
            "\t\tavg iter time = 1.86e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 1 outliers detected (of 1).\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(0, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_FPF_Stim2_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t837 iters\n",
            "\t\tq = 7.02e-14 +/- 6.27e-14\n",
            "\t\tdq = 3.29e-14 +/- 4.02e-14\n",
            "\t\tlearning rate = 1.35e-01\n",
            "\t\tavg iter time = 2.53e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_FPF_Stim1_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t316 iters\n",
            "\t\tq = 3.31e-13 +/- 1.59e-13\n",
            "\t\tdq = 1.39e-13 +/- 1.35e-12\n",
            "\t\tlearning rate = 3.24e-01\n",
            "\t\tavg iter time = 1.93e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 1 outliers detected (of 1).\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(0, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_FPF_Stim2_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t326 iters\n",
            "\t\tq = 5.71e-14 +/- 2.19e-14\n",
            "\t\tdq = 4.81e-14 +/- 1.04e-12\n",
            "\t\tlearning rate = 5.40e-01\n",
            "\t\tavg iter time = 2.36e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_DelayFPF_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t336 iters\n",
            "\t\tq = 4.66e-14 +/- 3.71e-14\n",
            "\t\tdq = 2.48e-14 +/- 3.48e-13\n",
            "\t\tlearning rate = 5.13e-01\n",
            "\t\tavg iter time = 2.45e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_DelayFPF_allpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t2637 iters\n",
            "\t\tq = 5.63e-05 +/- 4.71e-05\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 2.82e-07\n",
            "\t\tavg iter time = 3.23e-03 sec\n",
            "\tIdentified 114 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 114).\n",
            "\tComputing recurrent Jacobian at 114 unique fixed points.\n",
            "\tComputing input Jacobian at 114 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(114, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_Decision_decisionpca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t2663 iters\n",
            "\t\tq = 5.66e-05 +/- 4.73e-05\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 2.97e-07\n",
            "\t\tavg iter time = 2.45e-03 sec\n",
            "\tIdentified 104 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 104).\n",
            "\tComputing recurrent Jacobian at 104 unique fixed points.\n",
            "\tComputing input Jacobian at 104 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(104, 64)\n",
            "(1200, 64)\n",
            "Figure saved to PDM_LRNN_EI/LRNN_EI_Decision_allpca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwuTUxhpJZvG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
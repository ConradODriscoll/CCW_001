{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6iIYcnr02hH0",
        "iEJ5UG072zly",
        "cmLH2ZaP26A3",
        "C4KfC0k33ap8",
        "cskcUXhNnJUI",
        "ieVSoT-0TvDE",
        "Af3fBq_dsjSr",
        "TPPM61ACUCdN",
        "-CwvtZqNUQ4u",
        "zL0BDeMSfwS0",
        "8_hsHMkNvlEf",
        "_QlfAF6-3VCi",
        "aaxk0FML3Mjo",
        "_JQs02fl2iku",
        "ZSh2Vp642kA2",
        "HvHFRufh2rl6",
        "NM7lAtJr2vsG",
        "QxzpezHJ22k1",
        "XgC5yYHBe7Ua",
        "1MgUxm5ufIf3",
        "CcXT-CFu_iUr",
        "ioSrj2gn_lSH",
        "RYSZ0vey_odj",
        "4mI6cbxiD4vk",
        "TYW3x6FnESmc",
        "K0pdtrLcL9fw",
        "RVWP0Uu5L-0P"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "REALLY HACKY FIX FOR OBTAINING Hidden State:\n",
        "- Swapped the keys for the testing function (bic version) such that hidden state tensor is located at the 'network_activity' key, and hidden layer output activity is located at 'network_hidden_state'\n",
        "- This means. IF I WANT TO RUN IT AGAIN BUT USE THE OUTPUT ACTIVITY FOR THE ANALYSIS AND THEN USE HIDDEN STATE FPS WITH RELU ACTIVATION TO PLOT ALONGSIDE THE HIDDEN LAYER OUTPUT ACTIVITY FROM TESTING TRIALS:\n",
        "  -  NEED TO RE RUN WITH THE FOLLOWING:\n",
        "    - Keys swapped back (in testing func)\n",
        "    - hidden_key (in FPF input) == 'network_hidden_state'\n",
        "    - (Easier to copy note book and rerun like this)"
      ],
      "metadata": {
        "id": "V3fyHK95Dvjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CURRENT MODE == ANALYSE HIDDEN ACTIVITY (not hidden state)"
      ],
      "metadata": {
        "id": "s5qbdCjhEk_H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUDlYYGuDvC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages ((un)comment neuro and sb imports)"
      ],
      "metadata": {
        "id": "FY1zE_W-zNCH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsikeBzf22lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWp1iecHfRWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2396e570-d071-457e-d557-aab927ffa2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neurogym in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.11/dist-packages (from neurogym) (2.10.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from neurogym) (4.67.1)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.13.3)\n",
            "Requirement already satisfied: numpy==2.1.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (2.1.3)\n",
            "Requirement already satisfied: gymnasium==0.29.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (0.29.1)\n",
            "Requirement already satisfied: matplotlib==3.9.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (3.9.4)\n",
            "Requirement already satisfied: scipy==1.14.* in /usr/local/lib/python3.11/dist-packages (from neurogym) (1.14.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.*->neurogym) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.*->neurogym) (2.9.0.post0)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings->neurogym) (0.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->pydantic-settings->neurogym) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->pydantic-settings->neurogym) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.*->neurogym) (1.17.0)\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-6575_315\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-6575_315\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit bf51a6233a8f934a68430f8f78e44360410d23ca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (0.29.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3==2.7.0) (3.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3==2.7.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3==2.7.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3==2.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3==2.7.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3==2.7.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: stable_baselines3\n",
            "  Building wheel for stable_baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable_baselines3: filename=stable_baselines3-2.7.0-py3-none-any.whl size=187216 sha256=08a456f28f9662b6e5226246f14637dbdd2d5777e8cbd3be66c9354be4c09566\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-namrba7a/wheels/4e/50/0a/1b04f64886428aef488eca102d1c66b00f5218ca4ec32fa9e6\n",
            "Successfully built stable_baselines3\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.7.0\n",
            "Collecting git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
            "  Cloning https://github.com/Stable-Baselines-Team/stable-baselines3-contrib to /tmp/pip-req-build-acyju2zq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Stable-Baselines-Team/stable-baselines3-contrib /tmp/pip-req-build-acyju2zq\n",
            "  Resolved https://github.com/Stable-Baselines-Team/stable-baselines3-contrib to commit 33889dbb215b8992bf463551657b79241f4bccf8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sb3_contrib==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.29.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib==2.7.0) (3.0.2)\n",
            "Building wheels for collected packages: sb3_contrib\n",
            "  Building wheel for sb3_contrib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sb3_contrib: filename=sb3_contrib-2.7.0-py3-none-any.whl size=93173 sha256=bbabba70aef32b83432d7aa20de2441ed7df6ce52e4e5d1829ef8e0f26d092bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zxsf7mp4/wheels/f0/c6/aa/f7853333ad7a263ac541ccb1fff7a8ebcb1d94855318f2a49a\n",
            "Successfully built sb3_contrib\n",
            "Installing collected packages: sb3_contrib\n",
            "Successfully installed sb3_contrib-2.7.0\n",
            "Collecting deepdiff\n",
            "  Downloading deepdiff-8.5.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Downloading deepdiff-8.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: orderly-set, deepdiff\n",
            "Successfully installed deepdiff-8.5.0 orderly-set-5.5.0\n"
          ]
        }
      ],
      "source": [
        "# # # # Uncomment VV for session restart\n",
        "!pip install neurogym\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "!pip install git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "!pip install deepdiff\n",
        "\n",
        "\n",
        "\n",
        "# MODEL_IO_NSC = False\n",
        "# MODEL_IO_SE2D = False\n",
        "# MODEL_IO_SE3D = False\n",
        "# MODEL_IO_EI = False\n",
        "# MODEL_IO_NBIC = False\n",
        "\n",
        "# Use models instead of re-training every time\n",
        "## NEED TO MAKE SURE HAVE folders and files e.g NBIC : LRNN_NBIC/LRNN_NBIC.pth\n",
        "## training funcs spit out LRNN_NBIC_best.pth but training in dev nb doesnt so not gonna change\n",
        "MODEL_IO_NSC = True\n",
        "MODEL_IO_SE2D = True\n",
        "MODEL_IO_SE3D = True\n",
        "MODEL_IO_EI = True\n",
        "MODEL_IO_NBIC = True\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D-CJ15dewzV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from copy import deepcopy\n",
        "from sklearn.decomposition import PCA\n",
        "import itertools # Unused if not gridsearching\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"matplotlib\").setLevel(logging.CRITICAL)\n",
        "\n",
        "device = 'cpu'\n",
        "import neurogym as ngym\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Suppress UserWarnings specifically from the 'gymnasium' module\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Regime (Training with Validation Thresholding and Early Stopping)"
      ],
      "metadata": {
        "id": "6iIYcnr02hH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Function"
      ],
      "metadata": {
        "id": "iEJ5UG072zly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component function to run eval style trials on network for a single dataset (task trial setup)"
      ],
      "metadata": {
        "id": "i11UiICa3UBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6k_YFOjPeHr"
      },
      "outputs": [],
      "source": [
        "def validate_network(net, dataset, num_trials=200):\n",
        "    # same as test but no print statements\n",
        "    # Reset environment\n",
        "  env = dataset.env\n",
        "  env.reset()\n",
        "\n",
        "  # Initialise variables for logging\n",
        "  # perf = 0\n",
        "  activity_dict = {}  # recording activity\n",
        "  trial_infos = {}  # recording trial information\n",
        "\n",
        "  num_trial = num_trials\n",
        "  for i in range(num_trial):\n",
        "      # Neurogym boiler plate\n",
        "      # Sample a new trial\n",
        "      trial_info = env.new_trial()\n",
        "      # Observation and groud-truth of this trial\n",
        "      ob, gt = env.ob, env.gt\n",
        "      # Convert to numpy, add batch dimension to input\n",
        "      inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "      # Run the network for one trial\n",
        "      # inputs (SeqLen, Batch, InputSize)\n",
        "      # action_pred (SeqLen, Batch, OutputSize)\n",
        "      action_pred, _ = net(inputs)\n",
        "\n",
        "      # Compute performance\n",
        "      # First convert back to numpy\n",
        "\n",
        "      action_pred = action_pred.detach().numpy()[:, 0, :]\n",
        "      # Read out final choice at last time step\n",
        "      choice = np.argmax(action_pred[-1, :])\n",
        "      # Compare to ground truth\n",
        "      correct = choice == gt[-1]\n",
        "\n",
        "      # Record activity, trial information, choice, correctness\n",
        "      # rnn_activity = rnn_activity[:, 0, :].detach().numpy() # removed for new output signature of hidden state based networks (neither need it for validation anyway)\n",
        "      # activity_dict[i] = rnn_activity\n",
        "      trial_infos[i] = trial_info  # trial_info is a dictionary\n",
        "      trial_infos[i].update({'correct': correct})\n",
        "  avg_trial_performance = np.mean([val['correct'] for val in trial_infos.values()])\n",
        "  return trial_infos, activity_dict, avg_trial_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stop Validation Helper"
      ],
      "metadata": {
        "id": "cmLH2ZaP26A3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calling Validation Component for each validation data set and returning Performances to main training function"
      ],
      "metadata": {
        "id": "XCOwR_p-3R4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def early_stop_validation(model_in_training, validation_set_dict, validation_trials=200):\n",
        "  performance_dict = {}\n",
        "  for dataset_name, dataset in validation_set_dict.items():\n",
        "    trial_infos_valid, activity_dict_valid, avg_trial_performance_valid = validate_network(model_in_training, dataset, num_trials=validation_trials)\n",
        "    performance_dict[dataset_name] = avg_trial_performance_valid\n",
        "    # print(f'{dataset_name} - Accuracy : {avg_trial_performance_vt}')\n",
        "  return performance_dict\n"
      ],
      "metadata": {
        "id": "HOhkI7evHSvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Training Function"
      ],
      "metadata": {
        "id": "C4KfC0k33ap8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses Early Stop Validation Helper and a \"patience\" mechanism to implement early stopping for networks that have exceeded the require performance threshold across validation task trial setups but not exhibiting performance improvement from further training."
      ],
      "metadata": {
        "id": "w1beEFhb3dR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "# def training_with_early_stop(model, training_set, validation_set_dict, max_steps = 10000, min_validation_perf = 0.8, patience = 5, num_steps_for_early_stop_check = 500, num_validation_trials = 200, model_name = 'model_name', tr_output_mode = False):\n",
        "\n",
        "#       # validation_set_dict is like = {'Short': <neurogym dataset object> , ... }\n",
        "#       # training set is like <neurogym dataset object>\n",
        "\n",
        "#       # PERFORMANCE is each individual validation set accuracy\n",
        "#       # ACCURACY is the overall average of these\n",
        "#       # ES is for early stopping, i.e. perf/accuracy of validations that meet the es conditions (>threshold)\n",
        "#       # all is for all i.e. perf/accuracy of validations that haven't met the es conditions\n",
        "\n",
        "#       # we need to retain running loss / validation performances for plotting learning curves\n",
        "#       # Learning tracking\n",
        "#       # Training Loss Tracking\n",
        "#       tr_epochs_loss = []\n",
        "#       tr_loss = []\n",
        "\n",
        "#       # Validation Performance Tracking\n",
        "#       tr_epochs_valid_perf = []\n",
        "#       tr_valid_perfs_list_of_dicts = []\n",
        "#       tr_valid_perfs_avg = []\n",
        "#       n_steps_first_th = 0\n",
        "#       n_steps_final = 0\n",
        "\n",
        "#       # Setup\n",
        "#       optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
        "#       criterion = nn.CrossEntropyLoss()\n",
        "#       running_loss = 0\n",
        "#       running_acc = 0\n",
        "#       start_time = time.time()\n",
        "\n",
        "#       # Loop over training batches\n",
        "#       print('Training network...')\n",
        "\n",
        "#       current_best_valid_accuracy_es = 0.0\n",
        "#       current_best_valid_accuracy_all = 0.0\n",
        "\n",
        "\n",
        "#       # set best_valid_performance_es to a list of len n containing zeros where n is number of keys in validation_set_dict\n",
        "#       best_valid_performance_all = [0 for _ in validation_set_dict.keys()]\n",
        "#       best_valid_performance_es = [0 for _ in validation_set_dict.keys()]\n",
        "#       surpassed_threshold = False\n",
        "#       current_patience = patience\n",
        "#       model.train()\n",
        "#       model_save_name = f'{model_name}_best.pth'\n",
        "#       for i in range(max_steps):\n",
        "\n",
        "#           # Generate input and target, convert to pytorch tensor\n",
        "#           # inputs, labels = dataset()\n",
        "#           inputs, labels = training_set()\n",
        "#           inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "#           labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "#                   # boiler plate pytorch training:\n",
        "#           optimiser.zero_grad()   # zero the gradient buffers\n",
        "#           output, _ = model(inputs)\n",
        "#           # Reshape to (SeqLen x Batch, OutputSize)\n",
        "#           output_size = 3\n",
        "#           output = output.view(-1, output_size)\n",
        "\n",
        "#           loss = criterion(output, labels)\n",
        "\n",
        "#           loss.backward()\n",
        "#           optimiser.step()    # Does the update\n",
        "#           running_loss += loss.item()\n",
        "#           if i % 100 == 99:\n",
        "#             running_loss /= 100\n",
        "#             print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "#                 i+1, running_loss, time.time() - start_time))\n",
        "#             tr_epochs_loss.append(i+1)\n",
        "#             tr_loss.append(running_loss)\n",
        "\n",
        "#             running_loss = 0\n",
        "#           if (i + 1) % num_steps_for_early_stop_check == 0:\n",
        "#             model.eval()\n",
        "#             with torch.no_grad():\n",
        "#               current_perf_dict = early_stop_validation(model, validation_set_dict, num_validation_trials)\n",
        "#               print(f'Current Performance Dict: {current_perf_dict}')\n",
        "#               list_avg_perfs = list(current_perf_dict.values())\n",
        "#               average_perf = np.mean(list_avg_perfs)\n",
        "\n",
        "#               tr_epochs_valid_perf.append(i+1)\n",
        "#               tr_valid_perfs_list_of_dicts.append(current_perf_dict) # Means we retain labels for performance scores for the plot\n",
        "#               tr_valid_perfs_avg.append(average_perf)\n",
        "\n",
        "#               print(f'Current Average Performance: {average_perf}')\n",
        "#               status_list = [i>min_validation_perf for i in list_avg_perfs]\n",
        "\n",
        "#               performance_th_list = [i>j for i,j in zip(list_avg_perfs, best_valid_performance_all)]\n",
        "\n",
        "#               best_valid_performance_all = list_avg_perfs if all(performance_th_list) else best_valid_performance_all\n",
        "\n",
        "#               current_best_valid_accuracy_all = average_perf if average_perf > current_best_valid_accuracy_all else current_best_valid_accuracy_all\n",
        "#               if all(status_list):\n",
        "#                 surpassed_threshold = True\n",
        "#                 n_steps_first_th = i+1\n",
        "#                 num_steps_for_early_stop_check = 100\n",
        "#                 if average_perf > current_best_valid_accuracy_es:\n",
        "#                   current_best_valid_accuracy_es = average_perf\n",
        "#                   best_valid_performance_es = list_avg_perfs\n",
        "#                   # create a file of current best model\n",
        "#                   torch.save(model.state_dict(), model_save_name)\n",
        "#                   # Reset patience\n",
        "#                   current_patience = patience\n",
        "#                 elif ((average_perf == current_best_valid_accuracy_es) and (current_patience > 0)):\n",
        "#                   current_best_valid_accuracy_es = average_perf\n",
        "#                   best_valid_performance_es = list_avg_perfs\n",
        "#                   # create a file of current best model\n",
        "#                   torch.save(model.state_dict(), model_save_name)\n",
        "#                   # Dont Reset patience, continue to decrease (model trains a bit more beyond first attempt at 100)\n",
        "#                   current_patience -= 1\n",
        "\n",
        "#                 else:\n",
        "#                   if current_patience <= 0:\n",
        "#                     n_steps_final = i+1\n",
        "#                     print('Early Stopping. I have run out of patience Grrr' )\n",
        "#                     break\n",
        "#                   else:\n",
        "#                     current_patience -= 1\n",
        "#             model.train()\n",
        "#       learning_curve_dict = {\n",
        "#             'training_loss_epochs_list': tr_epochs_loss,\n",
        "#             'training_loss_values_list' : tr_loss,\n",
        "#             'validation_perf_epochs_list': tr_epochs_valid_perf,\n",
        "#             'validation_perf_dicts_list' : tr_valid_perfs_list_of_dicts,\n",
        "#             'validation_perf_avg_values_list' : tr_valid_perfs_avg,\n",
        "#             'n_steps_first_th' : n_steps_first_th,\n",
        "#             'n_steps_final' : n_steps_final\n",
        "#               }\n",
        "#       # Try to Load best model from last saved file. Handle for if it doesn't exist!\n",
        "#       try:\n",
        "#         model.load_state_dict(torch.load(model_save_name))\n",
        "#         print('Best model loaded')\n",
        "#         # Print best performance stats\n",
        "#         for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_es):\n",
        "#           print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "#         if tr_output_mode:\n",
        "#           return model, learning_curve_dict\n",
        "\n",
        "#         return model\n",
        "#       except:\n",
        "#         print('No best model that satisfies validation threshold found')\n",
        "#         print(f'Best all time performance: {current_best_valid_accuracy_all}')\n",
        "#         for valid_set_name, perf in zip(validation_set_dict.keys(),best_valid_performance_all):\n",
        "#           print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "#         if tr_output_mode:\n",
        "#           return model, learning_curve_dict\n",
        "\n",
        "#         return model"
      ],
      "metadata": {
        "id": "QRCZQ4EWLsyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function - BICs"
      ],
      "metadata": {
        "id": "ZQim61kTj0ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training_with_early_stop_and_regularisation(\n",
        "    model,\n",
        "    training_set,\n",
        "    validation_set_dict,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-3,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='model_name',\n",
        "    tr_output_mode=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains mode (optional wiring distance and activity regularisation if used in BICs),\n",
        "    keeps the early stop mechanism. Also tracks non task loss to plot if needed.\n",
        "    (Baso a Cleaned up version of the main training function with additional functionality for BICs - keep other in case ive fd up)\n",
        "    \"\"\"\n",
        "    # --- Setup ---\n",
        "    output_size = model.output_size\n",
        "    optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    start_time = time.time()\n",
        "    model_save_name = f'{model_name}_best.pth'\n",
        "\n",
        "    # --- Loss Tracking ---\n",
        "    tr_epochs_loss = []\n",
        "    tr_total_loss_values = []\n",
        "    tr_task_loss_values = []\n",
        "    tr_wiring_loss_values = []\n",
        "    tr_activity_loss_values = []\n",
        "    running_loss = 0\n",
        "    running_task_loss = 0\n",
        "    running_wiring_loss = 0\n",
        "    running_activity_loss = 0\n",
        "\n",
        "    # --- Validation and Early Stopping Tracking ---\n",
        "    tr_epochs_valid_perf = []\n",
        "    tr_valid_perfs_list_of_dicts = []\n",
        "    tr_valid_perfs_avg = []\n",
        "    n_steps_first_th = 0\n",
        "    n_steps_final = 0\n",
        "    current_best_valid_accuracy_es = 0.0\n",
        "    current_best_valid_accuracy_all = 0.0\n",
        "    best_valid_performance_all = [0 for _ in validation_set_dict.keys()]\n",
        "    best_valid_performance_es = [0 for _ in validation_set_dict.keys()]\n",
        "    surpassed_threshold = False\n",
        "    current_patience = patience\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    print('Training network...')\n",
        "    model.train()\n",
        "    for i in range(max_steps):\n",
        "        # --- Data ---\n",
        "        inputs, labels = training_set()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        # --- Forward Pass and Loss Calc ---\n",
        "        optimiser.zero_grad()\n",
        "        output, rnn_output = model(inputs) # Now Capturing rnn_output for activity loss\n",
        "        output = output.view(-1, output_size)\n",
        "\n",
        "        # 1. Task Loss (styll)\n",
        "        task_loss = criterion(output, labels)\n",
        "\n",
        "        # 2. Wiring Loss (is optional, adding 0 has no effect)\n",
        "        wiring_loss = torch.tensor(0.0)\n",
        "        if WD_approach:\n",
        "            wiring_loss = WD_regulariser(model)\n",
        "        elif 'penalise_weight_distance' in dir(model): # Check if method exists\n",
        "\n",
        "             wiring_loss = wiring_beta * model.penalise_weight_distance()\n",
        "\n",
        "        # 3. Activity Loss (optional)\n",
        "        activity_loss = torch.tensor(0.0)\n",
        "        if activity_regularisation:\n",
        "            activity_loss = activity_beta * torch.mean(rnn_output**2)\n",
        "\n",
        "        # Total Loss\n",
        "        loss = task_loss + wiring_loss + activity_loss\n",
        "\n",
        "        # --- Backprop and optmise step ---\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimiser.step()\n",
        "\n",
        "        # --- Tracking all loss components  ---\n",
        "        running_loss += loss.item()\n",
        "        running_task_loss += task_loss.item()\n",
        "        running_wiring_loss += wiring_loss.item()\n",
        "        running_activity_loss += activity_loss.item()\n",
        "        if i <= 1:\n",
        "          print(\"--- First Step Losses to Check Beta----\")\n",
        "          print(f\"Task Loss: {task_loss.item()}\")\n",
        "          print(f\"Wiring Loss: {wiring_loss.item()}\")\n",
        "          print(f\"Activity Loss: {activity_loss.item()}\")\n",
        "        if (i + 1) % 100 == 0:\n",
        "            # running losses\n",
        "            running_loss /= 100\n",
        "            running_task_loss /= 100\n",
        "            running_wiring_loss /= 100\n",
        "            running_activity_loss /= 100\n",
        "\n",
        "            print(f'Step {i+1}, Total Loss: {running_loss:.4f}, Time: {time.time() - start_time:.1f}s')\n",
        "            print(f' Loss Components -> Task: {running_task_loss:.4f}, Wiring: {running_wiring_loss:.4f}, Activity: {running_activity_loss:.4f}')\n",
        "\n",
        "            # Append to tracking lists\n",
        "            tr_epochs_loss.append(i + 1)\n",
        "            tr_total_loss_values.append(running_loss)\n",
        "            tr_task_loss_values.append(running_task_loss)\n",
        "            tr_wiring_loss_values.append(running_wiring_loss)\n",
        "            tr_activity_loss_values.append(running_activity_loss)\n",
        "\n",
        "            # Reset running losses\n",
        "            running_loss, running_task_loss, running_wiring_loss, running_activity_loss = 0, 0, 0, 0\n",
        "\n",
        "        # --- Early Stopping Check ---\n",
        "        if (i + 1) % num_steps_for_early_stop_check == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                current_perf_dict = early_stop_validation(model, validation_set_dict, num_validation_trials)\n",
        "                list_avg_perfs = list(current_perf_dict.values())\n",
        "                average_perf = np.mean(list_avg_perfs)\n",
        "\n",
        "                tr_epochs_valid_perf.append(i + 1)\n",
        "                tr_valid_perfs_list_of_dicts.append(current_perf_dict)\n",
        "                tr_valid_perfs_avg.append(average_perf)\n",
        "                print(f'Validation at Step {i+1} | Avg Perf: {average_perf:.3f}')\n",
        "\n",
        "                # Print all performances by key and perf value , without new line\n",
        "                for key, value in current_perf_dict.items():\n",
        "                    print(f'{key}: {value:.3f}', end=' ')\n",
        "                print()\n",
        "\n",
        "                status_list = [p > min_validation_perf for p in list_avg_perfs]\n",
        "                if all(status_list):\n",
        "                    if not surpassed_threshold:\n",
        "                        surpassed_threshold = True\n",
        "                        n_steps_first_th = i + 1\n",
        "                        num_steps_for_early_stop_check = 100 # Check more frequently after threshold\n",
        "                        print(\"Performance threshold surpassed. Checking more frequently.\")\n",
        "\n",
        "                    if average_perf > current_best_valid_accuracy_es:\n",
        "                        current_best_valid_accuracy_es = average_perf\n",
        "                        best_valid_performance_es = list_avg_perfs\n",
        "                        torch.save(model.state_dict(), model_save_name)\n",
        "                        current_patience = patience # Reset patience\n",
        "                        print(f\"New best model saved with avg perf: {average_perf:.3f}\")\n",
        "                    else:\n",
        "                        current_patience -= 1\n",
        "                        print(f\"No improvement. Patience left: {current_patience}\")\n",
        "\n",
        "                if surpassed_threshold and current_patience <= 0:\n",
        "                    n_steps_final = i + 1\n",
        "                    print('Early Stopping. I have run out of patience Grrr')\n",
        "                    break\n",
        "            model.train()\n",
        "\n",
        "    # final tracking dict\n",
        "    learning_curve_dict = {\n",
        "        'training_loss_epochs_list': tr_epochs_loss,\n",
        "        'training_total_loss_values_list': tr_total_loss_values,\n",
        "        'training_task_loss_values_list': tr_task_loss_values,\n",
        "        'training_wiring_loss_values_list': tr_wiring_loss_values,\n",
        "        'training_activity_loss_values_list': tr_activity_loss_values,\n",
        "        'validation_perf_epochs_list': tr_epochs_valid_perf,\n",
        "        'validation_perf_dicts_list': tr_valid_perfs_list_of_dicts,\n",
        "        'validation_perf_avg_values_list': tr_valid_perfs_avg,\n",
        "        'n_steps_first_th': n_steps_first_th,\n",
        "        'n_steps_final': n_steps_final\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_save_name))\n",
        "        print('Best model loaded.')\n",
        "        for valid_set_name, perf in zip(validation_set_dict.keys(), best_valid_performance_es):\n",
        "            print(f'Best {valid_set_name} performance: {perf}')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print('No best model was saved that satisfied the validation threshold.')\n",
        "\n",
        "    if tr_output_mode:\n",
        "        return model, learning_curve_dict\n",
        "    return model"
      ],
      "metadata": {
        "id": "XjEXaxFRoHpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Curve Visualisation"
      ],
      "metadata": {
        "id": "cskcUXhNnJUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(\n",
        "    learning_curve_dict,\n",
        "    average_only=False,\n",
        "    plot_loss_components=True,\n",
        "    filename=None,\n",
        "    show_legend=True,\n",
        "    legend_location='upper center'\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots training losses and validation accuracy from a learning_curve_dict.\n",
        "\n",
        "    Args:\n",
        "        learning_curve_dict: dict containing learning curve data.\n",
        "        average_only: If True, plots only average validation performance (instead of perf on each validation set).\n",
        "        plot_loss_components: If True, plots individual loss components (wiring, activity) if they were used.\n",
        "        filename: If provided, saves the figure (need to end with '.png'!.\n",
        "        show_legend: If True, displays the legend.\n",
        "        legend_location: Location of the legend (see bookmarked matplotlib page).\n",
        "    \"\"\"\n",
        "    # --- Unpack Data from Dictionary ---\n",
        "    # Loss Data\n",
        "    tr_epochs_loss = learning_curve_dict['training_loss_epochs_list']\n",
        "    tr_total_loss = learning_curve_dict['training_total_loss_values_list']\n",
        "    tr_task_loss = learning_curve_dict.get('training_task_loss_values_list', [])\n",
        "    tr_wiring_loss = learning_curve_dict.get('training_wiring_loss_values_list', [])\n",
        "    tr_activity_loss = learning_curve_dict.get('training_activity_loss_values_list', [])\n",
        "\n",
        "    # Validation Data\n",
        "    val_epochs = learning_curve_dict['validation_perf_epochs_list']\n",
        "    val_dicts = learning_curve_dict['validation_perf_dicts_list']\n",
        "    val_avg = learning_curve_dict['validation_perf_avg_values_list']\n",
        "\n",
        "    # Early Stopping Data\n",
        "    n_steps_final = learning_curve_dict.get('n_steps_final', None)\n",
        "    th_location = np.where(np.array(val_avg) > 0.8)[0][0] if np.any(np.array(val_avg) > 0.8) else None\n",
        "    n_steps_first_th = val_epochs[th_location] if th_location is not None else None\n",
        "\n",
        "    # --- Plotting ---\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Plot Training Losses on the left y-axis (ax1)\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss', color='tab:blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "    ax1.plot(tr_epochs_loss, tr_total_loss, color='tab:blue', label='Total Training Loss')\n",
        "\n",
        "    if plot_loss_components:\n",
        "        # Plot wiring loss if it was used\n",
        "        if np.any(tr_wiring_loss):\n",
        "            ax1.plot(tr_epochs_loss, tr_wiring_loss, color='tab:green', linestyle=':', label='Wiring Loss')\n",
        "        # Plot activity loss if it was used\n",
        "        if np.any(tr_activity_loss):\n",
        "            ax1.plot(tr_epochs_loss, tr_activity_loss, color='tab:cyan', linestyle=':', label='Activity Loss')\n",
        "\n",
        "    # Create a second y-axis for validation performance (ax2)\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel('Validation Performance', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "    ax2.set_ylim(0, 1.05) # Set y-axis for performance from 0 to 1\n",
        "\n",
        "    # Plot Validation Performance on the right y-axis (ax2)\n",
        "    if average_only:\n",
        "        ax2.plot(val_epochs, val_avg, color='tab:red', linestyle='--', label='Average Validation Performance')\n",
        "    else:\n",
        "        if val_dicts:\n",
        "            validation_set_names = list(val_dicts[0].keys())\n",
        "            # Use a colormap with highly contrasting colours\n",
        "            colors = plt.cm.get_cmap('Set1')(np.linspace(0, 1, len(validation_set_names)))\n",
        "\n",
        "            for i, name in enumerate(validation_set_names):\n",
        "                values = [d[name] for d in val_dicts]\n",
        "                ax2.plot(val_epochs, values, color=colors[i], linestyle='-', label=f'{name} Performance')\n",
        "\n",
        "    # Plot vertical lines for early stopping events\n",
        "    if n_steps_first_th is not None:\n",
        "        ax2.axvline(x=n_steps_first_th, color='gray', linestyle='--', label='Perf. Threshold Met')\n",
        "    if n_steps_final is not None and n_steps_final > 0:\n",
        "         ax2.axvline(x=n_steps_final, color='black', linestyle='--', label='Early Stopping')\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    if show_legend:\n",
        "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax2.legend(lines1 + lines2, labels1 + labels2, loc=legend_location)\n",
        "\n",
        "    plt.title('Learning Curve: Training Loss and Validation Performance vs. Epoch')\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Figure saved to {filename}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hmQmNNsKWHPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Regime"
      ],
      "metadata": {
        "id": "SMokBRwksnDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing - Functions"
      ],
      "metadata": {
        "id": "Pw6FJ4fijOB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Functions - Run Test Trials and Record Data Function"
      ],
      "metadata": {
        "id": "rUapAvGvjYxZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzqMSiTATjbr"
      },
      "outputs": [],
      "source": [
        "def evaluate_network_on_dataset(network, dataset_to_evaluate, num_trials=200):\n",
        "    \"\"\"\n",
        "    Evaluates the given network on NGym dataset and records trial data.\n",
        "\n",
        "    Args:\n",
        "        network: The network to evaluate.\n",
        "        dataset_to_evaluate: The NeuroGym dataset to use for evaluation.\n",
        "        num_trials (int): The number of trials to run for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing environmental information and detailed trial data\n",
        "              including network activity, stimulus values, and correctness.\n",
        "    \"\"\"\n",
        "    # Reset environment\n",
        "    environment = dataset_to_evaluate.env\n",
        "    environment.reset()\n",
        "\n",
        "    # Initialise variables for logging\n",
        "    # Stores correctness for calculating average performance\n",
        "    trial_correctness_records = {}\n",
        "    # Stores detailed information and network activity for each trial\n",
        "    trial_data_and_activity = {}\n",
        "\n",
        "    # Store the information of the trial environment\n",
        "    # For reporting or future devs with sequence isolation\n",
        "    # NOTE: for trial envs with varying task period timings this will need to be called IN THE LOOP AND STORED ALONGSIDE EACH TRIAL\n",
        "    # NOTE : Having trial envs with varying task period timings also cocks up the results data processing func so dont forget\n",
        "\n",
        "    environment_info = {\n",
        "            'dt' : environment.dt,\n",
        "            'trial_start_ind': environment.start_ind,\n",
        "            'trial_end_ind': environment.end_ind,\n",
        "            'timing': environment.timing,\n",
        "            'sigma': environment.sigma,\n",
        "            'choices': environment.choices,\n",
        "            'stim_values_array': environment.theta\n",
        "            }\n",
        "\n",
        "\n",
        "    for trial_index in range(num_trials):\n",
        "        # Initialise dictionary for the current trial's data\n",
        "        trial_data_and_activity[trial_index] = {}\n",
        "\n",
        "        # Sample a new trial\n",
        "        trial_information = environment.new_trial()\n",
        "\n",
        "        # Observation and groud-truth of this trial\n",
        "        observation, ground_truth = environment.ob, environment.gt\n",
        "\n",
        "        # Convert to numpy, add batch dimension to input (for consistency)\n",
        "        inputs_tensor = torch.from_numpy(observation[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "        # Run the network for one trial\n",
        "        # inputs_tensor (SeqLen, Batch, InputSize)\n",
        "        # predicted_actions (SeqLen, Batch, OutputSize) (output layer activity across all timesteps)\n",
        "        # hidden_activity (seq_len, batch, hidden layer size)\n",
        "        prediction_action, hidden_activity = network(inputs_tensor)\n",
        "\n",
        "        # Compute performance\n",
        "        # First convert back to numpy\n",
        "        prediction_action_np = prediction_action.detach().numpy()[:, 0, :]\n",
        "        # Read out final choice at last time step\n",
        "        network_choice = np.argmax(prediction_action_np[-1, :])\n",
        "        # Compare to ground truth\n",
        "        is_correct = network_choice == ground_truth[-1]\n",
        "\n",
        "        # Record activity, trial information, choice, correctness\n",
        "        hidden_activity_np = hidden_activity[:, 0, :].detach().numpy() # becomes (seq_len, hidden_size)\n",
        "\n",
        "        # Update all logging of trial information and network activity\n",
        "        trial_correctness_records[trial_index] = {}\n",
        "        trial_correctness_records[trial_index].update({'correct': is_correct})\n",
        "\n",
        "        trial_data_and_activity[trial_index]['network_activity'] = hidden_activity_np\n",
        "        trial_data_and_activity[trial_index]['sample_stim_value'] = trial_information['sample_theta']\n",
        "        trial_data_and_activity[trial_index]['test_stim_value'] = trial_information['test_theta']\n",
        "        trial_data_and_activity[trial_index]['test_equals_sample'] = True if int(trial_information['ground_truth']) == 1 else False\n",
        "        trial_data_and_activity[trial_index]['network_correct'] = is_correct\n",
        "\n",
        "    # Print Average trial performance during testing\n",
        "    average_trial_performance = np.mean([val['correct'] for val in trial_correctness_records.values()])\n",
        "    print('Average performance', average_trial_performance)\n",
        "\n",
        "    # PACKING THE DICTS\n",
        "    full_testing_data = {\n",
        "        'testing_env_info' : environment_info,\n",
        "        'testing_trial_and_activity': trial_data_and_activity,\n",
        "        'testing_trial_performance': average_trial_performance\n",
        "    }\n",
        "\n",
        "    return full_testing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36_3TSuYy2n-"
      },
      "outputs": [],
      "source": [
        "def bic_testing_w_state_tracking(network, dataset_to_evaluate, num_trials=200):\n",
        "    \"\"\"\n",
        "    Evaluates the given network on a NGym dataset and records trial data.\n",
        "    Needs to have .forward_for_fpf_ics(self, x) method implemented.\n",
        "\n",
        "    Args:\n",
        "        network: The network to evaluate.\n",
        "        dataset_to_evaluate: The NeuroGym dataset to use for evaluation.\n",
        "        num_trials: The number of trials to run for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing environmental information and detailed trial data\n",
        "              including network activity, stimulus values, and correctness.\n",
        "    \"\"\"\n",
        "    # Reset environment\n",
        "    environment = dataset_to_evaluate.env\n",
        "    environment.reset()\n",
        "\n",
        "    # Initialise variables for logging\n",
        "    # Stores correctness for calculating average performance\n",
        "    trial_correctness_records = {}\n",
        "    # Stores detailed information and network activity for each trial\n",
        "    trial_data_and_activity = {}\n",
        "\n",
        "    # Store the information of the trial environment\n",
        "    # For reporting or future devs with sequence isolation\n",
        "    # NOTE: for trial envs with varying task period timings this will need to be called IN THE LOOP AND STORED ALONGSIDE EACH TRIAL\n",
        "    # NOTE : Having trial envs with varying task period timings also cocks up the results data processing func so dont forget\n",
        "\n",
        "    environment_info = {\n",
        "            'dt' : environment.dt,\n",
        "            'trial_start_ind': environment.start_ind,\n",
        "            'trial_end_ind': environment.end_ind,\n",
        "            'timing': environment.timing,\n",
        "            'sigma': environment.sigma,\n",
        "            'choices': environment.choices,\n",
        "            'stim_values_array': environment.theta\n",
        "            }\n",
        "\n",
        "\n",
        "    for trial_index in range(num_trials):\n",
        "        # Initialise dictionary for the current trial's data\n",
        "        trial_data_and_activity[trial_index] = {}\n",
        "\n",
        "        # Sample a new trial\n",
        "        trial_information = environment.new_trial()\n",
        "\n",
        "        # Observation and groud-truth of this trial\n",
        "        observation, ground_truth = environment.ob, environment.gt\n",
        "\n",
        "        # Convert to numpy, add batch dimension to input (for consistency)\n",
        "        inputs_tensor = torch.from_numpy(observation[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "        # Run the network for one trial\n",
        "        # inputs_tensor (SeqLen, Batch, InputSize)\n",
        "        # predicted_actions (SeqLen, Batch, OutputSize) (output layer activity across all timesteps)\n",
        "        # hidden_activity (seq_len, batch, hidden layer size)\n",
        "        # prediction_action, hidden_activity = network(inputs_tensor)\n",
        "        prediction_action, hidden_activity, hidden_state_tensor = network.forward_for_fpf_ics(inputs_tensor)\n",
        "\n",
        "        # Compute performance\n",
        "        # First convert back to numpy\n",
        "        prediction_action_np = prediction_action.detach().numpy()[:, 0, :]\n",
        "        # Read out final choice at last time step\n",
        "        network_choice = np.argmax(prediction_action_np[-1, :])\n",
        "        # Compare to ground truth\n",
        "        is_correct = network_choice == ground_truth[-1]\n",
        "\n",
        "        # Record activity, trial information, choice, correctness\n",
        "        hidden_activity_np = hidden_activity[:, 0, :].detach().numpy() # becomes (seq_len, hidden_size)\n",
        "        hidden_state_np = hidden_state_tensor[:, 0, :].detach().numpy()\n",
        "        if hidden_activity_np.shape[0] != hidden_state_np.shape[0]:\n",
        "          print('gotcha')\n",
        "        # Update all logging of trial information and network activity\n",
        "        trial_correctness_records[trial_index] = {}\n",
        "        trial_correctness_records[trial_index].update({'correct': is_correct}) # Redundant but kept for original output structure\n",
        "\n",
        "        # trial_data_and_activity[trial_index]['network_activity'] = hidden_state_np ### NOTE THIS HAS BEEN CHANGED TO SEE HOW ANALYSIS CHANGES ### IF THESE ARE SWAPPED BACK (i.e. activity = output activity), the hidden_key input for bic fpf needs to be changed to = 'network_hidden_state'\n",
        "        # trial_data_and_activity[trial_index]['network_hidden_state'] = hidden_activity_np\n",
        "        trial_data_and_activity[trial_index]['network_activity'] = hidden_activity_np ### NOTE THIS HAS BEEN CHANGED TO SEE HOW ANALYSIS CHANGES ### IF THESE ARE SWAPPED BACK (i.e. activity = output activity), the hidden_key input for bic fpf needs to be changed to = 'network_hidden_state'\n",
        "        trial_data_and_activity[trial_index]['network_hidden_state'] = hidden_state_np\n",
        "        trial_data_and_activity[trial_index]['sample_stim_value'] = trial_information['sample_theta']\n",
        "        trial_data_and_activity[trial_index]['test_stim_value'] = trial_information['test_theta']\n",
        "        trial_data_and_activity[trial_index]['test_equals_sample'] = True if int(trial_information['ground_truth']) == 1 else False\n",
        "        trial_data_and_activity[trial_index]['network_correct'] = is_correct\n",
        "\n",
        "    # Print Average trial performance during testing\n",
        "    average_trial_performance = np.mean([val['correct'] for val in trial_correctness_records.values()])\n",
        "    print('Average performance', average_trial_performance)\n",
        "\n",
        "    # PACKING THE DICTS - cut down so now returning essentials\n",
        "    full_testing_data = {\n",
        "        'testing_env_info' : environment_info,\n",
        "        'testing_trial_and_activity': trial_data_and_activity,\n",
        "        'testing_trial_performance': average_trial_performance\n",
        "    }\n",
        "\n",
        "    return full_testing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----- ANALYSIS FUNCTIONS ------\n",
        "\n"
      ],
      "metadata": {
        "id": "cTpwWWrMp-pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VISUALISATION FUNCTIONS"
      ],
      "metadata": {
        "id": "yWHgCl0mqs4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Trial Unit Activty Plotting Function"
      ],
      "metadata": {
        "id": "kkV1iPjXix8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe this should take the whole trial dict, not just the activity? would be good for the title\n",
        "def plot_unit_activity_over_time(trial_activity, env_info, unit_indices_to_plot=None, legend = False, filename=None):\n",
        "    \"\"\"\n",
        "    plots the activty of all the units in a trial over time.\n",
        "    can also just plot a specefic subset of them if you want.\n",
        "    \"\"\"\n",
        "    seq_len, hidden_size = trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # make the time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    # get the fig and ax so we can save it later\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # figure out which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = unit_indices_to_plot\n",
        "        # just make sure the indicies are actually in the array\n",
        "        units_to_plot = [i for i in units_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "\n",
        "    for i in units_to_plot:\n",
        "        ax.plot(time_points, trial_activity[:, i], label=f'Unit {i+1}')\n",
        "\n",
        "    # draw the lines for the different task bits\n",
        "    current_time = 0\n",
        "    # bit fiddly, just makes sure we dont get duplicate labels in the legend\n",
        "    existing_legend_labels = [l.get_text() for l in ax.get_legend().get_texts()] if legend and ax.get_legend() else []\n",
        "\n",
        "    for phase, duration in timing.items():\n",
        "        # only works for fixed timings for now\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            # don't draw a line if it's off the edge of the plot\n",
        "            if current_time < time_points[-1]:\n",
        "                # add the line, but only give it a label if we want a legend\n",
        "                # and if that label isn't already there\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', label=phase if legend and phase not in existing_legend_labels else \"\")\n",
        "\n",
        "\n",
        "    ax.set_title('Network Unit Activity Over Time')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Activity')\n",
        "    if legend:\n",
        "      # put a legend on if we asked for one. can get a bit crowded\n",
        "      ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # save the plot if we got a filename, otherwise just show it\n",
        "    if filename:\n",
        "        try:\n",
        "            # make sure the directory exists\n",
        "            if os.path.dirname(filename):\n",
        "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            # save it out\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            # close the plot so it doesn't just pop up anyway / saves colab ram\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            # if saving went wrong for some reason, just show the plot instead\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "uc9XEhCYgvuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average Unit Activity Function"
      ],
      "metadata": {
        "id": "PMq5wtfLiugg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_average_unit_activity_over_time(trial_data_dict, env_info, unit_indices_to_plot=None, legend=False, filename=None):\n",
        "    \"\"\"\n",
        "    Averages the unit activty across a number of trials and then plots it.\n",
        "    You can also provide a list of speific units to plot.\n",
        "    \"\"\"\n",
        "    if not trial_data_dict:\n",
        "        print(\"No trial data provided for plotting.\")\n",
        "        return\n",
        "\n",
        "    # First, get the shape info from one of the trials\n",
        "    first_trial_key = list(trial_data_dict.keys())[0]\n",
        "    first_trial_activity = trial_data_dict[first_trial_key]['network_activity']\n",
        "    seq_len, hidden_size = first_trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Go through all the trials and stack their activities together\n",
        "    all_activities = []\n",
        "    for trial_data in trial_data_dict.values():\n",
        "        # just a check to make sure the shapes match up\n",
        "        if trial_data['network_activity'].shape == (seq_len, hidden_size):\n",
        "            all_activities.append(trial_data['network_activity'])\n",
        "        else:\n",
        "            # never happens but just incase\n",
        "            print(f\"Warning: Skipping trial with inconsistent shape: {trial_data['network_activity'].shape}\")\n",
        "\n",
        "    if not all_activities:\n",
        "        print(\"No valid trial data found for averaging.\")\n",
        "        return\n",
        "\n",
        "    all_activities_stacked = np.stack(all_activities, axis=0)\n",
        "\n",
        "    # Now we can average across all the trials\n",
        "    average_activity = np.mean(all_activities_stacked, axis=0)\n",
        "\n",
        "    # create the time axis for the plot\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    # get the fig and ax so we can save the plot\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "\n",
        "    # Decide which units we're actually plotting\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = unit_indices_to_plot\n",
        "        # Make sure the requested indicies are valid\n",
        "        units_to_plot = [i for i in units_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "\n",
        "    for i in units_to_plot:\n",
        "        ax.plot(time_points, average_activity[:, i], label=f'Avg Unit {i+1}')\n",
        "\n",
        "    # Add the vertical lines for task phases\n",
        "    current_time = 0\n",
        "    # a check to prevent duplicate labels appearing in the legend\n",
        "    existing_legend_labels = [l.get_text() for l in ax.get_legend().get_texts()] if legend and ax.get_legend() else []\n",
        "\n",
        "    for phase, duration in timing.items():\n",
        "        # This only works for the fixed timings\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            # don't draw lines that would be off the chart\n",
        "            if current_time < time_points[-1]:\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', label=phase if legend and phase not in existing_legend_labels else \"\")\n",
        "        else:\n",
        "            # For handling variable timings in future if needed\n",
        "            print(f\"Skipping phase '{phase}' with variable timing for plotting vertical lines.\")\n",
        "\n",
        "\n",
        "    ax.set_title('Average Network Unit Activity Over Time Across Trials')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Average Activity')\n",
        "    # The legend is optional as it can sometimes mess up the plot\n",
        "    if legend:\n",
        "      ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Save the figure or show it\n",
        "    if filename:\n",
        "        try:\n",
        "            # make sure the directory exists first\n",
        "            if os.path.dirname(filename):\n",
        "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            # close the plot so it doesn't show up after saving\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            # if saving fails, show the plot instead\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "sphc54ZBhWp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heat Map for Network Structure - BIC Change"
      ],
      "metadata": {
        "id": "oiQQWkED75Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_recurrent_weights_heatmap_BIC(net, filename = None, mask=None, weights_passed=False):\n",
        "    \"\"\"\n",
        "    Makes a heatmap of the recurrent weights from the RNN's h2h layer.\n",
        "    It expects the network to have a net.rnn.h2h.weight structure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if mask is not None:\n",
        "            effective_weights = net.rnn.h2h.weight * mask\n",
        "            weights = effective_weights.detach().cpu().numpy()\n",
        "        elif weights_passed:\n",
        "            weights = net\n",
        "        else:\n",
        "            # get the recurrent weights from the linear layer\n",
        "            weights = net.rnn.h2h.weight.detach().cpu().numpy()\n",
        "    except AttributeError:\n",
        "        print(\"Error: Could not find 'net.rnn.h2h.weight'.\")\n",
        "        return\n",
        "\n",
        "    num_units = weights.shape[0]\n",
        "\n",
        "    # set up a symmetric colour range for the plot\n",
        "    max_abs_val = np.max(np.abs(weights))\n",
        "    norm = mcolors.Normalize(vmin=-max_abs_val, vmax=max_abs_val)\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "    # use imshow to create the heatmap itself\n",
        "    im = ax.imshow(weights, cmap='bwr_r', norm=norm, interpolation='none')\n",
        "\n",
        "    # configure the colour bar\n",
        "    cbar = fig.colorbar(im, ax=ax, shrink=0.8)\n",
        "    cbar.set_label('Connection Weight', rotation=270, labelpad=20, fontsize=12)\n",
        "\n",
        "    # configure the axes and labels\n",
        "    ax.set_title('Recurrent Connection Weights Heatmap', fontsize=16, pad=20)\n",
        "    ax.set_ylabel('To Unit Index', fontsize=12)\n",
        "    ax.set_xlabel('From Unit Index', fontsize=12)\n",
        "\n",
        "    # configure the main ticks to be centered and rotated\n",
        "    tick_labels = np.arange(num_units)\n",
        "    ax.set_xticks(tick_labels)\n",
        "    ax.set_yticks(tick_labels)\n",
        "    ax.tick_params(axis='x', labelsize=10)\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "    plt.setp(\n",
        "        ax.get_xticklabels(),\n",
        "        rotation=90,\n",
        "        ha=\"center\",\n",
        "        rotation_mode=\"default\"\n",
        "    )\n",
        "\n",
        "    # add grid lines and borders inside the heatmap\n",
        "    # set minor ticks to sit between the major ones, which is where the grid lines go\n",
        "    ax.set_xticks(np.arange(-.5, num_units, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, num_units, 1), minor=True)\n",
        "\n",
        "    # add some faint gridlines to all the cells\n",
        "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.25, alpha=0.5)\n",
        "\n",
        "    # this is important - hide the minor tick marks on the axes themselves\n",
        "    ax.tick_params(which='minor', bottom=False, left=False)\n",
        "\n",
        "    # add a slightly more prominent border for the diagonal cells\n",
        "    for i in range(num_units):\n",
        "        rect = patches.Rectangle(\n",
        "            (i - 0.5, i - 0.5), 1, 1,\n",
        "            linewidth=0.75, edgecolor='black', facecolor='none', alpha=0.7\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    fig.tight_layout(pad=1.5)\n",
        "\n",
        "    # save or display the figure\n",
        "    if filename:\n",
        "      plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "      print(f\"Figure saved to {filename}\")\n",
        "      plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "5zhvZV7Rhk9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmap for Trial Phase Period Selectivity (TBD)"
      ],
      "metadata": {
        "id": "1ol1Aouwrrjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIMENSIONALITY REDUCTION"
      ],
      "metadata": {
        "id": "DTkePl_CscHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dPCA (I/O)"
      ],
      "metadata": {
        "id": "ieVSoT-0TvDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (O)"
      ],
      "metadata": {
        "id": "Af3fBq_dsjSr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2VRCeIAh0B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "export_nested_dict_to_json"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def export_nested_dict_to_json(data, filename):\n",
        "    \"\"\"\n",
        "    Exports a nested dictionary containing NumPy arrays to a JSON file.\n",
        "\n",
        "    Recursively converts NumPy arrays to lists before exporting and adds an\n",
        "    indicator to mark lists that were originally NumPy arrays.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The nested dictionary to export.\n",
        "        filename (str): The name of the JSON file to create.\n",
        "    \"\"\"\n",
        "    def convert_numpy_to_list(obj):\n",
        "        \"\"\"\n",
        "        Recursively converts NumPy arrays within an object to lists and adds a marker.\n",
        "        \"\"\"\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            # Convert to list and add a marker at the beginning\n",
        "            return ['NUMPY'] + obj.tolist()\n",
        "        elif isinstance(obj, dict):\n",
        "            return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [convert_numpy_to_list(item) for item in obj]\n",
        "        elif isinstance(obj, (np.float64, np.bool_, np.int64, np.int32)): # Added more scalar types\n",
        "             return obj.item() # Convert NumPy scalar types to Python native types\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    export_ready_data = convert_numpy_to_list(data)\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(export_ready_data, f, indent=4)\n",
        "        print(f\"Data successfully exported to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting data to {filename}: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (I)"
      ],
      "metadata": {
        "id": "TPPM61ACUCdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def import_nested_dict_from_json(filename):\n",
        "    \"\"\"\n",
        "    Loads data from a JSON file that was saved with the other function.\n",
        "    It finds any lists marked as 'NUMPY' and turns them back into numpy arrays.\n",
        "    \"\"\"\n",
        "    def convert_list_to_numpy_array(obj):\n",
        "        \"\"\"The helper that does the actual work of finding and converting the lists.\"\"\"\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: convert_list_to_numpy_array(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            # look for our 'NUMPY' marker at the start of a list\n",
        "            if obj and isinstance(obj[0], str) and obj[0] == 'NUMPY':\n",
        "                # if we find it, chop the marker off and convert the rest to an array\n",
        "                try:\n",
        "                    # process inner elements first, in case of nested arrays\n",
        "                    list_without_marker = [convert_list_to_numpy_array(item) for item in obj[1:]]\n",
        "                    return np.array(list_without_marker)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not convert list marked as 'NUMPY' to array. Returning list. Error: {e}\")\n",
        "                    # if something goes wrong, just give back the list as it was\n",
        "                    return obj\n",
        "            else:\n",
        "                # if there's no marker, just keep digging through the list\n",
        "                return [convert_list_to_numpy_array(item) for item in obj]\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            imported_data = json.load(f)\n",
        "\n",
        "        reconstructed_data = convert_list_to_numpy_array(imported_data)\n",
        "        print(f\"Data successfully imported from {filename}\")\n",
        "        return reconstructed_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filename}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from {filename}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error importing data from {filename}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Lvco-1z9h77_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accompanying Import Function (also located in dPCA notebook)"
      ],
      "metadata": {
        "id": "uRuYdxF-somd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check I/O"
      ],
      "metadata": {
        "id": "-CwvtZqNUQ4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Check if the dict you are exporting will be imported as an exact match in the dPCA notebook"
      ],
      "metadata": {
        "id": "k5pJyi8Osu-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deepdiff\n",
        "\n",
        "def compare_dicts(dict1, dict2):\n",
        "    \"\"\"\n",
        "    Compares two dictionaries and reports the differences.\n",
        "    Handles NumPy arrays by comparing their content.\n",
        "\n",
        "    Args:\n",
        "        dict1 (dict): The first dictionary.\n",
        "        dict2 (dict): The second dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the differences.\n",
        "    \"\"\"\n",
        "\n",
        "    diff = deepdiff.DeepDiff(dict1, dict2, ignore_order=False, verbose_level=0)\n",
        "\n",
        "    if not diff:\n",
        "        print(\"Dictionaries are identical.\")\n",
        "    else:\n",
        "        print(\"Differences found:\")\n",
        "        print(diff)\n",
        "\n",
        "    return diff\n"
      ],
      "metadata": {
        "id": "muWNZCH1UYlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "CVkk3zgVs8r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit PCA"
      ],
      "metadata": {
        "id": "zL0BDeMSfwS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_pca_on_selected_data(dict_of_trial_dicts, pca_components=2, report_var_expls = False):\n",
        "    '''\n",
        "    Fits a PCA model on the network activity from a dictionary of trials.\n",
        "\n",
        "    This function can be used in two ways:\n",
        "    1. To explore the data: set pca_components to None and report_var_expls to True.\n",
        "       This will print out variance info and show scree plots to help you\n",
        "       decide how many componants to use.\n",
        "\n",
        "    2. To get a model: set pca_components to a number (e.g. 2).\n",
        "       This will return the actual fitted PCA object.\n",
        "    '''\n",
        "    list_of_activity_arrays = []\n",
        "    for trial_num, trial_dict in dict_of_trial_dicts.items():\n",
        "        list_of_activity_arrays.append(trial_dict['network_activity'])\n",
        "\n",
        "    # combine all the trial activities into one big array for the PCA\n",
        "    activity_for_fit = np.concatenate(list_of_activity_arrays, axis=0)\n",
        "    # just a quick check on the shape to make sure it's right\n",
        "    # print(f'Checking Dimensionality should be (<seqlen*n_trials>, hidden size)')\n",
        "    # print(f'{activity_for_fit.shape}')\n",
        "    pca = PCA(n_components=pca_components)\n",
        "    pca.fit(activity_for_fit)\n",
        "\n",
        "    if report_var_expls:\n",
        "\n",
        "        print(\"--- Detailed PCA Variance Explanation ---\")\n",
        "\n",
        "        # print the variance explained by each component as a percentage\n",
        "        for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
        "            print(f\"Principal Component {i+1}: {ratio*100:.2f}% of total variance explained\")\n",
        "\n",
        "        # and the cumulative variance\n",
        "        cumulative_variance_percent = np.cumsum(pca.explained_variance_ratio_) * 100\n",
        "        for i, cum_percent in enumerate(cumulative_variance_percent):\n",
        "            print(f\"Cumulative Variance Explained by first {i+1} components: {cum_percent:.2f}%\")\n",
        "\n",
        "        print(f\"Total variance explained by all {pca.n_components_} selected components: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
        "\n",
        "        # make a scree plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
        "        plt.xlabel('Principal Component Number')\n",
        "        plt.ylabel('Proportion of Variance Explained')\n",
        "        plt.title('Scree Plot: Explained Variance Ratio per Component')\n",
        "        plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        # and another plot for the cumulative variance\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(1, len(cumulative_variance_percent) + 1), cumulative_variance_percent, marker='o', linestyle='-')\n",
        "        plt.xlabel('Number of Principal Components')\n",
        "        plt.ylabel('Cumulative Explained Variance (%)')\n",
        "        plt.title('Cumulative Explained Variance vs. Number of Components')\n",
        "        plt.xticks(range(1, len(cumulative_variance_percent) + 1))\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        # an example threshold line\n",
        "        plt.axhline(y=90, color='r', linestyle='--', label='90% Threshold')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    else:\n",
        "        return pca"
      ],
      "metadata": {
        "id": "1mQVHrZHiNIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot PC1 against time Function"
      ],
      "metadata": {
        "id": "8_hsHMkNvlEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------WONT WORK FOR DIFF TASK------"
      ],
      "metadata": {
        "id": "YpXYjEkoy2rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories(pca_object, data_to_transform_dict, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None):\n",
        "    \"\"\"\n",
        "    Takes a fitted PCA object and some data and plots the average PC1 trajectries\n",
        "    over time. It colours the lines based on the sample and test stimulus values,\n",
        "    using the project's style guide.\n",
        "\n",
        "    The plot_title argument is ignored to make sure the plots all look the same.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict:\n",
        "        print(\"No trial data provided for plotting PCA trajectories.\")\n",
        "        return\n",
        "\n",
        "    # ---- Style guide definitions ----\n",
        "    # these are the specific colours for the different trial conditions\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    # we only need one linestyle for this plot\n",
        "    LINESTYLE = '-'\n",
        "\n",
        "    # ---- Preparing the data ----\n",
        "    # first, group the trials by their stimulus condition\n",
        "    grouped_trajectories = defaultdict(list)\n",
        "    limited_trials = dict(list(data_to_transform_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "    for trial_dict in limited_trials.values():\n",
        "        stim_condition = (\n",
        "            round(trial_dict['sample_stim_value'], 2),\n",
        "            round(trial_dict['test_stim_value'], 2)\n",
        "        )\n",
        "        if stim_condition in STYLE_GUIDE_COLORS:\n",
        "            activity = np.array(trial_dict['network_activity'])\n",
        "            # just the first principal component\n",
        "            pc1_trajectory = pca_object.transform(activity)[:, 0]\n",
        "            grouped_trajectories[stim_condition].append(pc1_trajectory)\n",
        "\n",
        "    # ---- Setting up the plot ----\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    max_plotted_time = 0\n",
        "\n",
        "    # ---- Plot the mean trajectories ----\n",
        "    for condition, trajectories in grouped_trajectories.items():\n",
        "        if trajectories:\n",
        "            # average the trajectories for this condition\n",
        "            mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "\n",
        "            # get the right colour and label\n",
        "            colour = STYLE_GUIDE_COLORS[condition]['color']\n",
        "            label = STYLE_GUIDE_COLORS[condition]['label']\n",
        "\n",
        "            # make the time axis\n",
        "            time_points = np.arange(len(mean_trajectory)) * testing_env_info['dt']\n",
        "            max_plotted_time = max(max_plotted_time, time_points[-1])\n",
        "\n",
        "            ax.plot(time_points, mean_trajectory, color=colour, linestyle=LINESTYLE, label=label, linewidth=2.5)\n",
        "\n",
        "    # ---- Add lines and labels for task phases ----\n",
        "    task_env_dt = testing_env_info['dt']\n",
        "    ax.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "        end_time_ms = (end_index-1) * task_env_dt\n",
        "        if end_time_ms <= max_plotted_time + task_env_dt:\n",
        "            ax.axvline(x=end_time_ms, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    # put the phase labels near the top of the plot\n",
        "    annotation_y_pos = y_max - (y_max - y_min) * 0.05\n",
        "\n",
        "    for phase, start_index in testing_env_info['trial_start_ind'].items():\n",
        "        start_time_ms = start_index * task_env_dt\n",
        "        end_time_ms = (testing_env_info['trial_end_ind'][phase] - 1) * task_env_dt\n",
        "        center_time_ms = (start_time_ms + end_time_ms) / 2\n",
        "        if center_time_ms <= max_plotted_time:\n",
        "            ax.text(center_time_ms, annotation_y_pos, phase.capitalize(),\n",
        "                    ha='center', va='top', fontsize=12, color='black')\n",
        "\n",
        "    # ---- Final tweaks to the plot ----\n",
        "    ax.set_xlabel('Time (ms)', fontsize=14)\n",
        "    ax.set_ylabel('PC1 (from PCA fit)', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "    # add a bit of padding to the y-axis so the lines don't hit the top/bottom\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    y_range = y_max - y_min\n",
        "    ax.set_ylim(y_min - y_range * 0.1, y_max + y_range * 0.1)\n",
        "\n",
        "    ax.legend(title=\"Trial Conditions\", loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=10)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1]) # make space for the legend outside\n",
        "\n",
        "    # ---- Save or show the plot ----\n",
        "    if save_filename:\n",
        "        try:\n",
        "            # make sure the directory exists\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "8TBbfX8xiVHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2 Datasets 1 PCA Plotting 1D (For Leisoning)"
      ],
      "metadata": {
        "id": "_QlfAF6-3VCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------WONT WORK FOR DIFF TASK------"
      ],
      "metadata": {
        "id": "_UAH0RwUzEMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_two_datasets(pca_object, data_to_transform_dict1, data_to_transform_dict2, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None, label1=\"Unlesioned\", label2=\"Lesioned\"):\n",
        "    \"\"\"\n",
        "    Plots and compares the mean PC1 trajectories from two different datasets,\n",
        "    for example an 'Unlesioned' vs 'Lesioned' network.\n",
        "\n",
        "    The line colour shows the task condition, while the line style (solid/dashed)\n",
        "    shows which dataset it came from. The plot title is ignored for consistancy.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict1 and not data_to_transform_dict2:\n",
        "        print(\"No trial data provided from either dataset for plotting.\")\n",
        "        return\n",
        "\n",
        "    # ---- Style guide definitions ----\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    # solid for dataset 1, dashed for dataset 2\n",
        "    DATASET_STYLES = [\n",
        "        {'linestyle': '-', 'label': label1},\n",
        "        {'linestyle': '--', 'label': label2}\n",
        "    ]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    max_plotted_time = 0\n",
        "    all_plotted_conditions = set()\n",
        "\n",
        "    datasets = [(data_to_transform_dict1, DATASET_STYLES[0]), (data_to_transform_dict2, DATASET_STYLES[1])]\n",
        "\n",
        "    # loop through both datasets and plot their trajectories\n",
        "    for data_dict, style in datasets:\n",
        "        if not data_dict:\n",
        "            continue\n",
        "\n",
        "        # group the trials by their stimulus condition\n",
        "        grouped_trajectories = defaultdict(list)\n",
        "        limited_trials = dict(list(data_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "        for trial_dict in limited_trials.values():\n",
        "            stim_condition = (round(trial_dict['sample_stim_value'], 2), round(trial_dict['test_stim_value'], 2))\n",
        "            if stim_condition in STYLE_GUIDE_COLORS:\n",
        "                activity = np.array(trial_dict['network_activity'])\n",
        "                pc1_trajectory = pca_object.transform(activity)[:, 0]\n",
        "                grouped_trajectories[stim_condition].append(pc1_trajectory)\n",
        "                all_plotted_conditions.add(stim_condition)\n",
        "\n",
        "        # now plot the mean trajectory for each condition in this dataset\n",
        "        for condition, trajectories in grouped_trajectories.items():\n",
        "            if trajectories:\n",
        "                mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "                colour = STYLE_GUIDE_COLORS[condition]['color']\n",
        "                time_points = np.arange(len(mean_trajectory)) * testing_env_info['dt']\n",
        "                max_plotted_time = max(max_plotted_time, time_points[-1])\n",
        "\n",
        "                ax.plot(time_points, mean_trajectory, color=colour, linestyle=style['linestyle'], linewidth=2.5)\n",
        "\n",
        "    # ---- Add lines and labels for task phases ----\n",
        "    task_env_dt = testing_env_info['dt']\n",
        "    ax.axvline(x=0, color='k', linestyle='--', linewidth=1)\n",
        "    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "        end_time_ms = (end_index-1) * task_env_dt\n",
        "        if end_time_ms <= max_plotted_time + task_env_dt:\n",
        "            ax.axvline(x=end_time_ms, color='k', linestyle='--', linewidth=1)\n",
        "\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    annotation_y_pos = y_max - (y_max - y_min) * 0.05\n",
        "    for phase, start_index in testing_env_info['trial_start_ind'].items():\n",
        "        start_time_ms = start_index * task_env_dt\n",
        "        end_time_ms = (testing_env_info['trial_end_ind'][phase]-1) * task_env_dt\n",
        "        center_time_ms = (start_time_ms + end_time_ms) / 2\n",
        "        if center_time_ms <= max_plotted_time:\n",
        "            ax.text(center_time_ms, annotation_y_pos, phase.capitalize(), ha='center', va='top', fontsize=12)\n",
        "\n",
        "    # ---- Final plot tweaks ----\n",
        "    ax.set_xlabel('Time (ms)', fontsize=14)\n",
        "    ax.set_ylabel('PC1 (from PCA fit)', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    y_min, y_max = ax.get_ylim()\n",
        "    y_range = y_max - y_min\n",
        "    ax.set_ylim(y_min - y_range * 0.1, y_max + y_range * 0.1)\n",
        "\n",
        "    # ---- Build the legend manually ----\n",
        "    legend_handles = []\n",
        "    # First, the legend entries for the line styles (the two datasets)\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[0]['linestyle'], label=DATASET_STYLES[0]['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[1]['linestyle'], label=DATASET_STYLES[1]['label']))\n",
        "\n",
        "    # add an invisible spacer to seperate the two parts of the legend\n",
        "    legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # Second, the legend entries for the colours (the trial conditions)\n",
        "    sorted_conditions = sorted(list(all_plotted_conditions))\n",
        "    for condition in sorted_conditions:\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1]) # make space for the legend\n",
        "\n",
        "    # ---- Save or show the plot ----\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "TJUrR9BCiV7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot PC1(hla) vs PC2(hla)  "
      ],
      "metadata": {
        "id": "tQqMSmwpyMRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_2d(pca_object, data_to_transform_dict, testing_env_info,\n",
        "                             num_trials_to_plot=100, plot_title=None, save_filename=None,\n",
        "                             add_phase_markers=True):\n",
        "    \"\"\"\n",
        "    Plots the average PC1 vs PC2 trajectories from network activity.\n",
        "    The lines are coloured based on the trial condition, and it adds markers\n",
        "    for the start, end, and phase transitions of each trajectory.\n",
        "\n",
        "    The plot title is ignored for consistancy.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict:\n",
        "        print(\"No trial data provided for plotting PCA trajectories.\")\n",
        "        return\n",
        "\n",
        "    if pca_object.n_components < 2:\n",
        "        print(f\"Error: PCA object must be fit with n_components>=2, but has {pca_object.n_components}\")\n",
        "        return\n",
        "\n",
        "    # ---- Style guide definitions ----\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    # single dataset so all lines are solid\n",
        "    LINESTYLE = '-'\n",
        "\n",
        "    # ---- Preparing the data ----\n",
        "    grouped_trajectories = defaultdict(list)\n",
        "    limited_trials = dict(list(data_to_transform_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "    for trial_dict in limited_trials.values():\n",
        "        stim_condition = (\n",
        "            round(trial_dict['sample_stim_value'], 2),\n",
        "            round(trial_dict['test_stim_value'], 2)\n",
        "        )\n",
        "        if stim_condition in STYLE_GUIDE_COLORS:\n",
        "            activity = np.array(trial_dict['network_activity'])\n",
        "            # grab the first two principal components (PC1 and PC2)\n",
        "            pc_trajectory = pca_object.transform(activity)[:, :2]\n",
        "            grouped_trajectories[stim_condition].append(pc_trajectory)\n",
        "\n",
        "    # ---- Setting up the plot ----\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    # add a faint grid and centre lines\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    # make sure the plot is square\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    # ---- Plot the mean trajectories and markers ----\n",
        "    plotted_conditions = []\n",
        "    for condition, trajectories in grouped_trajectories.items():\n",
        "        if trajectories:\n",
        "            plotted_conditions.append(condition)\n",
        "            mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "            colour = STYLE_GUIDE_COLORS[condition]['color']\n",
        "\n",
        "            # plot the main trajectory line\n",
        "            ax.plot(mean_trajectory[:, 0], mean_trajectory[:, 1], color=colour, linestyle=LINESTYLE, linewidth=2.5)\n",
        "\n",
        "            # add a black square for the start point\n",
        "            ax.plot(mean_trajectory[0, 0], mean_trajectory[0, 1], marker='s', color='k', markersize=8, linestyle='None')\n",
        "\n",
        "            # add a black cross for the end point\n",
        "            ax.plot(mean_trajectory[-1, 0], mean_trajectory[-1, 1], marker='X', color='k', markersize=10, mew=2, linestyle='None')\n",
        "\n",
        "            # optionally add gold stars for phase transitions\n",
        "            if add_phase_markers:\n",
        "                for end_index in testing_env_info['trial_end_ind'].values():\n",
        "                    marker_idx = end_index - 1\n",
        "                    if marker_idx < len(mean_trajectory):\n",
        "                        ax.plot(mean_trajectory[marker_idx, 0], mean_trajectory[marker_idx, 1],\n",
        "                                marker='*', color='gold', markersize=12, linestyle='None')\n",
        "\n",
        "    # ---- Build the legend manually ----\n",
        "    legend_handles = []\n",
        "    # first, the handles for the different coloured lines\n",
        "    for condition in sorted(plotted_conditions):\n",
        "          style = STYLE_GUIDE_COLORS[condition]\n",
        "          legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "\n",
        "    # next, the handles for the different marker types\n",
        "    legend_handles.append(Line2D([0], [0], marker='s', color='k', label='Start', linestyle='None', markersize=8))\n",
        "    legend_handles.append(Line2D([0], [0], marker='X', color='k', label='End', linestyle='None', markersize=10, mew=2))\n",
        "    if add_phase_markers and plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], marker='*', color='gold', label='Phase Transition', linestyle='None', markersize=12))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # ---- Final plot tweaks ----\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # ---- Save or show the plot ----\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename):\n",
        "                os.makedirs(os.path.dirname(save_filename), exist_ok=True)\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "s6FVhKDai-om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot 2 Datasets 1 PCA(2D)"
      ],
      "metadata": {
        "id": "aaxk0FML3Mjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_two_datasets_2d(pca_object, data_to_transform_dict1, data_to_transform_dict2, testing_env_info, num_trials_to_plot=100, plot_title=None, save_filename=None, add_phase_markers=True, label1=\"Unlesioned\", label2=\"Lesioned\"):\n",
        "    \"\"\"\n",
        "    Plots and compares the mean PC1 vs PC2 trajectories from two datasets.\n",
        "\n",
        "    Line colour indicates the task condition, line style (solid/dashed) shows\n",
        "    the dataset, and markers show key events like start, end, and phase\n",
        "    transitions. The plot title is ignored for consistancy.\n",
        "    \"\"\"\n",
        "    if not data_to_transform_dict1 and not data_to_transform_dict2:\n",
        "        print(\"No trial data provided from either dataset for plotting.\")\n",
        "        return\n",
        "\n",
        "    if pca_object.n_components < 2:\n",
        "        print(f\"Error: PCA object must be fit with n_components>=2, but has {pca_object.n_components}\")\n",
        "        return\n",
        "\n",
        "    # ---- Style guide definitions ----\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    # solid for dataset 1, dashed for dataset 2\n",
        "    DATASET_STYLES = [\n",
        "        {'linestyle': '-', 'label': label1},\n",
        "        {'linestyle': '--', 'label': label2}\n",
        "    ]\n",
        "\n",
        "    # ---- Setting up the plot ----\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    # add a faint grid and centre lines\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    # make sure the plot is square\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    datasets = [(data_to_transform_dict1, DATASET_STYLES[0]), (data_to_transform_dict2, DATASET_STYLES[1])]\n",
        "    all_plotted_conditions = set()\n",
        "\n",
        "    # ---- Plot the trajectories and markers ----\n",
        "    for data_dict, style in datasets:\n",
        "        if not data_dict:\n",
        "            continue\n",
        "\n",
        "        grouped_trajectories = defaultdict(list)\n",
        "        limited_trials = dict(list(data_dict.items())[:num_trials_to_plot])\n",
        "\n",
        "        for trial_dict in limited_trials.values():\n",
        "            stim_condition = (round(trial_dict['sample_stim_value'], 2), round(trial_dict['test_stim_value'], 2))\n",
        "            if stim_condition in STYLE_GUIDE_COLORS:\n",
        "                activity = np.array(trial_dict['network_activity'])\n",
        "                pc_trajectory = pca_object.transform(activity)[:, :2]\n",
        "                grouped_trajectories[stim_condition].append(pc_trajectory)\n",
        "                all_plotted_conditions.add(stim_condition)\n",
        "\n",
        "        for condition, trajectories in grouped_trajectories.items():\n",
        "            if trajectories:\n",
        "                mean_trajectory = np.mean(np.array(trajectories), axis=0)\n",
        "                colour = STYLE_GUIDE_COLORS[condition]['color']\n",
        "\n",
        "                # plot the main trajectory\n",
        "                ax.plot(mean_trajectory[:, 0], mean_trajectory[:, 1], color=colour, linestyle=style['linestyle'], linewidth=2.5)\n",
        "                # add the start and end markers\n",
        "                ax.plot(mean_trajectory[0, 0], mean_trajectory[0, 1], marker='s', color='k', markersize=8, linestyle='None')\n",
        "                ax.plot(mean_trajectory[-1, 0], mean_trajectory[-1, 1], marker='X', color='k', markersize=10, mew=2, linestyle='None')\n",
        "\n",
        "                # and the phase transition markers if requested\n",
        "                if add_phase_markers:\n",
        "                    for end_index in testing_env_info['trial_end_ind'].values():\n",
        "                        marker_idx = end_index - 1\n",
        "                        if marker_idx < len(mean_trajectory):\n",
        "                            ax.plot(mean_trajectory[marker_idx, 0], mean_trajectory[marker_idx, 1], marker='*', color='gold', markersize=12, linestyle='None')\n",
        "\n",
        "    # ---- Build the legend manually in three parts ----\n",
        "    legend_handles = []\n",
        "    # Part 1: handles for the line styles (datasets)\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[0]['linestyle'], label=DATASET_STYLES[0]['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='k', lw=2, linestyle=DATASET_STYLES[1]['linestyle'], label=DATASET_STYLES[1]['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='w', label='')) # a spacer\n",
        "\n",
        "    # Part 2: handles for the line colours (conditions)\n",
        "    sorted_conditions = sorted(list(all_plotted_conditions))\n",
        "    for condition in sorted_conditions:\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "    legend_handles.append(Line2D([0], [0], color='w', label='')) # another spacer\n",
        "\n",
        "    # Part 3: handles for the different markers (start, end, etc.)\n",
        "    legend_handles.append(Line2D([0], [0], marker='s', color='k', label='Start', linestyle='None', markersize=8))\n",
        "    legend_handles.append(Line2D([0], [0], marker='X', color='k', label='End', linestyle='None', markersize=10, mew=2))\n",
        "    if add_phase_markers and all_plotted_conditions:\n",
        "        legend_handles.append(Line2D([0], [0], marker='*', color='gold', label='Phase Transition', linestyle='None', markersize=12))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # ---- Final plot tweaks ----\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # ---- Save or show the plot ----\n",
        "    if save_filename:\n",
        "        try:\n",
        "            if os.path.dirname(save_filename) and not os.path.exists(os.path.dirname(save_filename)):\n",
        "                os.makedirs(os.path.dirname(save_filename))\n",
        "            plt.savefig(save_filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {save_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {save_filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "RLHvV0OXjQzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNIT SELECTIVITY"
      ],
      "metadata": {
        "id": "FyA6-ZSWykrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calc Selectivity (and Inds)"
      ],
      "metadata": {
        "id": "VwbYY9HSzv_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_selectivity_indexes(task_condition_1_data_dict, task_condition_2_data_dict):\n",
        "  \"\"\"\n",
        "  Calculates a selectivity index for each hidden unit between two task conditions.\n",
        "  The selectivity index is based on the absolute difference in mean activity\n",
        "  between the two conditions, normalised by the pooled standard deviation.\n",
        "  This provides a measure of how strongly a unit's activity differentiates\n",
        "  between the two conditions.\n",
        "\n",
        "  Args:\n",
        "      task_condition_1_data_dict :  keys are trial numbers, values are dicts containing 'network_activity' for condition 1.\n",
        "      task_condition_2_data_dict : A dictionary with the same structure as task_condition_1_data_dict, for condition 2.\n",
        "\n",
        "  Returns:\n",
        "      A tuple containing:\n",
        "          - abs_selectivity_for_cond1xcond2 : Absolute selectivity index for each unit, in the order of hidden units.\n",
        "          - sorted_indexes : Indices of the hidden units sorted by their selectivity index in ascending order.\n",
        "  \"\"\"\n",
        "  # Uses absolute selectivity\n",
        "  mean_activity = []\n",
        "  std_activity = []\n",
        "\n",
        "  # Iterate through the two task condition data dictionaries\n",
        "  for task_condition in [task_condition_1_data_dict, task_condition_2_data_dict]:\n",
        "    # Concatenate network activity across all trials for the current condition\n",
        "    task_condition_activity = np.concatenate([value['network_activity'] for value in task_condition.values()], axis=0)\n",
        "\n",
        "    # Calculate the mean activity for each unit across all time steps and trials\n",
        "    mean_activity.append(np.mean(task_condition_activity, axis=0))\n",
        "\n",
        "    # Calculate the standard deviation of activity for each unit\n",
        "    std_activity.append(np.std(task_condition_activity, axis=0))\n",
        "\n",
        "  # Calculate the absolute difference between the mean activities of the two conditions\n",
        "  abs_selectivity_for_cond1xcond2 = abs((mean_activity[0] - mean_activity[1]))\n",
        "\n",
        "  # Normalise the absolute difference by the pooled standard deviation\n",
        "  # Adding a small epsilon (1e-7) to the denominator to prevent division by zero\n",
        "  abs_selectivity_for_cond1xcond2 /= np.sqrt((std_activity[0]**2 + std_activity[1]**2 + 1e-7)/2)\n",
        "\n",
        "  # Get the indices of the units sorted by their selectivity in ascending order\n",
        "  sorted_indexes = np.argsort(abs_selectivity_for_cond1xcond2)\n",
        "\n",
        "  # Return the selectivity values and the sorted unit indexes\n",
        "  return abs_selectivity_for_cond1xcond2, sorted_indexes"
      ],
      "metadata": {
        "id": "hLTXFIV518gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NETWORK LEISONING !!!! NEEDS BIC RELATED MODIFICATIONS"
      ],
      "metadata": {
        "id": "pow7TcLBzyoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lesion_network(trained_network, units_to_lesion):\n",
        "  # May not work for all network configs (designed on LRNN NB 1 HL(LeakyRNN))\n",
        "    try:\n",
        "        # Create a deep copy of the network\n",
        "        lesioned_network = deepcopy(trained_network)\n",
        "        print(\"Created a deep copy of the network.\")\n",
        "\n",
        "        # Locate the h2h Linear layer #### !!!! ---- NEEDS BIC Related Modifications ---- (Layer Attributes and Effective Weights) ------ !!!!\n",
        "        if hasattr(lesioned_network, 'rnn') and hasattr(lesioned_network.rnn, 'h2h'):\n",
        "            h2h_layer = lesioned_network.rnn.h2h # Direct ref?\n",
        "            print(f\"Found h2h layer: {h2h_layer}\")\n",
        "\n",
        "            # Get the weight tensor\n",
        "            h2h_weights = h2h_layer.weight.data.cpu().numpy()\n",
        "            print(f\"Original h2h weights shape: {h2h_weights.shape}\")\n",
        "\n",
        "            # Check if the provided unit indices are valid\n",
        "            hidden_size = h2h_weights.shape[0] # Assuming output dim == input dim for recurrent weights\n",
        "            valid_units_to_lesion = [u for u in units_to_lesion if 0 <= u < hidden_size]\n",
        "\n",
        "            if len(valid_units_to_lesion) != len(units_to_lesion):\n",
        "                print(\"Warning: Some provided unit indices were out of bounds.\")\n",
        "                print(f\"Valid hidden unit range is [0, {hidden_size - 1}].\")\n",
        "                print(f\"Lesioning units: {valid_units_to_lesion}\")\n",
        "            else:\n",
        "                print(f\"Lesioning recurrent connections for units: {valid_units_to_lesion}\")\n",
        "\n",
        "\n",
        "            # Set incoming and outgoing recurrent weights for the specified units to zero\n",
        "            # Recurrent weights shape: (output_features, input_features) or (to_units, from_units)\n",
        "            for unit_index in valid_units_to_lesion:\n",
        "                # Set weights *to* this unit from all other units in the h2h layer\n",
        "                h2h_weights[unit_index, :] = 0\n",
        "\n",
        "                # Set weights *from* this unit to all other units in the h2h layer\n",
        "                h2h_weights[:, unit_index] = 0\n",
        "            print(\"Recurrent weights for specified units set to zero.\")\n",
        "\n",
        "            # Update the weight tensor in the lesioned network\n",
        "            h2h_layer.weight.data = torch.from_numpy(h2h_weights).to(h2h_layer.weight.data.device) # Depends on if h2h_layer is direct ref or copy (wouldve seen probs in non BIC)\n",
        "\n",
        "\n",
        "            return lesioned_network\n",
        "\n",
        "        else:\n",
        "            print(\"Error: The network structure is not as expected (missing .rnn.h2h).\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during network lesioning: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "yIkEEN4v1-fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SELECTIVITY AND LEISONING FRAMEWORK"
      ],
      "metadata": {
        "id": "IbizyJKez4mE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leisoned Network for n% most selective Units and Analysis"
      ],
      "metadata": {
        "id": "LPLJGpQ30VxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leison_network_for_top_n_and_test(trained_network, list_of_task_cond_1_cond_2_data_dicts_for_selectivity, testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = None, fig_file_name = 'leisoned_unleisoned' , file_ext='.png', unleisoned_PCA_2d = None, return_results = False):\n",
        "  ## Note:\n",
        "  # calculate_selectivity_indexes is expecting the dicts in list_of_task... to be <trial_num>: 'network_activity',... i.e. testing_trial_and_activity structured so use data func with return like input = false\n",
        "  # Note : some things in this rough func wont work for a diff task or 2d nets\n",
        "\n",
        "  # Produce Leisoned Network\n",
        "  abs_selectivity_, sorted_indexes_ = calculate_selectivity_indexes(list_of_task_cond_1_cond_2_data_dicts_for_selectivity[0], list_of_task_cond_1_cond_2_data_dicts_for_selectivity[1])\n",
        "  units_to_leison_ = sorted_indexes_[-int(len(sorted_indexes_)*n_perc_leison/100):]\n",
        "\n",
        "\n",
        "  leisoned_network_ = lesion_network(trained_network, units_to_leison_)\n",
        "\n",
        "  # Test uneleisoned network\n",
        "  unleisoned_full_testing_data_ = evaluate_network_on_dataset(trained_network, testing_data_set, num_trials=2000)\n",
        "  # Test Leisoned Network\n",
        "  leisoned_full_testing_data_ = evaluate_network_on_dataset(leisoned_network_, testing_data_set, num_trials=2000)\n",
        "\n",
        "\n",
        "  testing_env_info_ = unleisoned_full_testing_data_['testing_env_info']\n",
        "\n",
        "  print(f\"Unleisoned Network Performance: {unleisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Leisoned Network Performance: {leisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "\n",
        "  print(f\"Performance Difference: {((unleisoned_full_testing_data_['testing_trial_performance'] - leisoned_full_testing_data_['testing_trial_performance'])/(unleisoned_full_testing_data_['testing_trial_performance'])) * 100} %\")\n",
        "\n",
        "  # Print a PCA Transformed Plot of the test activities for both networks\n",
        "\n",
        "\n",
        "  if unleisoned_PCA_1d:\n",
        "    one_d_pca_filename = fig_file_name + '_1d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets(unleisoned_PCA_1d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1 across t', save_filename=one_d_pca_filename, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  if unleisoned_PCA_2d:\n",
        "    two_d_pca_filename = fig_file_name + '_2d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets_2d(unleisoned_PCA_2d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1xPC2', save_filename=two_d_pca_filename, add_phase_markers=True, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  all_results_ = {\n",
        "      'abs_selectivity': abs_selectivity_,\n",
        "      'sorted_indexes': sorted_indexes_,\n",
        "      'units_to_leison': units_to_leison_,\n",
        "      'unleisoned_full_testing_data': unleisoned_full_testing_data_,\n",
        "      'leisoned_full_testing_data': leisoned_full_testing_data_\n",
        "  }\n",
        "  if return_results:\n",
        "    return all_results_\n",
        "  else:\n",
        "    print('Done')\n",
        "\n"
      ],
      "metadata": {
        "id": "xBy3V4Cu0iAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SELECTIVITY AND LEISONING Changes for EI and BICS"
      ],
      "metadata": {
        "id": "D5lRPN5N9f0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selectivity - For BICS"
      ],
      "metadata": {
        "id": "PwmXll-v_Es0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_selectivity_indexes_BIC(task_condition_1_data_dict, task_condition_2_data_dict):\n",
        "  \"\"\"\n",
        "  Calculates a selectivity index for each unit between two task conditions.\n",
        "\n",
        "  The index is just the difference in mean activity, normalised by the\n",
        "  pooled standard deviation. Basically, it shows how much a unit's firing\n",
        "  rate changes between the two conditions.\n",
        "\n",
        "  Returns the raw selectivity values (directional), indexes sorted by\n",
        "  the absolute selectivity, and indexes sorted within E/I populations.\n",
        "  \"\"\"\n",
        "  mean_activity = []\n",
        "  std_activity = []\n",
        "\n",
        "  # go through both sets of data\n",
        "  for task_condition in [task_condition_1_data_dict, task_condition_2_data_dict]:\n",
        "    # first, stack all the trial activities into one big array\n",
        "    task_condition_activity = np.concatenate([value['network_activity'] for value in task_condition.values()], axis=0)\n",
        "\n",
        "    # get the mean activity for each unit across all time steps and trials\n",
        "    mean_activity.append(np.mean(task_condition_activity, axis=0))\n",
        "\n",
        "    # and the standard deviation of activity for each unit\n",
        "    std_activity.append(np.std(task_condition_activity, axis=0))\n",
        "\n",
        "  # now calculate the selectivity (the difference in means)\n",
        "  selectivity_for_cond1xcond2 = (mean_activity[0] - mean_activity[1])\n",
        "\n",
        "  # normalise it by the pooled standard deviation\n",
        "  # add eps to the bottom to stop it dividing by zero\n",
        "  selectivity_for_cond1xcond2 /= np.sqrt((std_activity[0]**2 + std_activity[1]**2 + 1e-7)/2)\n",
        "\n",
        "  # get the unit indexes sorted by their absolute selectivity\n",
        "  abs_sorted_indexes = np.argsort(abs(selectivity_for_cond1xcond2))\n",
        "\n",
        "  # this bit sorts the indexes within the E and I populations\n",
        "  E_Prop = 0.8\n",
        "  e_size = int(E_Prop * len(abs_sorted_indexes))\n",
        "  ei_sorted_indexes = (np.argsort(selectivity_for_cond1xcond2[:e_size]), np.argsort(selectivity_for_cond1xcond2[e_size:]+e_size))\n",
        "\n",
        "  # returns raw selectivity (directional), absolute indexes for lesioning, and ei sorted indexes for other analysis (DOES THIS REGARDLESS OF EI OR NOT)\n",
        "  return selectivity_for_cond1xcond2, abs_sorted_indexes, ei_sorted_indexes"
      ],
      "metadata": {
        "id": "Z60PF5INjrW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leisoning for BICs"
      ],
      "metadata": {
        "id": "321qQw7a_Jwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lesion_network_BIC(trained_network, units_to_lesion):\n",
        "    \"\"\"\n",
        "    Takes a trained network and a list of units, and returns a new\n",
        "    network with those units lesioned. It works by setting the incoming\n",
        "    and outgoing recurrent weights for those units to zero.\n",
        "    \"\"\"\n",
        "    # layer_to_leision=None,  this is fine for now. Only need to change when multi layer (use f string for has attr 'rnn')\n",
        "    # Might not work for all network configs (designed on LRNN NB 1 HL(LeakyRNN))\n",
        "    try:\n",
        "        # make a deep copy of the network so we don't break the original\n",
        "        lesioned_network = deepcopy(trained_network)\n",
        "        print(\"Created a deep copy of the network.\")\n",
        "\n",
        "        # find the h2h Linear layer #### ----  doesnt acc need modification, all weights defined at same attribute location\n",
        "        if hasattr(lesioned_network, 'rnn') and hasattr(lesioned_network.rnn, 'h2h'):\n",
        "            # is this a direct ref?\n",
        "            h2h_layer = lesioned_network.rnn.h2h\n",
        "            print(f\"Found h2h layer: {h2h_layer}\")\n",
        "\n",
        "            # get the weight tensor\n",
        "            h2h_weights = h2h_layer.weight.data.cpu().numpy()\n",
        "            print(f\"Original h2h weights shape: {h2h_weights.shape}\")\n",
        "\n",
        "            # check the unit indexes are actually valid\n",
        "            hidden_size = h2h_weights.shape[0] # assumes output dim == input dim for recurrent weights\n",
        "            valid_units_to_lesion = [u for u in units_to_lesion if 0 <= u < hidden_size]\n",
        "\n",
        "            if len(valid_units_to_lesion) != len(units_to_lesion):\n",
        "                print(\"Warning: Some provided unit indices were out of bounds.\")\n",
        "                print(f\"Valid hidden unit range is [0, {hidden_size - 1}].\")\n",
        "                print(f\"Lesioning units: {valid_units_to_lesion}\")\n",
        "            else:\n",
        "                print(f\"Lesioning recurrent connections for units: {valid_units_to_lesion}\")\n",
        "\n",
        "\n",
        "            # set the incoming and outgoing recurrent weights for the units to zero\n",
        "            # recurrent weights shape is (to_units, from_units)\n",
        "            for unit_index in valid_units_to_lesion:\n",
        "                # set weights *to* this unit from all other units\n",
        "                h2h_weights[unit_index, :] = 0\n",
        "\n",
        "                # set weights *from* this unit to all other units\n",
        "                h2h_weights[:, unit_index] = 0\n",
        "            print(\"Recurrent weights for specified units set to zero.\")\n",
        "\n",
        "            # update the weights in the new lesioned network\n",
        "            # this depends on if h2h_layer is a direct ref or a copy (we would've seen problems in the non-BIC version if it was wrong)\n",
        "            h2h_layer.weight.data = torch.from_numpy(h2h_weights).to(h2h_layer.weight.data.device)\n",
        "\n",
        "\n",
        "            return lesioned_network\n",
        "\n",
        "        else:\n",
        "            print(\"Error: The network structure is not as expected (missing .rnn.h2h).\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during network lesioning: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "L-er6dCOkMhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Selectivity and Leisoning (Accomodate for BICs)"
      ],
      "metadata": {
        "id": "p79wAfEa_RHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def leison_network_for_top_n_and_test_BIC(trained_network, list_of_task_cond_1_cond_2_data_dicts_for_selectivity, testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = None, fig_file_name = 'leisoned_unleisoned' , file_ext='.png', unleisoned_PCA_2d = None, return_results = True):\n",
        "  \"\"\"\n",
        "  A wrapper function to find the most selective units, lesion them,\n",
        "  and then test the network's performance before and after. Also plots stuff.\n",
        "  \"\"\"\n",
        "  # get selectivity and find the top n% of units to lesion\n",
        "  selectivity_for_cond1xcond2_, abs_sorted_indexes_, ei_sorted_indexes_ = calculate_selectivity_indexes_BIC(list_of_task_cond_1_cond_2_data_dicts_for_selectivity[0], list_of_task_cond_1_cond_2_data_dicts_for_selectivity[1])\n",
        "  units_to_leison_ = abs_sorted_indexes_[-int(len(abs_sorted_indexes_)*n_perc_leison/100):]\n",
        "\n",
        "  # create the lesioned network\n",
        "  leisoned_network_ = lesion_network_BIC(trained_network, units_to_leison_)\n",
        "\n",
        "  # evaluate both networks on the test data\n",
        "  unleisoned_full_testing_data_ = evaluate_network_on_dataset(trained_network, testing_data_set, num_trials=2000)\n",
        "  leisoned_full_testing_data_ = evaluate_network_on_dataset(leisoned_network_, testing_data_set, num_trials=2000)\n",
        "\n",
        "\n",
        "  testing_env_info_ = unleisoned_full_testing_data_['testing_env_info']\n",
        "\n",
        "  # print out the results\n",
        "  print(f\"Unleisoned Network Performance: {unleisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "  print(f\"Leisoned Network Performance: {leisoned_full_testing_data_['testing_trial_performance'] * 100} %\")\n",
        "  print(f\"Performance Difference: {((unleisoned_full_testing_data_['testing_trial_performance'] - leisoned_full_testing_data_['testing_trial_performance'])/(unleisoned_full_testing_data_['testing_trial_performance'])) * 100} %\")\n",
        "\n",
        "  # plot PCA trajectories if a pca object was given\n",
        "  if unleisoned_PCA_1d:\n",
        "    one_d_pca_filename = fig_file_name + '_1d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets(unleisoned_PCA_1d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1 across t', save_filename=one_d_pca_filename, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  if unleisoned_PCA_2d:\n",
        "    two_d_pca_filename = fig_file_name + '_2d_pca' + file_ext\n",
        "    plot_pca_trajectories_two_datasets_2d(unleisoned_PCA_2d, unleisoned_full_testing_data_['testing_trial_and_activity'], leisoned_full_testing_data_['testing_trial_and_activity'], testing_env_info_, num_trials_to_plot=100, plot_title='(Un)Leisoned for HL Activity in PC1xPC2', save_filename=two_d_pca_filename, add_phase_markers=True, label1=\"Unleisoned\", label2=\"Leisoned\")\n",
        "\n",
        "  # bundle up the results\n",
        "  all_results_ = {\n",
        "      'raw_selectivity': selectivity_for_cond1xcond2_,\n",
        "      'abs_sorted_indexes': abs_sorted_indexes_,\n",
        "      'ei_sorted_indexes': ei_sorted_indexes_,\n",
        "      'units_to_leison': units_to_leison_,\n",
        "      'unleisoned_full_testing_data': unleisoned_full_testing_data_,\n",
        "      'leisoned_full_testing_data': leisoned_full_testing_data_\n",
        "  }\n",
        "  if return_results:\n",
        "    return all_results_\n",
        "  else:\n",
        "    print('Done')"
      ],
      "metadata": {
        "id": "MyYyquwQklog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FULL FPF FUCNTION LIBRARY"
      ],
      "metadata": {
        "id": "oMJpr7pkeU14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import code stub"
      ],
      "metadata": {
        "id": "_JQs02fl2iku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WHEN RUNNING FPF NEED TO DO THIS FIRST (LUCKILY SEEMS TO WORK IN THIS NOTEBOOK UNLIKE DPCA)\n",
        "# also need to add fixed point finder package folder from wd to notebook drive thing\n",
        "# import sys\n",
        "# sys.path.append('/fixed-point-finder-master')\n",
        "# %cd fixed-point-finder-master\n",
        "# from FixedPointFinderTorch import FixedPointFinderTorch as FixedPointFinder\n",
        "# import torch"
      ],
      "metadata": {
        "id": "avA9mfOJesIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRIAL DATA EXTRACTION HELPER (NEW ONE)"
      ],
      "metadata": {
        "id": "ZSh2Vp642kA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_dict_of_trial_data_for_conds_and_hla_index(full_testing_data_dict, dict_of_conds, hla_index=None, return_like_full = False):\n",
        "  \"\"\"\n",
        "  A really important helper function.\n",
        "  It pulls out trial data for specific conditions and can also slice the\n",
        "  network activity data to specific time periods (using an int, tuple, or task phase name).\n",
        "  Replaces that other stupid data processing function I made.\n",
        "  \"\"\"\n",
        "  # TODO: maybe move this to the top of the notebook and integrate better\n",
        "  full_testing_data_dict_ = deepcopy(full_testing_data_dict)\n",
        "  env_info = full_testing_data_dict_['testing_env_info'] # must be there\n",
        "  trial_testing_data_dict_ = full_testing_data_dict_['testing_trial_and_activity'] # must be there\n",
        "\n",
        "  # work out how to slice the data based on hla_index\n",
        "  slicer = None\n",
        "  if isinstance(hla_index, int):\n",
        "    slicer = hla_index\n",
        "  if isinstance(hla_index, tuple):\n",
        "    if hla_index[0] < hla_index[1]:\n",
        "      slicer = slice(hla_index[0], hla_index[1])\n",
        "    else:\n",
        "      slicer = slice(hla_index[1], hla_index[0])\n",
        "  if isinstance(hla_index, str):\n",
        "    if hla_index in env_info['trial_start_ind'] and hla_index in env_info['trial_end_ind']:\n",
        "      slicer = slice(env_info['trial_start_ind'][hla_index], env_info['trial_end_ind'][hla_index])\n",
        "  if isinstance(hla_index, list):\n",
        "    items_in_list_in_env_info = [item for item in hla_index if item in env_info['trial_start_ind'] and item in env_info['trial_end_ind']]\n",
        "    if items_in_list_in_env_info:\n",
        "      slicer = slice(min([env_info['trial_start_ind'][i] for i in hla_index]), max([env_info['trial_end_ind'][i] for i in hla_index]))\n",
        "\n",
        "  # filter the dictionary based on the conditions\n",
        "  cond_filtered_dict = {}\n",
        "  for trial_id, trial_data in trial_testing_data_dict_.items():\n",
        "    if all([trial_data[f'{cond_key}'] == cond_value for cond_key, cond_value in dict_of_conds.items()]):\n",
        "      if slicer:\n",
        "        trial_data['network_activity'] = trial_data['network_activity'][slicer]\n",
        "\n",
        "      cond_filtered_dict[trial_id] = trial_data\n",
        "\n",
        "  # adding this in so i can reuse output of just conditional to perform the index slicing too!\n",
        "  if return_like_full:\n",
        "    return {'testing_trial_and_activity': cond_filtered_dict, 'testing_env_info': env_info}\n",
        "  else:\n",
        "    return cond_filtered_dict"
      ],
      "metadata": {
        "id": "1vKzNlF7k5r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(full_testing_data_dict, dict_of_conds, hla_index=None, return_like_full = False):\n",
        "  \"\"\"\n",
        "  The new version of the really important helper function.\n",
        "\n",
        "  Filters trials based on conditions and slices the activity data to specific\n",
        "  time periods. This one also handles slicing both 'network_activity' and\n",
        "  'network_hidden_state' if it exists.\n",
        "  \"\"\"\n",
        "  # TODO: maybe move this to the top of the notebook and integrate better\n",
        "  full_testing_data_dict_ = deepcopy(full_testing_data_dict)\n",
        "  env_info = full_testing_data_dict_['testing_env_info'] # must be there\n",
        "  trial_testing_data_dict_ = full_testing_data_dict_['testing_trial_and_activity'] # must be there\n",
        "\n",
        "  # work out how to slice the data based on hla_index\n",
        "  slicer = None\n",
        "  if isinstance(hla_index, int):\n",
        "    slicer = hla_index\n",
        "  if isinstance(hla_index, tuple):\n",
        "    if hla_index[0] < hla_index[1]:\n",
        "      slicer = slice(hla_index[0], hla_index[1])\n",
        "    else:\n",
        "      slicer = slice(hla_index[1], hla_index[0])\n",
        "  if isinstance(hla_index, str):\n",
        "    if hla_index in env_info['trial_start_ind'] and hla_index in env_info['trial_end_ind']:\n",
        "      slicer = slice(env_info['trial_start_ind'][hla_index], env_info['trial_end_ind'][hla_index])\n",
        "  if isinstance(hla_index, list):\n",
        "    items_in_list_in_env_info = [item for item in hla_index if item in env_info['trial_start_ind'] and item in env_info['trial_end_ind']]\n",
        "    if items_in_list_in_env_info:\n",
        "      slicer = slice(min([env_info['trial_start_ind'][i] for i in hla_index]), max([env_info['trial_end_ind'][i] for i in hla_index]))\n",
        "\n",
        "  # filter the dictionary based on the conditions\n",
        "  cond_filtered_dict = {}\n",
        "  for trial_id, trial_data in trial_testing_data_dict_.items():\n",
        "    if all([trial_data[f'{cond_key}'] == cond_value for cond_key, cond_value in dict_of_conds.items()]):\n",
        "      # if we're slicing, apply it to both activity and hidden_state if they exist\n",
        "      if slicer:\n",
        "        trial_data['network_activity'] = trial_data['network_activity'][slicer]\n",
        "        network_hidden_state_ = trial_data.get('network_hidden_state', None)\n",
        "        if network_hidden_state_ is not None:\n",
        "          trial_data['network_hidden_state'] = network_hidden_state_[slicer]\n",
        "\n",
        "      cond_filtered_dict[trial_id] = trial_data\n",
        "\n",
        "  # adding this in so i can reuse output of just conditional to perform the index slicing too!\n",
        "  if return_like_full:\n",
        "    return {'testing_trial_and_activity': cond_filtered_dict, 'testing_env_info': env_info}\n",
        "  else:\n",
        "    return cond_filtered_dict"
      ],
      "metadata": {
        "id": "vOst54VelDbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF Specific Helper Funcs"
      ],
      "metadata": {
        "id": "HvHFRufh2rl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_random_samples_with_opt_noise(list_of_arrays, num_samples, std_pc=0.0, random=False, random_range_modifier = 0.0, protected_indexes=None):\n",
        "    \"\"\"\n",
        "    Gets samples from a list of arrays. Has two main modes.\n",
        "    1. random=True: creates brand new random samples within the range of the original data.\n",
        "    2. random=False: samples from the original data (with replacement) and can add\n",
        "       some gaussian noise if you want.\n",
        "    \"\"\"\n",
        "    # make sure we're working with a numpy array\n",
        "    if not isinstance(list_of_arrays, np.ndarray):\n",
        "        list_of_arrays_np = np.array(list_of_arrays)\n",
        "    else:\n",
        "        list_of_arrays_np = list_of_arrays\n",
        "\n",
        "    # get the number of dimensions\n",
        "    n_dim = list_of_arrays_np.shape[-1] if list_of_arrays_np.ndim > 1 else list_of_arrays_np.shape[0] # Check this (alt notebook now?)\n",
        "\n",
        "    # if random=True, make completely new samples\n",
        "    if random:\n",
        "        # find the min/max for each unit to create a plausible range\n",
        "        min_per_unit = np.min(list_of_arrays_np, axis=0) * (1.0 - random_range_modifier)\n",
        "        max_per_unit = np.max(list_of_arrays_np, axis=0) * (1.0 + random_range_modifier)\n",
        "\n",
        "        # now create the random arrays\n",
        "        # np.random.uniform(low, high, size)\n",
        "        sampled_arrays = np.random.uniform(low=min_per_unit,\n",
        "                                           high=max_per_unit,\n",
        "                                           size=(num_samples, n_dim))\n",
        "        return sampled_arrays\n",
        "\n",
        "    # otherwise, sample from the existing arrays\n",
        "    # samples with replacement\n",
        "    random_indices = np.random.choice(len(list_of_arrays_np), size=num_samples)\n",
        "    sampled_arrays = list_of_arrays_np[random_indices]\n",
        "\n",
        "    # if we want noise, add it now\n",
        "    if std_pc > 0.0:\n",
        "        # calculate noise based on a percentage of each unit's std dev\n",
        "        std_dev_per_unit = np.std(list_of_arrays_np, axis=0)\n",
        "        noise_scale_per_unit = std_pc * std_dev_per_unit\n",
        "        noise = np.random.randn(num_samples, n_dim) * noise_scale_per_unit\n",
        "\n",
        "        # don't add noise to any protected units\n",
        "        if protected_indexes is not None:\n",
        "            noise[:, protected_indexes] = 0.0\n",
        "        sampled_arrays += noise\n",
        "        return sampled_arrays\n",
        "\n",
        "    # if no noise, just return the samples as they are\n",
        "    return sampled_arrays"
      ],
      "metadata": {
        "id": "hbgx5v-DlU-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input and IC Data Construction Func"
      ],
      "metadata": {
        "id": "NM7lAtJr2vsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def obtain_data_for_fpf_setup_bic(filtered_trial_data_dict, num_init_conds, noise_std_or_random_range_modifier = 0.0, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key='network_activity'):\n",
        "    \"\"\"\n",
        "    Prepares the initial conditions for the fixed point finder.\n",
        "\n",
        "    It creates a set of initial hidden layer activities and corresponding inputs\n",
        "    based on the provided trial data.\n",
        "    \"\"\"\n",
        "    if list_of_input_arrays is None:\n",
        "        # default inputs if none are provided (what shape does this go to?)\n",
        "        list_of_input_arrays = [np.array([0.0, 0.0, 1.0]),np.array([0.0,1.0,0.0]),np.array([1.0,0.0,0.0])]\n",
        "\n",
        "    list_of_hidden_activity = [trial_data[f'{hidden_key}'] for trial_data in filtered_trial_data_dict.values()]\n",
        "    list_of_hidden_activity_proc = []\n",
        "\n",
        "    # flatten the list of activities into a list of 1d arrays\n",
        "    for hla_arr in list_of_hidden_activity:\n",
        "        if hla_arr.ndim == 2:\n",
        "            list_of_hidden_activity_proc.extend([arr for arr in hla_arr])\n",
        "        else:\n",
        "            list_of_hidden_activity_proc.append(hla_arr)\n",
        "\n",
        "    list_of_hidden_activity_proc = np.array(list_of_hidden_activity_proc)\n",
        "\n",
        "    if random_ics:\n",
        "        init_hla_cond_array = get_random_samples_with_opt_noise(list_of_hidden_activity_proc, num_init_conds, std_pc=0.0, random=True, random_range_modifier = noise_std_or_random_range_modifier, protected_indexes=None)\n",
        "    else:\n",
        "        init_hla_cond_array = get_random_samples_with_opt_noise(list_of_hidden_activity_proc, num_init_conds, std_pc=noise_std_or_random_range_modifier, random=False, random_range_modifier = 0.0, protected_indexes=noise_protected_indexes_hla)\n",
        "\n",
        "\n",
        "    # make sure we have the same number of inputs as initial conditions\n",
        "    input_arrays = get_random_samples_with_opt_noise(list_of_input_arrays, num_init_conds)\n",
        "\n",
        "    return init_hla_cond_array, input_arrays"
      ],
      "metadata": {
        "id": "-O7-LBWzleqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed Point Finding"
      ],
      "metadata": {
        "id": "NV2ugkEK2zoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_fixed_point_finding(rnn_layer, initial_hla_array, fixed_input_array, n_iters_fpf = 20000):\n",
        "  \"\"\"\n",
        "  A wrapper for the FixedPointFinder. It takes an RNN layer,\n",
        "  a set of initial hidden activities, and a fixed input, then\n",
        "  goes and finds the fixed points.\n",
        "  \"\"\"\n",
        "  fp_finder = None\n",
        "  fp_finder = FixedPointFinder(rnn_layer, max_iters = n_iters_fpf)\n",
        "\n",
        "  # convert to numpy just in case (shouldnt be needed though)\n",
        "  if torch.is_tensor(initial_hla_array):\n",
        "    initial_hla_array = initial_hla_array.cpu().numpy()\n",
        "  if torch.is_tensor(fixed_input_array):\n",
        "    fixed_input_array = fixed_input_array.cpu().numpy()\n",
        "\n",
        "  if fixed_input_array.shape[0] != initial_hla_array.shape[0] and fixed_input_array.shape[0] != 1:\n",
        "    print('Fixed input should either be 1 vector (1,n_input_dim) shaped, or have same number of \"rows\" as initial conditions')\n",
        "    # not sure how fpf handles this, might need to raise an error here later\n",
        "    print('Expect error but continuing.')\n",
        "\n",
        "\n",
        "  unique_fps, all_fps = fp_finder.find_fixed_points(initial_hla_array, fixed_input_array)\n",
        "  fp_finder = None # clean up\n",
        "  # can change to return all_fps if needed, hasn't been so far\n",
        "  print(unique_fps.xstar.shape)\n",
        "  print(all_fps.xstar.shape)\n",
        "  return unique_fps"
      ],
      "metadata": {
        "id": "zqtvlIihlosp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed Point PCA Plotter"
      ],
      "metadata": {
        "id": "QxzpezHJ22k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def plot_pca_trajectories_with_fps_BICS(\n",
        "    fixed_points_obj,   # A single FixedPoints object\n",
        "    pca_object,         # fitted PCA object (assumes n_components>=2)\n",
        "    trial_data_dict=None,# pre-filtered dict of trial data for the specific scenario\n",
        "    trial_env_info=None, # env info (dt, trial_start_ind, trial_end_ind)\n",
        "    task_phase_str=None, # e.g., 'delay', 'sample' - corresponds to the scenario's phase\n",
        "    plot_prev=True,      # If True, plot pre-phase activity in faint black\n",
        "    plot_title=None,     # Optional plot title (ignored)\n",
        "    filename=None,       # Optional filename to save (triggers save and close)\n",
        "    max_trials_to_plot=100, # Max number of trial trajectories to plot\n",
        "    fixed_axis_limits=None, # (xmin, xmax, ymin, ymax) tuple for fixed axis limits\n",
        "    activate_fps = False # set dep. on if using activity or state\n",
        "    ):\n",
        "    \"\"\"\n",
        "    This is the big one. It plots the fixed points and the average 2D PCA\n",
        "    trajectories for a specific task phase.\n",
        "\n",
        "    It can show the activity from before the main phase in faint black and\n",
        "    has a pretty complex legend for all the different elements.\n",
        "    \"\"\"\n",
        "    # ---- Style guide definitions ----\n",
        "    STYLE_GUIDE_COLORS = {\n",
        "        (0.0, 0.0):   {'color': '#68d3e8', 'label': 'S: 0.00, T: 0.00'},\n",
        "        (3.14, 0.0):  {'color': '#e69010', 'label': 'S: 3.14, T: 0.00'},\n",
        "        (0.0, 3.14):  {'color': '#6b08bd', 'label': 'S: 0.00, T: 3.14'},\n",
        "        (3.14, 3.14): {'color': '#69420c', 'label': 'S: 3.14, T: 3.14'},\n",
        "    }\n",
        "    STYLE_GUIDE_MARKERS = {\n",
        "        'stable_fp':    {'marker': 'D', 'color': 'g', 'label': 'Stable Fixed Point', 'size': 120},\n",
        "        'unstable_fp':  {'marker': 'o', 'color': 'r', 'label': 'Unstable Fixed Point', 'size': 120},\n",
        "        'start':        {'marker': 's', 'color': 'k', 'label': 'Start', 'size': 64},\n",
        "        'phase_trans':  {'marker': '*', 'color': 'gold', 'label': 'Phase Transition', 'size': 144}\n",
        "    }\n",
        "\n",
        "    # ---- Plotting Setup ----\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    ax.grid(True, linestyle='--', color='lightgrey')\n",
        "    ax.axhline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.axvline(0, color='grey', linestyle='-', linewidth=0.8)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    legend_handles = []\n",
        "    plotted_fp_types = set()\n",
        "    plotted_conditions = set()\n",
        "\n",
        "    # ---- 1. Plot the fixed points ----\n",
        "    if fixed_points_obj:\n",
        "        fp_activity = fixed_points_obj.xstar\n",
        "        if activate_fps:\n",
        "             # Assumes ReLU\n",
        "            fp_activity = np.maximum(0, fp_activity)\n",
        "\n",
        "        transformed_fps = pca_object.transform(fp_activity)[:, :2]\n",
        "\n",
        "        for i in range(len(transformed_fps)):\n",
        "            is_stable = fixed_points_obj.is_stable[i]\n",
        "            style_key = 'stable_fp' if is_stable else 'unstable_fp'\n",
        "            style = STYLE_GUIDE_MARKERS[style_key]\n",
        "\n",
        "            ax.scatter(transformed_fps[i, 0], transformed_fps[i, 1],\n",
        "                       marker=style['marker'], facecolor=style['color'], s=style['size'],\n",
        "                       edgecolor='k', linewidth=1.0, zorder=10)\n",
        "            plotted_fp_types.add(style_key)\n",
        "\n",
        "    # ---- 2. Plot the trial trajectories ----\n",
        "    if trial_data_dict and trial_env_info and task_phase_str:\n",
        "        phase_start_idx = trial_env_info['trial_start_ind'].get(task_phase_str)\n",
        "        phase_end_idx = trial_env_info['trial_end_ind'].get(task_phase_str)\n",
        "        phase_order = list(trial_env_info.get('trial_start_ind', {}).keys())\n",
        "\n",
        "        if phase_start_idx is not None and phase_end_idx is not None:\n",
        "            grouped_trajectories = defaultdict(list)\n",
        "            limited_trials = dict(list(trial_data_dict.items())[:max_trials_to_plot])\n",
        "\n",
        "            for trial_dict in limited_trials.values():\n",
        "                stim_condition = (round(trial_dict['sample_stim_value'], 2), round(trial_dict['test_stim_value'], 2))\n",
        "                if stim_condition in STYLE_GUIDE_COLORS:\n",
        "                    activity = np.array(trial_dict['network_activity'])\n",
        "                    grouped_trajectories[stim_condition].append(pca_object.transform(activity)[:, :2])\n",
        "\n",
        "            for condition, trajectories in grouped_trajectories.items():\n",
        "                if not trajectories: continue\n",
        "                plotted_conditions.add(condition)\n",
        "                mean_traj = np.mean(np.array(trajectories), axis=0)\n",
        "\n",
        "                # plot the bit before this phase in faint black\n",
        "                if plot_prev and phase_start_idx > 0:\n",
        "                    pre_phase_seg = mean_traj[0:phase_start_idx]\n",
        "                    ax.plot(pre_phase_seg[:, 0], pre_phase_seg[:, 1], color='k', lw=1.0, alpha=0.8)\n",
        "\n",
        "                # plot the main phase bit in its proper colour\n",
        "                in_phase_seg = mean_traj[phase_start_idx-1:phase_end_idx]\n",
        "                ax.plot(in_phase_seg[:, 0], in_phase_seg[:, 1], color=STYLE_GUIDE_COLORS[condition]['color'], lw=2.5)\n",
        "\n",
        "                # add the start marker (always at timepoint 0)\n",
        "                start_style = STYLE_GUIDE_MARKERS['start']\n",
        "                ax.plot(mean_traj[0, 0], mean_traj[0, 1], marker=start_style['marker'], color=start_style['color'],\n",
        "                        markersize=np.sqrt(start_style['size']), linestyle='None', zorder=5)\n",
        "\n",
        "                # add markers for phase transitions\n",
        "                indices_to_mark = []\n",
        "                if task_phase_str in phase_order:\n",
        "                    current_phase_position = phase_order.index(task_phase_str)\n",
        "                    indices_to_mark.append(phase_end_idx - 1) # end of current phase\n",
        "\n",
        "                    if plot_prev:\n",
        "                        # ends of all previous phases\n",
        "                        for i in range(current_phase_position):\n",
        "                            prev_end_idx = trial_env_info['trial_end_ind'].get(phase_order[i])\n",
        "                            if prev_end_idx:\n",
        "                                indices_to_mark.append(prev_end_idx - 1)\n",
        "\n",
        "                phase_trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "                # Use set to plot each unique index only once\n",
        "                for end_idx in set(filter(None, indices_to_mark)):\n",
        "                    if end_idx >= 0 and end_idx < len(mean_traj):\n",
        "                        ax.plot(mean_traj[end_idx, 0], mean_traj[end_idx, 1],\n",
        "                                marker=phase_trans_style['marker'],\n",
        "                                color=phase_trans_style['color'],\n",
        "                                markersize=np.sqrt(phase_trans_style['size']),\n",
        "                                linestyle='None', zorder=5)\n",
        "\n",
        "    # ---- 3. Build the fancy legend ----\n",
        "    # fixed point markers\n",
        "    for fp_type in sorted(list(plotted_fp_types)):\n",
        "        style = STYLE_GUIDE_MARKERS[fp_type]\n",
        "        legend_handles.append(Line2D([0], [0], marker=style['marker'], color='w', label=style['label'],\n",
        "                                     markerfacecolor=style['color'], markeredgecolor='k', markersize=np.sqrt(style['size'])))\n",
        "    if plotted_fp_types: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # trial condition lines\n",
        "    for condition in sorted(list(plotted_conditions)):\n",
        "        style = STYLE_GUIDE_COLORS[condition]\n",
        "        legend_handles.append(Line2D([0], [0], color=style['color'], lw=2.5, label=style['label']))\n",
        "    if plotted_conditions: legend_handles.append(Line2D([0], [0], color='w', label=''))\n",
        "\n",
        "    # other markers (start, phase transition)\n",
        "    if plotted_conditions:\n",
        "        start_style = STYLE_GUIDE_MARKERS['start']\n",
        "        legend_handles.append(Line2D([0], [0], marker=start_style['marker'], color='w', label=start_style['label'],\n",
        "                                     markerfacecolor=start_style['color'], markersize=np.sqrt(start_style['size'])))\n",
        "        trans_style = STYLE_GUIDE_MARKERS['phase_trans']\n",
        "        legend_handles.append(Line2D([0], [0], marker=trans_style['marker'], color='w', label=trans_style['label'],\n",
        "                                     markerfacecolor=trans_style['color'], markersize=np.sqrt(trans_style['size'])))\n",
        "\n",
        "    ax.legend(handles=legend_handles, title=\"Legend\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "    # ---- 4. Final plot tweaks ----\n",
        "    if fixed_axis_limits:\n",
        "        ax.set_xlim(fixed_axis_limits[0], fixed_axis_limits[1])\n",
        "        ax.set_ylim(fixed_axis_limits[2], fixed_axis_limits[3])\n",
        "\n",
        "    ax.set_xlabel('Principal Component 1', fontsize=14)\n",
        "    ax.set_ylabel('Principal Component 2', fontsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "\n",
        "    # ---- 5. Save or show the plot ----\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename) and not os.path.exists(os.path.dirname(filename)):\n",
        "                os.makedirs(os.path.dirname(filename))\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ZVkiyuSbl_nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to run full FPF (based on our implementation)"
      ],
      "metadata": {
        "id": "rCCg6zd1i_ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fpf_2d_pca_plot_BIC(rnn_for_fpf, testing_trial_data_for_fpa, testing_trial_env_for_fpa, pca_object_for_plotting = None, ic_period = 'sample', fixed_input_array_ = [[1.0,0.0,1.0]], trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=False, use_noisey_ics = False, filename_for_plot = 'figure.png', title_for_plot = 'Sample Period 0.0 Stimulus Input Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_hidden_state'):\n",
        "    \"\"\"\n",
        "    A high-level wrapper to run the whole analysis pipeline:\n",
        "    1. Extracts data for a specific task period.\n",
        "    2. Generates initial conditions (straight, random, or with noise).\n",
        "    3. Runs the fixed-point finder.\n",
        "    4. Plots the results (trajectories and fixed points) on a 2D PCA plot.\n",
        "    \"\"\"\n",
        "    # if using hidden state for FPF (AND HIDDEN ACTIVITY FOR REST OF ANALYSIS), need to activate the FPs (e.g. ReLU) before plotting\n",
        "    _activate_fps = True if hidden_key == 'network_hidden_state' else False\n",
        "\n",
        "    # get the data from the very first timestep of the specified period to generate ICs from\n",
        "    period_i_data_test_period = extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(testing_trial_data_for_fpa, {'network_correct': True}, return_like_full=True, hla_index= ic_period)\n",
        "    period_i_0_trial_data = extract_dict_of_trial_data_for_conds_and_hla_index_BICFPF(period_i_data_test_period, {'network_correct': True}, return_like_full=False, hla_index=0)\n",
        "\n",
        "    # 1. Generate the initial conditions for the FPF\n",
        "    list_of_ic_arrs = []\n",
        "    # always include the straight samples\n",
        "    ic_arr_0, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds=1000, noise_std_or_random_range_modifier = 0.0, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "    list_of_ic_arrs.append(ic_arr_0)\n",
        "    # optionally add random and noisy ICs\n",
        "    if use_random_ics:\n",
        "        ic_arr_1, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds = 100, noise_std_or_random_range_modifier = 0.1, random_ics = True, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "        list_of_ic_arrs.append(ic_arr_1)\n",
        "    if use_noisey_ics:\n",
        "        ic_arr_2, _ = obtain_data_for_fpf_setup_bic(period_i_0_trial_data, num_init_conds = 100, noise_std_or_random_range_modifier = 0.1, random_ics = False, noise_protected_indexes_hla = None, list_of_input_arrays = None, hidden_key=hidden_key)\n",
        "        list_of_ic_arrs.append(ic_arr_2)\n",
        "    period_i_0_init_conds = np.concatenate(list_of_ic_arrs, axis=0)\n",
        "\n",
        "    # 2. Run the fixed-point finder\n",
        "    unique_fps_period_i_input_j = perform_fixed_point_finding(rnn_layer=rnn_for_fpf, initial_hla_array=period_i_0_init_conds, fixed_input_array=fixed_input_array_)\n",
        "\n",
        "    # 3. Get the trial data for plotting the trajectories\n",
        "    period_cond_trial_data = extract_dict_of_trial_data_for_conds_and_hla_index(testing_trial_data_for_fpa, trial_cond_for_plot, return_like_full=False)\n",
        "\n",
        "    # 4. Make the final plot\n",
        "    plot_pca_trajectories_with_fps_BICS(\n",
        "      fixed_points_obj = unique_fps_period_i_input_j,\n",
        "      pca_object = pca_object_for_plotting,\n",
        "      trial_data_dict=period_cond_trial_data,\n",
        "      trial_env_info=testing_trial_env_for_fpa,\n",
        "      task_phase_str= ic_period,\n",
        "      plot_prev=plot_prev,\n",
        "      plot_title=title_for_plot,\n",
        "      filename=filename_for_plot,\n",
        "      max_trials_to_plot=max_trials_to_plot,\n",
        "      activate_fps=_activate_fps\n",
        "      )"
      ],
      "metadata": {
        "id": "_V6yLu_DmcEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Trial Run with 'Functionised' Notebook ---\n"
      ],
      "metadata": {
        "id": "G-3WMCKFqDSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINING BIC NETWORKS (LAST UPDATE : 1507_4:07pm)"
      ],
      "metadata": {
        "id": "6HfrDvwBeWQt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAI8fAKFabC4"
      },
      "source": [
        "## LeakyRNN Layer - No Self Connections, State,Output Separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70yOyEMH4wcI"
      },
      "outputs": [],
      "source": [
        "# Leaky RNN with No Self connections\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class LeakyRNN_NSC_MS(nn.Module):\n",
        "    \"\"\"Leaky RNN No Self Connections and Maintained Unit State\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt, tau=100, **kwargs): # dt is now required\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "        self.batch_first = False # For fixed point finder\n",
        "        # Check for stability (/biological plausibility)\n",
        "        if self.alpha > 1.0:\n",
        "            print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0. This can lead to numerical instability.\")\n",
        "\n",
        "        # self.nsc_mask = self.create_no_self_conn_mask()\n",
        "        mask = torch.ones(self.hidden_size, self.hidden_size) - torch.eye(self.hidden_size, self.hidden_size)\n",
        "        self.register_buffer('nsc_mask', mask)\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      # Initialise input-to-hidden layer with Kaiming Uniform\n",
        "      init.kaiming_uniform_(self.input2h.weight, a=math.sqrt(5))\n",
        "      if self.input2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.input2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.input2h.bias, -bound, bound)\n",
        "\n",
        "      # Initialise hidden-to-hidden layer with Orthogonal\n",
        "      init.orthogonal_(self.h2h.weight)\n",
        "      if self.h2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.h2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.h2h.bias, -bound, bound)\n",
        "\n",
        "\n",
        "    def init_hidden(self, input):\n",
        "      batch_size = input.shape[1]\n",
        "      return (torch.zeros(batch_size, self.hidden_size).to(input.device), torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step. (Now using a maintained internal state)\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "\n",
        "        state, output = hidden\n",
        "\n",
        "        effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "\n",
        "        recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "\n",
        "        total_input = self.input2h(input) + recurrent_component\n",
        "        state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "        output = torch.relu(state)\n",
        "        return state, output\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden[1])\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "\n",
        "\n",
        "        return output, hidden # Note, hidden is now tuple with: (final state, final output) which are (shape?) (previously it was just (final output))\n",
        "\n",
        "    def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "      state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "      effective_h2h_weights = self.h2h.weight * self.nsc_mask\n",
        "      recurrent_component = F.linear(output, effective_h2h_weights, self.h2h.bias)\n",
        "      total_input = self.input2h(input) + recurrent_component\n",
        "      state = state * (1 - self.alpha) + total_input * self.alpha\n",
        "      return state\n",
        "\n",
        "\n",
        "    def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "      if hidden_state_only is None:\n",
        "          hidden_state_only = self.init_hidden(input)[1]\n",
        "      elif isinstance(hidden_state_only, tuple):\n",
        "          hidden_state_only = hidden_state_only[1]\n",
        "\n",
        "      output = []\n",
        "      steps = range(input.size(0))\n",
        "      for i in steps:\n",
        "          hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "          hidden_output = torch.relu(hidden_state_only)\n",
        "          output.append(hidden_output)\n",
        "      output = torch.stack(output, dim=0)\n",
        "      return output, hidden_state_only\n",
        "\n",
        "    def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        hidden_state_only_list = []\n",
        "        # hidden_state_only_list.append(hidden_state_only)\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_state_only_list.append(hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "        return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NSC : Main Network (s/o sep)"
      ],
      "metadata": {
        "id": "fXkIF_fseqNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGfTkthSexQp"
      },
      "outputs": [],
      "source": [
        "class RNNNet_MS(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer. That uses the NSC and Maintained State version of the LRNN Layer\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # Leaky RNN\n",
        "        self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.all_layers = [self.fc]\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      for layer in self.all_layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "          init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "        if layer.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output # So this is actually unchanged except for the self.rnn = LeakyRNN_NSC_MS(..)\n",
        "\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial Embedding with WD Penalty"
      ],
      "metadata": {
        "id": "W7cJa-Ime4Hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Approach - WD Regulariser Module (used in training with other network)"
      ],
      "metadata": {
        "id": "XgC5yYHBe7Ua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_ubcU_ZXsOZ"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import scipy.spatial\n",
        "class Reg_WD(torch.nn.Module):\n",
        "\n",
        "    \"\"\"A regulariser for spatially embedded RNNs.\n",
        "  Applies L1 regularisation to recurrent kernel of\n",
        "  RNN which is weighted by the distance of units\n",
        "  in predefined 3D space.\n",
        "  Calculation:\n",
        "      reg_WD * sum[distance_matrix o recurrent_kernel]\n",
        "  Attributes:\n",
        "      reg_WD: Float; Weighting of Reg_WD regularisation term.\n",
        "      network_structure: Defines a 3D grid specifying the\n",
        "      dimensions of a 3D space where neurons are placed.\n",
        "      The tuple specifies the range of coordinates along\n",
        "      each of the three axes in this 3D space.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, reg_WD=0.01, neuron_num=64, network_structure=(4,4,4), coordinates_list=None, distance_power=1, distance_metric='euclidean'):\n",
        "        super(Reg_WD, self).__init__()\n",
        "\n",
        "        self.distance_power = distance_power\n",
        "        self.reg_WD = torch.tensor([reg_WD], dtype=torch.float32)\n",
        "\n",
        "        # Set up tensor with distance matrix\n",
        "        nx = np.arange(network_structure[0])\n",
        "        ny = np.arange(network_structure[1])\n",
        "        nz = np.arange(network_structure[2])\n",
        "\n",
        "        # Set up coordinate grid\n",
        "        x, y, z = np.meshgrid(nx, ny, nz)\n",
        "        self.coordinates = [x.ravel(), y.ravel(), z.ravel()]\n",
        "\n",
        "        # Override coordinate grid if provided in init\n",
        "        if coordinates_list is not None:\n",
        "            self.coordinates = coordinates_list\n",
        "\n",
        "        # Check neuron number / number of coordinates\n",
        "        if (len(self.coordinates[0]) == neuron_num) and (len(self.coordinates[1]) == neuron_num) and (len(self.coordinates[2]) == neuron_num):\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError('Network / coordinate structure does not match the number of neurons.')\n",
        "\n",
        "        # Calculate the euclidean distance matrix\n",
        "        euclidean_vector = scipy.spatial.distance.pdist(np.transpose(self.coordinates), metric=distance_metric)\n",
        "        euclidean = scipy.spatial.distance.squareform(euclidean_vector ** self.distance_power)\n",
        "        self.distance_matrix = torch.tensor(euclidean, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, net):\n",
        "        eff_weight_matrix = net.rnn.h2h.weight * net.rnn.nsc_mask\n",
        "        abs_weight_matrix = torch.abs(eff_weight_matrix)\n",
        "        WD_loss = self.reg_WD * torch.sum(abs_weight_matrix * self.distance_matrix)\n",
        "        return WD_loss\n",
        "\n",
        "    def _check_penalty_number(self, x):\n",
        "        if not isinstance(x, (float, int)):\n",
        "            raise ValueError(('Value: {} is not a valid regularization penalty number, '\n",
        "                              'expected an int or float value').format(x))\n",
        "\n",
        "    def visualise_distance_matrix(self):\n",
        "        plt.imshow(self.distance_matrix.numpy())\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    def visualise_neuron_structure(self):\n",
        "        fig = plt.figure()\n",
        "        ax = Axes3D(fig)\n",
        "        ax.scatter(self.coordinates[0], self.coordinates[1], self.coordinates[2], c='b', marker='.')\n",
        "        ax.set_xlabel('x')\n",
        "        ax.set_ylabel('y')\n",
        "        ax.set_zlabel('z')\n",
        "        plt.show()\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'reg_WD': float(self.reg_WD)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2D Approach - SE_RNNNet (a Main Network)"
      ],
      "metadata": {
        "id": "Opd-aiUMe_wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCv2Tz1BxEZC"
      },
      "outputs": [],
      "source": [
        "class SE_RNNNet(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer. (ALSO UPDATED FOR Maintained State Version)\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, spatial_embedding_dim = 2 , **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.ndim = spatial_embedding_dim\n",
        "        self.spatial_embedding_arrangement = self.spatial_embedding() # Renamed to avoid conflict with method name\n",
        "        self.distance_matrix_computed = self.distance_matrix() # Renamed to avoid conflict with method name\n",
        "        # Leaky RNN\n",
        "        # self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "        self.rnn = LeakyRNN_NSC_MS(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "    def spatial_embedding(self):\n",
        "      len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "      print(len_dimensions)\n",
        "      spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "      _unit = 0\n",
        "      for i in range(len_dimensions):\n",
        "        for j in range(len_dimensions):\n",
        "          spatial_embedding_arrangement[i,j] = _unit\n",
        "          _unit += 1\n",
        "      return spatial_embedding_arrangement\n",
        "\n",
        "    def distance_matrix(self):\n",
        "\n",
        "      len_dimensions = int(self.hidden_size ** (1/self.ndim)) # Convert to integer\n",
        "      spatial_embedding_arrangement = np.zeros((len_dimensions, len_dimensions))\n",
        "      _unit = 0\n",
        "      for i in range(len_dimensions):\n",
        "        for j in range(len_dimensions):\n",
        "          spatial_embedding_arrangement[i,j] = _unit\n",
        "          _unit += 1\n",
        "\n",
        "      distance_matrix = np.zeros((self.hidden_size, self.hidden_size))\n",
        "      # distance matrix i_j = distance from i to j in the spatial embedding\n",
        "      for i in range(self.hidden_size):\n",
        "        [unit_i_location_x,unit_i_location_y] = np.where(spatial_embedding_arrangement == i)\n",
        "        unit_i_location = np.array([unit_i_location_x,unit_i_location_y])\n",
        "        for j in range(self.hidden_size):\n",
        "          [unit_j_location_x,unit_j_location_y] = np.where(spatial_embedding_arrangement == j)\n",
        "          unit_j_location = np.array([unit_j_location_x,unit_j_location_y])\n",
        "          distance_matrix[i,j] = np.linalg.norm(unit_i_location - unit_j_location)\n",
        "      return torch.from_numpy(distance_matrix.T).float() # For consistency as Pytorch .weights (for h2h linear) is arranged such that weight from i to j = W[j,i] #here are distance matrix is symmetric so doesnt matter but good for understanding\n",
        "\n",
        "    def penalise_weight_distance(self):\n",
        "      # Hidden Layer Weight Matrix\n",
        "      # Effective Weight Matrix\n",
        "      eff_weight_matrix = self.rnn.h2h.weight * self.rnn.nsc_mask\n",
        "      weight_matrix_penalty = torch.abs(eff_weight_matrix)\n",
        "      # Weight Distance elementwise product\n",
        "      # wd_penalty_raw =  weight_matrix_penalty * torch.square(self.distance_matrix_computed)\n",
        "      wd_penalty_raw =  weight_matrix_penalty * self.distance_matrix_computed # try L1\n",
        "      L2_penalty_term = torch.sum(wd_penalty_raw)\n",
        "      return L2_penalty_term\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E-I RNN"
      ],
      "metadata": {
        "id": "qQ8ROpFvfUdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Effective Weight Module"
      ],
      "metadata": {
        "id": "Ng4OLcsRfzfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liYep7yXTo7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class EIRecLinear(nn.Module):\n",
        "\n",
        "    \"\"\"Recurrent E-I Linear transformation.\n",
        "\n",
        "    This module implements a linear transformation with recurrent E-I dynamics,\n",
        "    where part of the units are excitatory and the rest are inhibitory.\n",
        "\n",
        "    Args:\n",
        "        hidden_size: int, the number of units in the layer.\n",
        "        e_prop: float between 0 and 1, the proportion of excitatory units.\n",
        "        bias: bool, if True, adds a learnable bias to the output.\n",
        "    \"\"\"\n",
        "\n",
        "    __constants__ = ['bias', 'hidden_size', 'e_prop']\n",
        "\n",
        "    def __init__(self, hidden_size, e_prop, bias=True):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.e_prop = e_prop\n",
        "        self.e_size = int(e_prop * hidden_size) # Number of excitatory units\n",
        "        self.i_size = hidden_size - self.e_size # Number of inhibitory units\n",
        "\n",
        "        # Weight matrix for the recurrent connections\n",
        "        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "        # Create a mask to define the E-I interactions\n",
        "        # The mask has ones for E to E/I and negative ones for I to E/I, except the diagonal\n",
        "\n",
        "        mask_no_diag = np.ones((self.hidden_size,self.hidden_size)) -  np.diag(np.ones((self.hidden_size)))\n",
        "\n",
        "        E_I_unit_list = np.concatenate((np.ones((self.e_size,1)),-1*np.ones((self.i_size,1)))).T\n",
        "\n",
        "        mask = mask_no_diag*E_I_unit_list\n",
        "        # self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32))\n",
        "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "        # Optionally add a bias term\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialise weights and biases\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        # Scale the weights for the excitatory neurons\n",
        "        self.weight.data[:, :self.e_size] /= (self.e_size/self.i_size)\n",
        "\n",
        "        # Initialise biases\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def effective_weight(self):\n",
        "        # Apply the mask you have already created to the weights after applying rectification to get the effective weight\n",
        "        # This ensures that weights from excitatory neurons are positive,\n",
        "        # and weights from inhibitory neurons are negative.\n",
        "        eff_W = F.relu(self.weight)*self.mask\n",
        "        return eff_W\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Apply the linear transformation using the effective weights and biases\n",
        "        # The weights used are non-negative due to the absolute value in effective_weight.\n",
        "        return F.linear(input, self.effective_weight(), self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - RNN Layer"
      ],
      "metadata": {
        "id": "1b-feEuUf6HU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIVaftSaHatf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EIRNN(nn.Module):\n",
        "    \"\"\"E-I RNN.\n",
        "\n",
        "    Reference:\n",
        "        Song, H.F., Yang, G.R. and Wang, X.J., 2016.\n",
        "        Training excitatory-inhibitory recurrent neural networks\n",
        "        for cognitive tasks: a simple and flexible framework.\n",
        "        PLoS computational biology, 12(2).\n",
        "\n",
        "    Args:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "\n",
        "    Inputs:\n",
        "        input: (seq_len, batch, input_size)\n",
        "        hidden: (batch, hidden_size)\n",
        "        e_prop: float between 0 and 1, proportion of excitatory neurons\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=None,\n",
        "                 e_prop=0.8, sigma_rec=0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.e_size = int(hidden_size * e_prop)\n",
        "        self.i_size = hidden_size - self.e_size\n",
        "        self.num_layers = 1\n",
        "        self.tau = 100\n",
        "        if dt is None:\n",
        "            alpha = 1\n",
        "        else:\n",
        "            alpha = dt / self.tau\n",
        "        self.alpha = alpha\n",
        "        self.oneminusalpha = 1 - alpha\n",
        "        # Recurrent noise parameter, scaled by the discretization (sqrt(2*alpha)) and noise level (sigma_rec)\n",
        "        # This adds stochasticity to the recurrent dynamics, possibly simulating biological neural variability\n",
        "        self._sigma_rec = np.sqrt(2*alpha) * sigma_rec\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = EIRecLinear(hidden_size, e_prop=0.8)\n",
        "\n",
        "    def init_hidden(self, input):\n",
        "        batch_size = input.shape[1]\n",
        "        return (torch.zeros(batch_size, self.hidden_size).to(input.device),\n",
        "                torch.zeros(batch_size, self.hidden_size).to(input.device))\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Recurrence helper.\"\"\"\n",
        "        state, output = hidden\n",
        "        total_input = self.input2h(input) + self.h2h(output)\n",
        "        state = state * self.oneminusalpha + total_input * self.alpha\n",
        "        state += self._sigma_rec * torch.randn_like(state)\n",
        "        output = torch.relu(state)\n",
        "        return state, output\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input)\n",
        "\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden[1])\n",
        "        output = torch.stack(output, dim=0)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "    def recurrence_helper_fpf(self, input, hidden_state_only):\n",
        "        \"\"\"Recurrence helper.\"\"\"\n",
        "        state, output = hidden_state_only, torch.relu(hidden_state_only)\n",
        "        total_input = self.input2h(input) + self.h2h(output)\n",
        "        state = state * self.oneminusalpha + total_input * self.alpha\n",
        "        state += self._sigma_rec * torch.randn_like(state)\n",
        "        return state\n",
        "\n",
        "    def forward_helper_fpf(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        return output, hidden_state_only\n",
        "    def forward_helper_fpf_ICs(self, input, hidden_state_only=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "        if hidden_state_only is None:\n",
        "            hidden_state_only = self.init_hidden(input)[0]\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        hidden_state_only_list = []\n",
        "        # hidden_state_only_list.append(hidden_state_only)\n",
        "        for i in steps:\n",
        "            hidden_state_only = self.recurrence_helper_fpf(input[i], hidden_state_only)\n",
        "            hidden_state_only_list.append(hidden_state_only)\n",
        "            hidden_output = torch.relu(hidden_state_only)\n",
        "            output.append(hidden_output)\n",
        "        output = torch.stack(output, dim=0)\n",
        "        hidden_state_only_tensor = torch.stack(hidden_state_only_list, dim=0)\n",
        "        return output, hidden_state_only_tensor # hidden_state_only_tensor is shaped (seq_len, batch_size, hidden_size) and contains the raw states, we want to track this in FPF testing to obtain ICs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EI - Main Network"
      ],
      "metadata": {
        "id": "AHau3cdef8VN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH6ZaJM_HZQV"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EINet(nn.Module):\n",
        "    \"\"\"Recurrent network model.\n",
        "\n",
        "    Args:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "        rnn: str, type of RNN, lstm, rnn, ctrnn, or eirnn\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        # Excitatory-inhibitory RNN\n",
        "        self.rnn = EIRNN(input_size, hidden_size, **kwargs)\n",
        "        self.fc = nn.Linear(self.rnn.e_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_activity, _ = self.rnn(x)\n",
        "        rnn_e = rnn_activity[:, :, :self.rnn.e_size]\n",
        "        out = self.fc(rnn_e)\n",
        "        return out, rnn_activity\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "        rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "        rnn_e = rnn_outputs[:, :, :self.rnn.e_size]\n",
        "        out = self.fc(rnn_e)\n",
        "        return out, rnn_outputs, hidden_state_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialising for BIC Networks"
      ],
      "metadata": {
        "id": "wfk6ZruZdaiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good for temp testing of diff functionality and using the current Standard Implementation to guide. If we implement three at a time, is that dumb or can we get the outputs in a way that informs the analysis / write up narrative"
      ],
      "metadata": {
        "id": "5ZeLjVe_df9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting From Pretrained / Training"
      ],
      "metadata": {
        "id": "-fNC_ly7d1zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Data Sets"
      ],
      "metadata": {
        "id": "YIKbFK6x1AUy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsChQgYM1B_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Setups\n",
        "\n",
        "### SHARED ACROSS TRAINING VALID TEST\n",
        "timestep = 50 #ms\n",
        "noise = 1.0\n",
        "batch_size = 64\n",
        "\n",
        "# Assign Timing for each task period (same as default but enables calculation of sequence length)\n",
        "timing_valid_s = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': 300,\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "timing_valid_m = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': 500,\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "timing_valid_l = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': 900,\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "\n",
        "timing_valid_ll = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': 1000,\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "\n",
        "timing_training = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': ('choice', (300, 400, 500, 600, 700, 800, 900)),\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "\n",
        "# Assign Time step size and calculate sequence length of a full trial\n",
        "# Short\n",
        "trial_time_s = sum(timing_valid_s.values()) #ms\n",
        "seq_len_valid_s = int(trial_time_s/timestep)\n",
        "# Medium\n",
        "trial_time_m = sum(timing_valid_m.values()) #ms\n",
        "seq_len_valid_m = int(trial_time_m/timestep)\n",
        "# Long\n",
        "trial_time_l = sum(timing_valid_l.values()) #ms\n",
        "seq_len_valid_l = int(trial_time_l/timestep)\n",
        "# X-Long\n",
        "trial_time_ll = sum(timing_valid_ll.values()) #ms\n",
        "seq_len_valid_ll = int(trial_time_ll/timestep)\n",
        "\n",
        "task_name = 'DelayMatchSample-v0'\n",
        "\n",
        "kwargs_valid_s = {'dt' : timestep, 'timing': timing_valid_s, 'sigma': noise}\n",
        "kwargs_valid_m = {'dt' : timestep, 'timing': timing_valid_m, 'sigma': noise}\n",
        "kwargs_valid_l = {'dt' : timestep, 'timing': timing_valid_l, 'sigma': noise}\n",
        "kwargs_valid_ll = {'dt' : timestep, 'timing': timing_valid_ll, 'sigma': noise}\n",
        "kwargs_training = {'dt' : timestep, 'timing': timing_training, 'sigma': noise}\n",
        "\n",
        "dataset_valid_s = ngym.Dataset(task_name, env_kwargs=kwargs_valid_s, batch_size=batch_size, seq_len=seq_len_valid_s)\n",
        "dataset_valid_m = ngym.Dataset(task_name, env_kwargs=kwargs_valid_m, batch_size=batch_size, seq_len=seq_len_valid_m)\n",
        "dataset_valid_l = ngym.Dataset(task_name, env_kwargs=kwargs_valid_l, batch_size=batch_size, seq_len=seq_len_valid_l)\n",
        "dataset_valid_ll = ngym.Dataset(task_name, env_kwargs=kwargs_valid_ll, batch_size=batch_size, seq_len=seq_len_valid_ll)\n",
        "dataset_training = ngym.Dataset(task_name, env_kwargs=kwargs_training, batch_size=batch_size, seq_len=124)\n",
        "\n",
        "validation_set_dictionary = {\n",
        "    'Short': dataset_valid_s,\n",
        "    'Medium': dataset_valid_m,\n",
        "    'Long': dataset_valid_l,\n",
        "    'UnseenLong' : dataset_valid_ll\n",
        "}"
      ],
      "metadata": {
        "id": "ISyydYsDdMwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-NSC from .pth / TRAINING"
      ],
      "metadata": {
        "id": "WnmK7O0pgNve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Parameters\n",
        "hidden_size_NSC = 64\n",
        "input_size_NSC = 3\n",
        "output_size_NSC = 3\n",
        "dt_NSC = 50\n",
        "tau_NSC = 100\n",
        "# Initialising base model\n",
        "LRNN_NSC = RNNNet_MS(input_size=input_size_NSC, hidden_size = hidden_size_NSC, output_size = output_size_NSC, dt=dt_NSC, tau=tau_NSC)\n",
        "# MODEL_IO_NSC = False\n",
        "\n",
        "if MODEL_IO_NSC:\n",
        "  LRNN_NSC_TRAINED = LRNN_NSC\n",
        "  # LRNN_NSC_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/NSC_LRNN_MODEL.pth'))\n",
        "  LRNN_NSC_TRAINED.load_state_dict(torch.load('LRNN_NSC/LRNN_NSC.pth'))\n",
        "  LRNN_NSC_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_NSC_TRAINED, LRNN_NSC_training_dict = training_with_early_stop_and_regularisation(\n",
        "    model=LRNN_NSC,\n",
        "    training_set= dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=100000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=1500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_NSC_best',\n",
        "    tr_output_mode= True)\n",
        "\n"
      ],
      "metadata": {
        "id": "9KnZin-NlhJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # plot_learning_curve(\n",
        "  #   learning_curve_dict=LRNN_NSC_training_dict,\n",
        "  #   average_only=False,\n",
        "  #   plot_loss_components=True,\n",
        "  #   filename='LRNN_NSC/Learning_Curve_NSC_all.png',\n",
        "  #   show_legend=True,\n",
        "  #   legend_location='center right')\n"
      ],
      "metadata": {
        "id": "44IitiI8_XQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-SE_2D from .pth"
      ],
      "metadata": {
        "id": "XTEL_S-3gTVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Parameters\n",
        "hidden_size_SE2D = 64\n",
        "input_size_SE2D = 3\n",
        "output_size_SE2D = 3\n",
        "dt_SE2D = 50\n",
        "tau_SE2D = 100\n",
        "# Initialising base model\n",
        "LRNN_SE2D = SE_RNNNet(input_size=input_size_SE2D, hidden_size = hidden_size_SE2D, output_size = output_size_SE2D, dt=dt_SE2D, tau=tau_SE2D)\n",
        "# MODEL_IO_SE2D = False\n",
        "\n",
        "if MODEL_IO_SE2D:\n",
        "  LRNN_SE2D_TRAINED = LRNN_SE2D\n",
        "  # LRNN_SE2D_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/2D_WIRING_MODEL.pth'))\n",
        "  LRNN_SE2D_TRAINED.load_state_dict(torch.load('LRNN_SE2D/LRNN_SE2D.pth'))\n",
        "  LRNN_SE2D_TRAINED.eval()\n",
        "\n",
        "else:\n",
        "  LRNN_SE2D_TRAINED, LRNN_SE2D_training_dict = training_with_early_stop_and_regularisation(\n",
        "    model=LRNN_SE2D,\n",
        "    training_set= dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.00001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=100000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=10,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_SE2D_best',\n",
        "    tr_output_mode= True)\n",
        "  plot_learning_curve(\n",
        "    learning_curve_dict=LRNN_SE2D_training_dict,\n",
        "    average_only=False,\n",
        "    plot_loss_components=True,\n",
        "    filename='LRNN_SE2D/Learning_Curve_SE2D_all.png',\n",
        "    show_legend=True,\n",
        "    legend_location='center right')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t7Ha6Kd-mtGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb5f7a8-dc86-4166-d974-4c77d3004dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-SE_3D from .pth"
      ],
      "metadata": {
        "id": "6veOoLRkgZ6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WD_regulariser = Reg_WD(reg_WD=0.0001, neuron_num=64, network_structure=(4,4,4))"
      ],
      "metadata": {
        "id": "F9_fk6y9_F1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialising Parameters\n",
        "hidden_size_SE3D = 64\n",
        "input_size_SE3D = 3\n",
        "output_size_SE3D = 3\n",
        "dt_SE3D = 50\n",
        "tau_SE3D = 100\n",
        "# Initialising base model\n",
        "LRNN_SE3D = RNNNet_MS(input_size=input_size_SE3D, hidden_size = hidden_size_SE3D, output_size = output_size_SE3D, dt=dt_SE3D, tau=tau_SE3D)\n",
        "# MODEL_IO_SE3D = False\n",
        "\n",
        "if MODEL_IO_SE3D:\n",
        "  LRNN_SE3D_TRAINED = LRNN_SE3D\n",
        "  LRNN_SE3D_TRAINED.load_state_dict(torch.load('LRNN_SE3D/LRNN_SE3D.pth'))\n",
        "  LRNN_SE3D_TRAINED.eval()\n",
        "else:\n",
        "  LRNN_SE3D_TRAINED, LRNN_SE3D_training_dict = training_with_early_stop_and_regularisation(\n",
        "    model=LRNN_SE3D,\n",
        "    training_set= dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=True,\n",
        "    WD_regulariser=WD_regulariser,\n",
        "    wiring_beta=0.0001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=1e-1,\n",
        "    max_steps=100000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=10,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_SE3D_best',\n",
        "    tr_output_mode= True)\n",
        "  plot_learning_curve(\n",
        "    learning_curve_dict=LRNN_SE3D_training_dict,\n",
        "    average_only=False,\n",
        "    plot_loss_components=True,\n",
        "    filename='LRNN_SE3D/Learning_Curve_SE3D_all.png',\n",
        "    show_legend=True,\n",
        "    legend_location= 'center right' )\n"
      ],
      "metadata": {
        "id": "0nXIjezcmvBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising EI-LRNN from .pth"
      ],
      "metadata": {
        "id": "D7DRXCPLgccC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Parameters\n",
        "hidden_size_EI = 64\n",
        "input_size_EI = 3\n",
        "output_size_EI = 3\n",
        "dt_EI = 50\n",
        "tau_EI = 100\n",
        "# Initialising base model # Does not take tau, maybe change this if want to use EI Layers in 2c\n",
        "LRNN_EI = EINet(input_size=input_size_EI, hidden_size = hidden_size_EI, output_size = output_size_EI, dt=dt_EI)\n",
        "# MODEL_IO_EI = False\n",
        "\n",
        "if MODEL_IO_EI:\n",
        "  LRNN_EI_TRAINED = LRNN_EI\n",
        "  LRNN_EI_TRAINED.load_state_dict(torch.load('LRNN_EI/LRNN_EI.pth'))\n",
        "  LRNN_EI_TRAINED.eval()\n",
        "\n",
        "else:\n",
        "  LRNN_EI_TRAINED, LRNN_EI_training_dict = training_with_early_stop_and_regularisation(\n",
        "    model=LRNN_EI,\n",
        "    training_set= dataset_training,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.001,\n",
        "    activity_regularisation=True,\n",
        "    activity_beta=5e-2,\n",
        "    max_steps=100000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=10,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_EI_best',\n",
        "    tr_output_mode= True)\n",
        "  plot_learning_curve(\n",
        "    learning_curve_dict=LRNN_EI_training_dict,\n",
        "    average_only=False,\n",
        "    plot_loss_components=True,\n",
        "    filename='LRNN_EI/Learning_Curve_EI_all.png',\n",
        "    show_legend=True,\n",
        "    legend_location= 'center right' )"
      ],
      "metadata": {
        "id": "jt1E9vEJmuKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Testing"
      ],
      "metadata": {
        "id": "oRZcQyaVrBdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising Testing Dataset"
      ],
      "metadata": {
        "id": "DBVY3jxsrEqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset for testing\n",
        "# Using Unseen 'delay' at 1100 : extrapolation on working memory time period\n",
        "timing_testing = {\n",
        "            'fixation': 300,\n",
        "            'sample': 500,\n",
        "            'delay': 1100,\n",
        "            'test': 500,\n",
        "            'decision': 900}\n",
        "\n",
        "timestep = 50\n",
        "noise = 0.0 # Consider setting to 0 (check with gem)\n",
        "batch_size = 64 # Consistent with Training (dont think it has that much of an effect)\n",
        "# Testing Trials\n",
        "trial_time_testing = sum(timing_testing.values()) #ms\n",
        "seq_len_testing = int(trial_time_testing/timestep)\n",
        "\n",
        "task_name = 'DelayMatchSample-v0'\n",
        "\n",
        "\n",
        "kwargs_testing = {'dt' : timestep, 'timing': timing_testing, 'sigma': noise}\n",
        "\n",
        "# kwargs_testing = {'dt' : timestep, 'timing': timing_testing, 'sigma': 0.0}\n",
        "\n",
        "dataset_testing = ngym.Dataset(task_name, env_kwargs=kwargs_testing, batch_size=batch_size, seq_len=seq_len_testing)"
      ],
      "metadata": {
        "id": "AVld-yNorEVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Testing for Each Network"
      ],
      "metadata": {
        "id": "nzdORMbDriBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for LRNN - NSC"
      ],
      "metadata": {
        "id": "3U-jRlj2roUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LRNN_NSC_full_testing_data = evaluate_network_on_dataset(LRNN_NSC_TRAINED, dataset_testing, num_trials=2000)\n",
        "LRNN_NSC_full_testing_data = bic_testing_w_state_tracking(LRNN_NSC_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "id": "3lzJIqyNrkdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc19e0b-ccec-4e42-bdea-660f8b4e0413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for LRNN - SE2D"
      ],
      "metadata": {
        "id": "XozPpPsZruiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LRNN_SE2D_full_testing_data = evaluate_network_on_dataset(LRNN_SE2D_TRAINED, dataset_testing, num_trials=2000)\n",
        "LRNN_SE2D_full_testing_data = bic_testing_w_state_tracking(LRNN_SE2D_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "id": "NP5Vazy4rxsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715ed560-ac36-493d-b127-c67320d98250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for LRNN - SE3D"
      ],
      "metadata": {
        "id": "HI4ly4R8ryD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LRNN_SE3D_full_testing_data = evaluate_network_on_dataset(LRNN_SE3D_TRAINED, dataset_testing, num_trials=2000)\n",
        "LRNN_SE3D_full_testing_data = bic_testing_w_state_tracking(LRNN_SE3D_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "id": "uyJfow8cr0ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7833ce2e-1372-4e4a-b3cd-f9bc3bed8453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for EI - LRNN"
      ],
      "metadata": {
        "id": "rcYOOJU7r01q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LRNN_EI_full_testing_data = evaluate_network_on_dataset(LRNN_EI_TRAINED, dataset_testing, num_trials=2000)\n",
        "LRNN_EI_full_testing_data = bic_testing_w_state_tracking(LRNN_EI_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "id": "G7sj0TYBr3LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757046bb-fa0c-437a-8897-eb2e1244b726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Data Partitioning for Each Network's Testing Data"
      ],
      "metadata": {
        "id": "fI92cs44xkRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - NSC"
      ],
      "metadata": {
        "id": "cDQALmGYxpfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "# trial_activity_matching\n",
        "cond_dict_matching = {\n",
        "    'test_equals_sample' : True\n",
        "}\n",
        "LRNN_NSC_testing_data_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, cond_dict_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_non_matching\n",
        "\n",
        "cond_dict_non_matching = {\n",
        "    'test_equals_sample' : False\n",
        "}\n",
        "LRNN_NSC_testing_data_non_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, cond_dict_non_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_sample\n",
        "cond_dict_0p0_sample = {\n",
        "    'sample_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NSC_testing_data_0p0_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_test\n",
        "cond_dict_0p0_test = {\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NSC_testing_data_0p0_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "\n",
        "# trial_activity_3p1_sample\n",
        "cond_dict_3p1_sample = {\n",
        "    'sample_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NSC_testing_data_3p1_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_3p1_test\n",
        "cond_dict_3p1_test = {\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NSC_testing_data_3p1_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_3p1\n",
        "cond_dict_0p0_3p1 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NSC_testing_data_0p0_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "#trial_activity_0p0_0p0\n",
        "cond_dict_0p0_0p0 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NSC_testing_data_0p0_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_0p0\n",
        "cond_dict_3p1_0p0 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NSC_testing_data_3p1_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_3p1\n",
        "cond_dict_3p1_3p1 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NSC_testing_data_3p1_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : np.pi}, return_like_full=True)"
      ],
      "metadata": {
        "id": "eIOm7xDI1j28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - SE2D"
      ],
      "metadata": {
        "id": "i2badTASyE5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "# trial_activity_matching\n",
        "\n",
        "cond_dict_matching = {\n",
        "    'test_equals_sample' : True\n",
        "}\n",
        "LRNN_SE2D_testing_data_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, cond_dict_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_non_matching\n",
        "\n",
        "cond_dict_non_matching = {\n",
        "    'test_equals_sample' : False\n",
        "}\n",
        "LRNN_SE2D_testing_data_non_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, cond_dict_non_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_sample\n",
        "cond_dict_0p0_sample = {\n",
        "    'sample_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE2D_testing_data_0p0_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_test\n",
        "cond_dict_0p0_test = {\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE2D_testing_data_0p0_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "\n",
        "# trial_activity_3p1_sample\n",
        "cond_dict_3p1_sample = {\n",
        "    'sample_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE2D_testing_data_3p1_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_3p1_test\n",
        "cond_dict_3p1_test = {\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE2D_testing_data_3p1_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_3p1\n",
        "cond_dict_0p0_3p1 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE2D_testing_data_0p0_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "#trial_activity_0p0_0p0\n",
        "cond_dict_0p0_0p0 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE2D_testing_data_0p0_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_0p0\n",
        "cond_dict_3p1_0p0 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE2D_testing_data_3p1_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_3p1\n",
        "cond_dict_3p1_3p1 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE2D_testing_data_3p1_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : np.pi}, return_like_full=True)"
      ],
      "metadata": {
        "id": "ZWEyrJeDyE5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAp_IMwKyGkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - SE3D"
      ],
      "metadata": {
        "id": "z60EhaDCyGxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "# # trial_activity_matching\n",
        "cond_dict_matching = {\n",
        "    'test_equals_sample' : True\n",
        "}\n",
        "\n",
        "LRNN_SE3D_testing_data_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, cond_dict_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_non_matching\n",
        "\n",
        "cond_dict_non_matching = {\n",
        "    'test_equals_sample' : False\n",
        "}\n",
        "LRNN_SE3D_testing_data_non_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, cond_dict_non_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_sample\n",
        "cond_dict_0p0_sample = {\n",
        "    'sample_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE3D_testing_data_0p0_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_test\n",
        "cond_dict_0p0_test = {\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE3D_testing_data_0p0_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "\n",
        "# trial_activity_3p1_sample\n",
        "cond_dict_3p1_sample = {\n",
        "    'sample_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE3D_testing_data_3p1_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_3p1_test\n",
        "cond_dict_3p1_test = {\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE3D_testing_data_3p1_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_3p1\n",
        "cond_dict_0p0_3p1 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE3D_testing_data_0p0_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "#trial_activity_0p0_0p0\n",
        "cond_dict_0p0_0p0 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE3D_testing_data_0p0_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_0p0\n",
        "cond_dict_3p1_0p0 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_SE3D_testing_data_3p1_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_3p1\n",
        "cond_dict_3p1_3p1 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_SE3D_testing_data_3p1_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : np.pi}, return_like_full=True)"
      ],
      "metadata": {
        "id": "nzojUl8zyGxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sV97Xe-_yHk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - E-I"
      ],
      "metadata": {
        "id": "t8gBoM0ayHtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "# trial_activity_matching\n",
        "cond_dict_matching = {\n",
        "    'test_equals_sample' : True\n",
        "}\n",
        "\n",
        "LRNN_EI_testing_data_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, cond_dict_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_non_matching\n",
        "\n",
        "cond_dict_non_matching = {\n",
        "    'test_equals_sample' : False\n",
        "}\n",
        "LRNN_EI_testing_data_non_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, cond_dict_non_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_sample\n",
        "cond_dict_0p0_sample = {\n",
        "    'sample_stim_value' : 0.0\n",
        "}\n",
        "LRNN_EI_testing_data_0p0_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_test\n",
        "cond_dict_0p0_test = {\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_EI_testing_data_0p0_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "\n",
        "# trial_activity_3p1_sample\n",
        "cond_dict_3p1_sample = {\n",
        "    'sample_stim_value' : np.pi\n",
        "}\n",
        "LRNN_EI_testing_data_3p1_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_3p1_test\n",
        "cond_dict_3p1_test = {\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_EI_testing_data_3p1_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_3p1\n",
        "cond_dict_0p0_3p1 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_EI_testing_data_0p0_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "#trial_activity_0p0_0p0\n",
        "cond_dict_0p0_0p0 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_EI_testing_data_0p0_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_0p0\n",
        "cond_dict_3p1_0p0 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_EI_testing_data_3p1_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_3p1\n",
        "cond_dict_3p1_3p1 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_EI_testing_data_3p1_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : np.pi}, return_like_full=True)"
      ],
      "metadata": {
        "id": "b3hxxzBcyHte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Unit Activity"
      ],
      "metadata": {
        "id": "-deNZfFHuEzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN NSC"
      ],
      "metadata": {
        "id": "U62YUUzpuHBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NSC - Single Trial Unit Activity"
      ],
      "metadata": {
        "id": "LUNow4c31PAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_NSC_one_trial_0p0_0p0 = LRNN_NSC_testing_data_0p0_0p0['testing_trial_and_activity'][list(LRNN_NSC_testing_data_0p0_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NSC_one_trial_0p0_3p1 = LRNN_NSC_testing_data_0p0_3p1['testing_trial_and_activity'][list(LRNN_NSC_testing_data_0p0_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NSC_one_trial_3p1_0p0 = LRNN_NSC_testing_data_3p1_0p0['testing_trial_and_activity'][list(LRNN_NSC_testing_data_3p1_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NSC_one_trial_3p1_3p1 = LRNN_NSC_testing_data_3p1_3p1['testing_trial_and_activity'][list(LRNN_NSC_testing_data_3p1_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NSC_one_trial_plot_env_info = LRNN_NSC_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "msU4bhye7Y-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0p0_0p0\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_0p0_0p0, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NSC/1trial_0p0_0p0_LRNN_NSC.png') # plot all units, no legend for now\n",
        "#0p0_3p1\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_0p0_3p1, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NSC/1trial_0p0_3p1_LRNN_NSC.png') # plot all units, no legend for now\n",
        "# 3p1_0p0\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_3p1_0p0, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NSC/1trial_3p1_0p0_LRNN_NSC.png')\n",
        "#3p1_3p1\n",
        "plot_unit_activity_over_time(LRNN_NSC_one_trial_3p1_3p1, LRNN_NSC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NSC/1trial_3p1_3p1_LRNN_NSC.png')\n"
      ],
      "metadata": {
        "id": "FZ5Ggj6H7Uyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c9273b-d6b3-48f3-9fc6-7388d5164e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/1trial_0p0_0p0_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/1trial_0p0_3p1_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/1trial_3p1_0p0_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/1trial_3p1_3p1_LRNN_NSC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NSC - Average Unit Activity Plot"
      ],
      "metadata": {
        "id": "Er2j5bAC1Smd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_NSC_all_trial_0p0_0p0 = LRNN_NSC_testing_data_0p0_0p0['testing_trial_and_activity']\n",
        "LRNN_NSC_all_trial_0p0_3p1 = LRNN_NSC_testing_data_0p0_3p1['testing_trial_and_activity']\n",
        "LRNN_NSC_all_trial_3p1_0p0 = LRNN_NSC_testing_data_3p1_0p0['testing_trial_and_activity']\n",
        "LRNN_NSC_all_trial_3p1_3p1 = LRNN_NSC_testing_data_3p1_3p1['testing_trial_and_activity']\n",
        "LRNN_NSC_all_trial_plot_env_info = LRNN_NSC_testing_data_0p0_0p0['testing_env_info'] # Same for each\n"
      ],
      "metadata": {
        "id": "1RdCK8oi7b6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#0p0_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_0p0_0p0, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NSC/avg_0p0_0p0_LRNN_NSC.png')\n",
        "\n",
        "#0p0_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_0p0_3p1, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NSC/avg_0p0_3p1_LRNN_NSC.png')\n",
        "\n",
        "#3p1_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_3p1_0p0, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NSC/avg_3p1_0p0_LRNN_NSC.png')\n",
        "\n",
        "#3p1_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_NSC_all_trial_3p1_3p1, LRNN_NSC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NSC/avg_3p1_3p1_LRNN_NSC.png')\n"
      ],
      "metadata": {
        "id": "daTuDYVb7d1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c270e084-1b63-47c0-b7d8-0794da3e9b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/avg_0p0_0p0_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/avg_0p0_3p1_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/avg_3p1_0p0_LRNN_NSC.png\n",
            "Figure saved to LRNN_NSC/avg_3p1_3p1_LRNN_NSC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN SE2D"
      ],
      "metadata": {
        "id": "8u8WYL0fuKvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN SE 2D - Single Trial Unit"
      ],
      "metadata": {
        "id": "idxMl2Nq4pLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_SE2D_one_trial_0p0_0p0 = LRNN_SE2D_testing_data_0p0_0p0['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_0p0_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE2D_one_trial_0p0_3p1 = LRNN_SE2D_testing_data_0p0_3p1['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_0p0_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE2D_one_trial_3p1_0p0 = LRNN_SE2D_testing_data_3p1_0p0['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_3p1_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE2D_one_trial_3p1_3p1 = LRNN_SE2D_testing_data_3p1_3p1['testing_trial_and_activity'][list(LRNN_SE2D_testing_data_3p1_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE2D_one_trial_plot_env_info = LRNN_SE2D_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "MnOOY9Bf8Kn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0p0_0p0\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_0p0_0p0, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE2D/1trial_0p0_0p0_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "#0p0_3p1\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_0p0_3p1, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE2D/1trial_0p0_3p1_LRNN_SE2D.png') # plot all units, no legend for now\n",
        "# 3p1_0p0\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_3p1_0p0, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE2D/1trial_3p1_0p0_LRNN_SE2D.png')\n",
        "#3p1_3p1\n",
        "plot_unit_activity_over_time(LRNN_SE2D_one_trial_3p1_3p1, LRNN_SE2D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE2D/1trial_3p1_3p1_LRNN_SE2D.png')"
      ],
      "metadata": {
        "id": "h_kvTbrtAL8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30342bf-8da1-402c-a877-0f4b5e67bd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/1trial_0p0_0p0_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/1trial_0p0_3p1_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/1trial_3p1_0p0_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/1trial_3p1_3p1_LRNN_SE2D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN SE 2D - Average Unit Activity Plot"
      ],
      "metadata": {
        "id": "5SCQnc0dzrl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE2D_all_trial_0p0_0p0 = LRNN_SE2D_testing_data_0p0_0p0['testing_trial_and_activity']\n",
        "LRNN_SE2D_all_trial_0p0_3p1 = LRNN_SE2D_testing_data_0p0_3p1['testing_trial_and_activity']\n",
        "LRNN_SE2D_all_trial_3p1_0p0 = LRNN_SE2D_testing_data_3p1_0p0['testing_trial_and_activity']\n",
        "LRNN_SE2D_all_trial_3p1_3p1 = LRNN_SE2D_testing_data_3p1_3p1['testing_trial_and_activity']\n",
        "LRNN_SE2D_all_trial_plot_env_info = LRNN_SE2D_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "4yjM02hQ-_iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0p0_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_0p0_0p0, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE2D/avg_0p0_0p0_LRNN_SE2D.png')\n",
        "\n",
        "#0p0_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_0p0_3p1, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE2D/avg_0p0_3p1_LRNN_SE2D.png')\n",
        "\n",
        "#3p1_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_3p1_0p0, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE2D/avg_3p1_0p0_LRNN_SE2D.png')\n",
        "\n",
        "#3p1_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_SE2D_all_trial_3p1_3p1, LRNN_SE2D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE2D/avg_3p1_3p1_LRNN_SE2D.png')"
      ],
      "metadata": {
        "id": "ojFzUek-_o9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbda1d5-6749-4707-c655-e4b222e8be98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/avg_0p0_0p0_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/avg_0p0_3p1_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/avg_3p1_0p0_LRNN_SE2D.png\n",
            "Figure saved to LRNN_SE2D/avg_3p1_3p1_LRNN_SE2D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN SE 3D"
      ],
      "metadata": {
        "id": "jFByJIvRuMJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN SE 3D - Single Trial Unit"
      ],
      "metadata": {
        "id": "s7m4K9sv1vhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_SE3D_one_trial_0p0_0p0 = LRNN_SE3D_testing_data_0p0_0p0['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_0p0_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE3D_one_trial_0p0_3p1 = LRNN_SE3D_testing_data_0p0_3p1['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_0p0_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE3D_one_trial_3p1_0p0 = LRNN_SE3D_testing_data_3p1_0p0['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_3p1_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE3D_one_trial_3p1_3p1 = LRNN_SE3D_testing_data_3p1_3p1['testing_trial_and_activity'][list(LRNN_SE3D_testing_data_3p1_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_SE3D_one_trial_plot_env_info = LRNN_SE3D_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "ICW6t4FouNUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0p0_0p0\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_0p0_0p0, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE3D/1trial_0p0_0p0_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "#0p0_3p1\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_0p0_3p1, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE3D/1trial_0p0_3p1_LRNN_SE3D.png') # plot all units, no legend for now\n",
        "# 3p1_0p0\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_3p1_0p0, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE3D/1trial_3p1_0p0_LRNN_SE3D.png')\n",
        "#3p1_3p1\n",
        "plot_unit_activity_over_time(LRNN_SE3D_one_trial_3p1_3p1, LRNN_SE3D_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_SE3D/1trial_3p1_3p1_LRNN_SE3D.png')\n"
      ],
      "metadata": {
        "id": "J6VXrBLe12eB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d40189f-de46-4532-f1a7-a6d6c1b19f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/1trial_0p0_0p0_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/1trial_0p0_3p1_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/1trial_3p1_0p0_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/1trial_3p1_3p1_LRNN_SE3D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN SE 3D - Average Unit Activity"
      ],
      "metadata": {
        "id": "c7avsiLt1yXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE3D_all_trial_0p0_0p0 = LRNN_SE3D_testing_data_0p0_0p0['testing_trial_and_activity']\n",
        "LRNN_SE3D_all_trial_0p0_3p1 = LRNN_SE3D_testing_data_0p0_3p1['testing_trial_and_activity']\n",
        "LRNN_SE3D_all_trial_3p1_0p0 = LRNN_SE3D_testing_data_3p1_0p0['testing_trial_and_activity']\n",
        "LRNN_SE3D_all_trial_3p1_3p1 = LRNN_SE3D_testing_data_3p1_3p1['testing_trial_and_activity']\n",
        "LRNN_SE3D_all_trial_plot_env_info = LRNN_SE3D_testing_data_0p0_0p0['testing_env_info'] # Same for each"
      ],
      "metadata": {
        "id": "SwyJRVYK1-WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0p0_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_0p0_0p0, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE3D/avg_0p0_0p0_LRNN_SE3D.png')\n",
        "\n",
        "#0p0_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_0p0_3p1, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE3D/avg_0p0_3p1_LRNN_SE3D.png')\n",
        "\n",
        "#3p1_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_3p1_0p0, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE3D/avg_3p1_0p0_LRNN_SE3D.png')\n",
        "\n",
        "#3p1_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_SE3D_all_trial_3p1_3p1, LRNN_SE3D_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_SE3D/avg_3p1_3p1_LRNN_SE3D.png')\n"
      ],
      "metadata": {
        "id": "bHvgR8m02CDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3515f5e-6413-48e4-ae31-d3c4fe647c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/avg_0p0_0p0_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/avg_0p0_3p1_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/avg_3p1_0p0_LRNN_SE3D.png\n",
            "Figure saved to LRNN_SE3D/avg_3p1_3p1_LRNN_SE3D.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN EI Net"
      ],
      "metadata": {
        "id": "2Z532d7kuN4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Function for E-I Population Distinction"
      ],
      "metadata": {
        "id": "2rBHUgJAuPHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ei_unit_activity_trial(trial_activity, env_info, e_size, unit_indices_to_plot=None, filename=None):\n",
        "    \"\"\"\n",
        "    Takes a single trial's data and plots the activity of E/I units over time.\n",
        "\n",
        "    Args:\n",
        "        trial_activity : (shape: seq_len x hidden_size).\n",
        "        env_info (dict): Environmental information including 'dt' and 'timing'.\n",
        "        e_size (int): The number of excitatory units. Assumes E units are first.\n",
        "        unit_indices_to_plot (list, optional): Specific unit indices to plot.\n",
        "                                            If None, all units are plotted. Defaults to None.\n",
        "        filename (str, optional): File path to save the figure. If None,\n",
        "                                  the plot is displayed directly. Defaults to None.\n",
        "    \"\"\"\n",
        "\n",
        "    seq_len, hidden_size = trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Create time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # Define E and I indices\n",
        "    e_indices = set(range(e_size))\n",
        "    i_indices = set(range(e_size, hidden_size))\n",
        "\n",
        "    # Determine which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = [i for i in unit_indices_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "    # Plot unit activities with E/I colour coding and labeling\n",
        "    e_plotted = False\n",
        "    i_plotted = False\n",
        "    for i in units_to_plot:\n",
        "        if i in e_indices:\n",
        "            label = 'Excitatory' if not e_plotted else ''\n",
        "            ax.plot(time_points, trial_activity[:, i], color='blue', alpha=0.7, label=label)\n",
        "            e_plotted = True\n",
        "        elif i in i_indices:\n",
        "            label = 'Inhibitory' if not i_plotted else ''\n",
        "            ax.plot(time_points, trial_activity[:, i], color='red', alpha=0.7, label=label)\n",
        "            i_plotted = True\n",
        "\n",
        "    # Add vertical lines for task phases\n",
        "    current_time = 0\n",
        "    phase_boundaries = [0]\n",
        "    for duration in timing.values():\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            if current_time <= (time_points[-1]+dt):\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', alpha=0.5)\n",
        "                phase_boundaries.append(current_time)\n",
        "\n",
        "    # Add phase labels inside the plot after all data is plotted\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    text_y_position = ymax - (ymax - ymin) * 0.05  # Position text near the top\n",
        "\n",
        "    phase_keys = list(timing.keys())\n",
        "    for i in range(len(phase_boundaries) - 1):\n",
        "        start_time = phase_boundaries[i]\n",
        "        end_time = phase_boundaries[i+1]\n",
        "        mid_point = start_time + (end_time - start_time) / 2\n",
        "        ax.text(mid_point, text_y_position, phase_keys[i], ha='center', va='top', fontsize=12, style='italic')\n",
        "\n",
        "    ax.set_title('E/I Network Unit Activity Over Time (Single Trial)')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Activity')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename):\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_ei_average_unit_activity(trial_data_dict, env_info, e_size, unit_indices_to_plot=None, filename=None):\n",
        "    \"\"\"\n",
        "    Calculates and plots the average activity of E/I network units over time\n",
        "    across multiple trials.\n",
        "\n",
        "    Args:\n",
        "        trial_data_dict (dict): A dictionary of multiple trials.\n",
        "        env_info (dict): Environmental information including 'dt' and 'timing'.\n",
        "        e_size (int): The number of excitatory units. Assumes E units are first.\n",
        "        unit_indices_to_plot (list, optional): Specific unit indices to plot.\n",
        "                                            If None, all units are plotted. Defaults to None.\n",
        "        filename (str, optional): File path to save the figure. If None,\n",
        "                                  the plot is displayed directly. Defaults to None.\n",
        "    \"\"\"\n",
        "    if not trial_data_dict:\n",
        "        print(\"No trial data provided for plotting.\")\n",
        "        return\n",
        "\n",
        "    first_trial_key = list(trial_data_dict.keys())[0]\n",
        "    first_trial_activity = trial_data_dict[first_trial_key]['network_activity']\n",
        "    seq_len, hidden_size = first_trial_activity.shape\n",
        "    dt = env_info['dt']\n",
        "    timing = env_info['timing']\n",
        "\n",
        "    # Stack all activity arrays for averaging\n",
        "    all_activities = [t['network_activity'] for t in trial_data_dict.values() if t['network_activity'].shape == (seq_len, hidden_size)]\n",
        "    if not all_activities:\n",
        "        print(\"No valid trial data found for averaging.\")\n",
        "        return\n",
        "\n",
        "    average_activity = np.mean(np.stack(all_activities, axis=0), axis=0)\n",
        "\n",
        "    # Create time axis\n",
        "    time_points = np.arange(seq_len) * dt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "    # Define E and I indices\n",
        "    e_indices = set(range(e_size))\n",
        "    i_indices = set(range(e_size, hidden_size))\n",
        "\n",
        "    # Determine which units to plot\n",
        "    units_to_plot = range(hidden_size)\n",
        "    if unit_indices_to_plot is not None:\n",
        "        units_to_plot = [i for i in unit_indices_to_plot if 0 <= i < hidden_size]\n",
        "\n",
        "    # Plot average unit activities with E/I colour-coding and labeling\n",
        "    e_plotted = False\n",
        "    i_plotted = False\n",
        "    for i in units_to_plot:\n",
        "        if i in e_indices:\n",
        "            label = 'Excitatory' if not e_plotted else ''\n",
        "            ax.plot(time_points, average_activity[:, i], color='blue', alpha=0.7, label=label)\n",
        "            e_plotted = True\n",
        "        elif i in i_indices:\n",
        "            label = 'Inhibitory' if not i_plotted else ''\n",
        "            ax.plot(time_points, average_activity[:, i], color='red', alpha=0.7, label=label)\n",
        "            i_plotted = True\n",
        "\n",
        "    # Add vertical lines for task phases\n",
        "    current_time = 0\n",
        "    phase_boundaries = [0]\n",
        "    for duration in timing.values():\n",
        "        if isinstance(duration, (int, float)):\n",
        "            current_time += duration\n",
        "            if current_time <= (time_points[-1]+dt):\n",
        "                ax.axvline(x=current_time, color='k', linestyle='--', alpha=0.5)\n",
        "                phase_boundaries.append(current_time)\n",
        "\n",
        "    # Add phase labels inside the plot\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    text_y_position = ymax - (ymax - ymin) * 0.05\n",
        "\n",
        "    phase_keys = list(timing.keys())\n",
        "    for i in range(len(phase_boundaries) - 1):\n",
        "        start_time = phase_boundaries[i]\n",
        "        end_time = phase_boundaries[i+1]\n",
        "        mid_point = start_time + (end_time - start_time) / 2\n",
        "        ax.text(mid_point, text_y_position, phase_keys[i], ha='center', va='top', fontsize=12, style='italic')\n",
        "\n",
        "    ax.set_title('Average E/I Network Unit Activity Across Trials')\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Average Activity')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    if filename:\n",
        "        try:\n",
        "            if os.path.dirname(filename):\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Figure saved to {filename}\")\n",
        "            plt.close(fig)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving figure to {filename}: {e}\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "GnJ9m5cf0_Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_EI_E_SIZE = LRNN_EI_TRAINED.rnn.e_size\n",
        "print(LRNN_EI_E_SIZE)"
      ],
      "metadata": {
        "id": "JA8kifvU2sIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85162896-51e6-4e33-d6e5-1726a538d09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN EI - Single Unit Activity"
      ],
      "metadata": {
        "id": "3zgJPxLy2O2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_EI_one_trial_0p0_0p0 = LRNN_EI_testing_data_0p0_0p0['testing_trial_and_activity'][list(LRNN_EI_testing_data_0p0_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_EI_one_trial_0p0_3p1 = LRNN_EI_testing_data_0p0_3p1['testing_trial_and_activity'][list(LRNN_EI_testing_data_0p0_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_EI_one_trial_3p1_0p0 = LRNN_EI_testing_data_3p1_0p0['testing_trial_and_activity'][list(LRNN_EI_testing_data_3p1_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_EI_one_trial_3p1_3p1 = LRNN_EI_testing_data_3p1_3p1['testing_trial_and_activity'][list(LRNN_EI_testing_data_3p1_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_EI_one_trial_plot_env_info = LRNN_EI_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "2EnFu6ik2RBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing the new func:\n",
        "# plot_ei_unit_activity_trial(LRNN_EI_one_trial_0p0_0p0, env_info=LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename=None)"
      ],
      "metadata": {
        "id": "9S3eKSIr3CYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0p0_0p0\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_0p0_0p0, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/1trial_0p0_0p0_LRNN_EI.png') # plot all units, no legend for now\n",
        "#0p0_3p1\n",
        "\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_0p0_3p1, LRNN_EI_one_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/1trial_0p0_3p1_LRNN_EI.png') # plot all units, no legend for now\n",
        "# 3p1_0p0\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_3p1_0p0, LRNN_EI_one_trial_plot_env_info,e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None,  filename='LRNN_EI/1trial_3p1_0p0_LRNN_EI.png')\n",
        "#3p1_3p1\n",
        "plot_ei_unit_activity_trial(LRNN_EI_one_trial_3p1_3p1, LRNN_EI_one_trial_plot_env_info,e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None,  filename='LRNN_EI/1trial_3p1_3p1_LRNN_EI.png')\n"
      ],
      "metadata": {
        "id": "eCJdkwlJ2fEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88558c42-2dc3-4674-afed-365133ffe0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/1trial_0p0_0p0_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/1trial_0p0_3p1_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/1trial_3p1_0p0_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/1trial_3p1_3p1_LRNN_EI.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN EI - Average Unit Activity"
      ],
      "metadata": {
        "id": "r_0pbac62RjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_EI_all_trial_0p0_0p0 = LRNN_EI_testing_data_0p0_0p0['testing_trial_and_activity']\n",
        "LRNN_EI_all_trial_0p0_3p1 = LRNN_EI_testing_data_0p0_3p1['testing_trial_and_activity']\n",
        "LRNN_EI_all_trial_3p1_0p0 = LRNN_EI_testing_data_3p1_0p0['testing_trial_and_activity']\n",
        "LRNN_EI_all_trial_3p1_3p1 = LRNN_EI_testing_data_3p1_3p1['testing_trial_and_activity']\n",
        "LRNN_EI_all_trial_plot_env_info = LRNN_EI_testing_data_0p0_0p0['testing_env_info'] # Same for each\n"
      ],
      "metadata": {
        "id": "2SW5bYn-2TMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#0p0_0p0\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_0p0_0p0, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/avg_0p0_0p0_LRNN_EI.png')\n",
        "# plot_ei_average_unit_activity(LRNN_EI_all_trial_0p0_0p0, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None)\n",
        "\n",
        "#0p0_3p1\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_0p0_3p1, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/avg_0p0_3p1_LRNN_EI.png')\n",
        "\n",
        "#3p1_0p0\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_3p1_0p0, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/avg_3p1_0p0_LRNN_EI.png')\n",
        "\n",
        "#3p1_3p1\n",
        "plot_ei_average_unit_activity(LRNN_EI_all_trial_3p1_3p1, LRNN_EI_all_trial_plot_env_info, e_size=LRNN_EI_E_SIZE, unit_indices_to_plot=None, filename='LRNN_EI/avg_3p1_3p1_LRNN_EI.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "xgoXXUU22g-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77002f85-41ed-495a-a101-99506fef6e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/avg_0p0_0p0_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/avg_0p0_3p1_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/avg_3p1_0p0_LRNN_EI.png\n",
            "Figure saved to LRNN_EI/avg_3p1_3p1_LRNN_EI.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x82wL9Vj5_Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Re-) Plotting Network Structure"
      ],
      "metadata": {
        "id": "JV37O0mq8B7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot LRNN NSC"
      ],
      "metadata": {
        "id": "yc8k7gV38G0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_recurrent_weights_heatmap_BIC(net, filename = None, mask=None, weights_passed=False)\n",
        "plot_recurrent_weights_heatmap_BIC(LRNN_NSC_TRAINED, mask=LRNN_NSC_TRAINED.rnn.nsc_mask, filename='LRNN_NSC/LRNN_NSC_Connectivity.png')"
      ],
      "metadata": {
        "id": "311ufb_58FrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c35192-7007-4ffd-c479-82a777be02d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot  LRNN SE 2D"
      ],
      "metadata": {
        "id": "N5rAmdob8jga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_SE2D_TRAINED, mask=LRNN_SE2D_TRAINED.rnn.nsc_mask, filename='LRNN_SE2D/LRNN_SE2D_Connectivity.png')"
      ],
      "metadata": {
        "id": "il2ALH-U8ZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ec0af2-3bcc-4a2f-f575-6ee44299ac04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot  LRNN SE 3D"
      ],
      "metadata": {
        "id": "yDTU0UeT8wQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_SE3D_TRAINED, mask=LRNN_SE3D_TRAINED.rnn.nsc_mask, filename='LRNN_SE3D/LRNN_SE3D_Connectivity.png')"
      ],
      "metadata": {
        "id": "2NBOpFX98x5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e088dd1e-b46d-4133-be6d-6a710a62e772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot  LRNN EI"
      ],
      "metadata": {
        "id": "mx_MMuVa83PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_EI_TRAINED.rnn.h2h.effective_weight().detach().numpy(),weights_passed=True, filename='LRNN_EI/LRNN_EI_Connectivity.png')"
      ],
      "metadata": {
        "id": "M7-2VdBT84bR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da73dc1-8031-42a7-bc58-cf9f0d213cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/LRNN_EI_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dwjtcMFP9IKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (EXPORTING DATA)"
      ],
      "metadata": {
        "id": "IRTjjEEd_b_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-NSC"
      ],
      "metadata": {
        "id": "CcXT-CFu_iUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_nested_dict_to_json(LRNN_NSC_full_testing_data, filename= 'LRNN_NSC/LRNN_NSC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "id": "HSapbiXnCC1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b4ea9f-de36-4a91-d410-67534bc101bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to LRNN_NSC/LRNN_NSC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_testing_structure = import_nested_dict_from_json(filename = 'LRNN_NSC/LRNN_NSC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "id": "fghlS7pICbKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff422368-fd64-461e-e31c-b4d2ef4577b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully imported from LRNN_NSC/LRNN_NSC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_from_io = compare_dicts(LRNN_NSC_full_testing_data, temp_testing_structure)"
      ],
      "metadata": {
        "id": "c0cJ8pszCjNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72825d0b-4710-4dcf-a634-f599f6206a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-SE2D"
      ],
      "metadata": {
        "id": "ioSrj2gn_lSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "export_nested_dict_to_json(LRNN_SE2D_full_testing_data, filename= 'LRNN_SE2D/LRNN_SE2D_testing_data_for_dPCA.json')\n",
        "\n",
        "temp_testing_structure = import_nested_dict_from_json(filename = 'LRNN_SE2D/LRNN_SE2D_testing_data_for_dPCA.json')\n",
        "\n",
        "diff_from_io = compare_dicts(LRNN_SE2D_full_testing_data, temp_testing_structure)"
      ],
      "metadata": {
        "id": "dL81dU7V_m_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d567052-8e88-475a-f037-11065d91054a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to LRNN_SE2D/LRNN_SE2D_testing_data_for_dPCA.json\n",
            "Data successfully imported from LRNN_SE2D/LRNN_SE2D_testing_data_for_dPCA.json\n",
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-SE3D"
      ],
      "metadata": {
        "id": "rT0fKpQi_mlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_nested_dict_to_json(LRNN_SE3D_full_testing_data, filename= 'LRNN_SE3D/LRNN_SE3D_testing_data_for_dPCA.json')\n",
        "\n",
        "temp_testing_structure = import_nested_dict_from_json(filename = 'LRNN_SE3D/LRNN_SE3D_testing_data_for_dPCA.json')\n",
        "\n",
        "diff_from_io = compare_dicts(LRNN_SE3D_full_testing_data, temp_testing_structure)\n"
      ],
      "metadata": {
        "id": "-ZZJLcgZ_oHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf7403c-0a21-4dab-88da-17021be37ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to LRNN_SE3D/LRNN_SE3D_testing_data_for_dPCA.json\n",
            "Data successfully imported from LRNN_SE3D/LRNN_SE3D_testing_data_for_dPCA.json\n",
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-EI"
      ],
      "metadata": {
        "id": "RYSZ0vey_odj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "export_nested_dict_to_json(LRNN_EI_full_testing_data, filename= 'LRNN_EI/LRNN_EI_testing_data_for_dPCA.json')\n",
        "\n",
        "temp_testing_structure = import_nested_dict_from_json(filename = 'LRNN_EI/LRNN_EI_testing_data_for_dPCA.json')\n",
        "\n",
        "diff_from_io = compare_dicts(LRNN_EI_full_testing_data, temp_testing_structure)\n"
      ],
      "metadata": {
        "id": "Xc66nVQ2_qNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f83fd79-55d6-4244-81d2-2d93d48d3f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to LRNN_EI/LRNN_EI_testing_data_for_dPCA.json\n",
            "Data successfully imported from LRNN_EI/LRNN_EI_testing_data_for_dPCA.json\n",
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rY5faDN1AXUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (Importing Plots and Displaying)"
      ],
      "metadata": {
        "id": "rpQFadwbDr3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-NSC"
      ],
      "metadata": {
        "id": "4mI6cbxiD4vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Define the directory containing the images\n",
        "image_directory = 'LRNN_NSC/LRNN_NSC_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "id": "RwvpmXiuDuug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1371f75-bf2a-44b7-bf47-a8f2b1e575b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'LRNN_NSC/LRNN_NSC_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-SE2D"
      ],
      "metadata": {
        "id": "TYW3x6FnESmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the images\n",
        "image_directory = 'LRNN_SE2D/LRNN_SE2D_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "id": "D7VgDMzEESme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5453ec-21c8-42e3-8217-7e8396651592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'LRNN_SE2D/LRNN_SE2D_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-SE3d"
      ],
      "metadata": {
        "id": "8sYhgn5lETvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the images\n",
        "image_directory = 'LRNN_SE3D/LRNN_SE3D_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "id": "6i5AtNSyETvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01d1d20-9904-4433-aa50-bde5aa267fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'LRNN_SE3D/LRNN_SE3D_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-EI\n"
      ],
      "metadata": {
        "id": "n1HkGV5xEUVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the images\n",
        "image_directory = 'LRNN_EI/LRNN_EI_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "id": "V24vKtVqEUVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e926c37-d21c-4417-8e1b-fea5afcc4923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'LRNN_EI/LRNN_EI_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA (All Networks)"
      ],
      "metadata": {
        "id": "sHf51SslE_WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN NSC"
      ],
      "metadata": {
        "id": "K0pdtrLcL9fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN NSC"
      ],
      "metadata": {
        "id": "jesMZCwFL9fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample period data for all conds:\n",
        "LRNN_NSC_sample_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='sample')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_NSC_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# test period data for all conds:\n",
        "LRNN_NSC_test_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='test')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_NSC_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n"
      ],
      "metadata": {
        "id": "E1JhcojbL9fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_NSC_one_d_sample_pca = fit_pca_on_selected_data(LRNN_NSC_sample_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_NSC_two_d_sample_pca = fit_pca_on_selected_data(LRNN_NSC_sample_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_NSC_one_d_delay_pca = fit_pca_on_selected_data(LRNN_NSC_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_NSC_two_d_delay_pca = fit_pca_on_selected_data(LRNN_NSC_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the test period (1d)\n",
        "LRNN_NSC_one_d_test_pca = fit_pca_on_selected_data(LRNN_NSC_test_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the test period (2d)\n",
        "LRNN_NSC_two_d_test_pca = fit_pca_on_selected_data(LRNN_NSC_test_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_NSC_one_d_decision_pca = fit_pca_on_selected_data(LRNN_NSC_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_NSC_two_d_decision_pca = fit_pca_on_selected_data(LRNN_NSC_decision_period_trials_dict, pca_components=2, report_var_expls = False)"
      ],
      "metadata": {
        "id": "fHsaQsUqL9fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN NSC"
      ],
      "metadata": {
        "id": "qhIOwK3-L9fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN NSC Plot"
      ],
      "metadata": {
        "id": "B-Jmv3SxL9fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_sample_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_sample_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "7tYKYmEAL9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f97bd0-512a-42ba-f4ea-7938a2c887ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_sample_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_delay_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_delay_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "cD6mwnJXL9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5d65da-287b-415a-ffda-07b62afe5524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_delay_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_test_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_test_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "O3oF2DcLL9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822a84c4-77a2-4442-dc06-d481ecf97631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_test_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_decision_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_decision_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "id": "5obZZd_6L9fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9a9ad0-78e7-4ac7-e34b-a979129b371e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN NSC Plot"
      ],
      "metadata": {
        "id": "hCx-bizAL9f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_sample_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_sample_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "zkcy5mBRL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da941f5d-2c1a-4f7e-de4e-7cf7dd56b47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_sample_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_delay_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "CBVsM-lkL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9980755-02dc-4ed8-96cb-8425d8211034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_delay_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_test_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_test_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "69Isu4gKL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5beab8c-6136-4551-d2da-e145da5b33c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_test_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_decision_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "cagekq1JL9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb55e1c-f0d4-48d3-82ba-eb469296a1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add All Period PCA"
      ],
      "metadata": {
        "id": "JqyZ4i1zvLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all periods all conds (correct)\n",
        "LRNN_NSC_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NSC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_NSC_one_d_all_pca = fit_pca_on_selected_data(LRNN_NSC_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_NSC_two_d_all_pca = fit_pca_on_selected_data(LRNN_NSC_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NSC_one_d_all_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NSC_two_d_all_pca, data_to_transform_dict=LRNN_NSC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NSC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NSC/LRNN_NSC_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "Gq6N07tbvKtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53828654-6581-407a-b93a-338be464ac0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NSC/LRNN_NSC_all_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN SE2D"
      ],
      "metadata": {
        "id": "RVWP0Uu5L-0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN SE2D"
      ],
      "metadata": {
        "id": "Ni_RSucaL-0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample period data for all conds:\n",
        "LRNN_SE2D_sample_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='sample')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_SE2D_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# test period data for all conds:\n",
        "LRNN_SE2D_test_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='test')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_SE2D_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n"
      ],
      "metadata": {
        "id": "mijjTjCXL-0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_SE2D_one_d_sample_pca = fit_pca_on_selected_data(LRNN_SE2D_sample_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_SE2D_two_d_sample_pca = fit_pca_on_selected_data(LRNN_SE2D_sample_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_SE2D_one_d_delay_pca = fit_pca_on_selected_data(LRNN_SE2D_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_SE2D_two_d_delay_pca = fit_pca_on_selected_data(LRNN_SE2D_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the test period (1d)\n",
        "LRNN_SE2D_one_d_test_pca = fit_pca_on_selected_data(LRNN_SE2D_test_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the test period (2d)\n",
        "LRNN_SE2D_two_d_test_pca = fit_pca_on_selected_data(LRNN_SE2D_test_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_SE2D_one_d_decision_pca = fit_pca_on_selected_data(LRNN_SE2D_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_SE2D_two_d_decision_pca = fit_pca_on_selected_data(LRNN_SE2D_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n"
      ],
      "metadata": {
        "id": "gnU_0EglL-0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN SE2D"
      ],
      "metadata": {
        "id": "MA-IVWyCL-0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN SE2D Plot"
      ],
      "metadata": {
        "id": "XxgSgudrL-0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_sample_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_sample_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_delay_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_test_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_test_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_decision_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_decision_PCA_1D_full_trials.png')\n"
      ],
      "metadata": {
        "id": "34h3eONBMLJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a732dbf-8166-46b0-a7ec-78a803a88691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/LRNN_SE2D_sample_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_delay_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_test_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN SE2D Plot"
      ],
      "metadata": {
        "id": "RIEuOwSIL-0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_sample_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_sample_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_delay_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_test_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_test_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_decision_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "2RnjUUYyMQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81fe4b80-018d-4cfb-d14c-ff60ef0e52c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/LRNN_SE2D_sample_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_delay_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_test_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add All Period PCA"
      ],
      "metadata": {
        "id": "dxCf6baovU7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all periods all conds (correct)\n",
        "LRNN_SE2D_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE2D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_SE2D_one_d_all_pca = fit_pca_on_selected_data(LRNN_SE2D_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_SE2D_two_d_all_pca = fit_pca_on_selected_data(LRNN_SE2D_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE2D_one_d_all_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE2D_two_d_all_pca, data_to_transform_dict=LRNN_SE2D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE2D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE2D/LRNN_SE2D_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "wAwBWnMMvWZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bbf569-4381-4435-d3b8-38b444465f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE2D/LRNN_SE2D_all_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN SE3D"
      ],
      "metadata": {
        "id": "feyZMvShFQk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN SE3D"
      ],
      "metadata": {
        "id": "Bwqg7_TmFTrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample period data for all conds:\n",
        "LRNN_SE3D_sample_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='sample')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_SE3D_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# test period data for all conds:\n",
        "LRNN_SE3D_test_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='test')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_SE3D_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "\n",
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_SE3D_one_d_sample_pca = fit_pca_on_selected_data(LRNN_SE3D_sample_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_SE3D_two_d_sample_pca = fit_pca_on_selected_data(LRNN_SE3D_sample_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_SE3D_one_d_delay_pca = fit_pca_on_selected_data(LRNN_SE3D_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_SE3D_two_d_delay_pca = fit_pca_on_selected_data(LRNN_SE3D_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the test period (1d)\n",
        "LRNN_SE3D_one_d_test_pca = fit_pca_on_selected_data(LRNN_SE3D_test_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the test period (2d)\n",
        "LRNN_SE3D_two_d_test_pca = fit_pca_on_selected_data(LRNN_SE3D_test_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_SE3D_one_d_decision_pca = fit_pca_on_selected_data(LRNN_SE3D_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_SE3D_two_d_decision_pca = fit_pca_on_selected_data(LRNN_SE3D_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n"
      ],
      "metadata": {
        "id": "_5wQRzPuNMpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN SE3D"
      ],
      "metadata": {
        "id": "4I_0P9izGFfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN SE3D Plot"
      ],
      "metadata": {
        "id": "7k9TaDTzGict"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_sample_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_sample_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_delay_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_test_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_test_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_decision_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_decision_PCA_1D_full_trials.png')\n"
      ],
      "metadata": {
        "id": "uHXltp5lNN4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2d50e6-88a2-4f17-b7ce-5e6b136048ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/LRNN_SE3D_sample_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_delay_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_test_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN SE3D Plot"
      ],
      "metadata": {
        "id": "Msau2MN2Glgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_sample_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_sample_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_delay_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], save_filename='LRNN_SE3D/LRNN_SE3D_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_test_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_test_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_decision_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "Ev5bTjoZNO5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad00ac0-a3cf-4bdb-e5e4-3f33d24ca212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/LRNN_SE3D_sample_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_delay_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_test_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add All Period PCA"
      ],
      "metadata": {
        "id": "lao9vKdmvZyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all periods all conds (correct)\n",
        "LRNN_SE3D_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_SE3D_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_SE3D_one_d_all_pca = fit_pca_on_selected_data(LRNN_SE3D_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_SE3D_two_d_all_pca = fit_pca_on_selected_data(LRNN_SE3D_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_SE3D_one_d_all_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_SE3D_two_d_all_pca, data_to_transform_dict=LRNN_SE3D_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_SE3D_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_SE3D/LRNN_SE3D_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "N3tmag0CvZaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64e6dba-dd1f-4669-be68-2c728d86884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_SE3D/LRNN_SE3D_all_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN EI\n"
      ],
      "metadata": {
        "id": "uvXuJRKRL6wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN EI"
      ],
      "metadata": {
        "id": "Mr6Cegh-L6wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample period data for all conds:\n",
        "LRNN_EI_sample_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='sample')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_EI_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# test period data for all conds:\n",
        "LRNN_EI_test_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='test')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_EI_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_EI_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)"
      ],
      "metadata": {
        "id": "dOeyBcAsL6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_EI_one_d_sample_pca = fit_pca_on_selected_data(LRNN_EI_sample_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_EI_two_d_sample_pca = fit_pca_on_selected_data(LRNN_EI_sample_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_EI_one_d_delay_pca = fit_pca_on_selected_data(LRNN_EI_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_EI_two_d_delay_pca = fit_pca_on_selected_data(LRNN_EI_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the test period (1d)\n",
        "LRNN_EI_one_d_test_pca = fit_pca_on_selected_data(LRNN_EI_test_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the test period (2d)\n",
        "LRNN_EI_two_d_test_pca = fit_pca_on_selected_data(LRNN_EI_test_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_EI_one_d_decision_pca = fit_pca_on_selected_data(LRNN_EI_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_EI_two_d_decision_pca = fit_pca_on_selected_data(LRNN_EI_decision_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "\n",
        "# all periods all conds (correct)\n",
        "LRNN_EI_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_EI_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_EI_one_d_all_pca = fit_pca_on_selected_data(LRNN_EI_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_EI_two_d_all_pca = fit_pca_on_selected_data(LRNN_EI_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_all_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_EI/LRNN_EI_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_all_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_EI/LRNN_EI_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "2_f1URUkL6wN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af0614f-d37c-47e8-866d-7a788204feb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/LRNN_EI_all_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN EI"
      ],
      "metadata": {
        "id": "lM1XWxzrL6wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN EI Plot"
      ],
      "metadata": {
        "id": "Ofb1IS_2L6wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_sample_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_EI/LRNN_EI_sample_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_delay_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_EI/LRNN_EI_delay_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_test_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_EI/LRNN_EI_test_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_EI_one_d_decision_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_EI/LRNN_EI_decision_PCA_1D_full_trials.png')\n"
      ],
      "metadata": {
        "id": "6hzc3oWnMpWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b5df39-f2e2-47c5-d2e1-a5204ae636df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/LRNN_EI_sample_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_delay_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_test_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN EI Plot"
      ],
      "metadata": {
        "id": "wI4EWWwVL6wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_sample_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_EI/LRNN_EI_sample_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_delay_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_EI/LRNN_EI_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_test_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_EI/LRNN_EI_test_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_EI_two_d_decision_pca, data_to_transform_dict=LRNN_EI_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_EI_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_EI/LRNN_EI_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "id": "snr0AS_1MwNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40f9c3b-f81e-4f95-8a32-8540f2538964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_EI/LRNN_EI_sample_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_delay_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_test_PCA_2D_full_trials.png\n",
            "Figure saved to LRNN_EI/LRNN_EI_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmTiUfaqNz-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Sb4Q3U8PsPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selectivity and Leisoning - All BICs"
      ],
      "metadata": {
        "id": "4rZiQCoUH-P3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables for all"
      ],
      "metadata": {
        "id": "ArlnACvMIpxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leisoning_testing_data_set = dataset_testing"
      ],
      "metadata": {
        "id": "wRmAAD_YIsri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NSC"
      ],
      "metadata": {
        "id": "QdVEFAcYIBcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "KokoDqzOIFGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NSC_sample_stim_1_data = LRNN_NSC_testing_data_0p0_sample\n",
        "LRNN_NSC_sample_stim_2_data = LRNN_NSC_testing_data_3p1_sample\n",
        "LRNN_NSC_sample_stim_data_dicts = [LRNN_NSC_sample_stim_1_data['testing_trial_and_activity'], LRNN_NSC_sample_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NSC_1D_PCA_sssl = LRNN_NSC_one_d_sample_pca\n",
        "LRNN_NSC_2D_PCA_sssl = LRNN_NSC_two_d_sample_pca\n"
      ],
      "metadata": {
        "id": "9ZJtC5o9IQVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NSC_sample_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NSC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NSC_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NSC_1D_PCA_sssl, fig_file_name = 'LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_NSC_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "id": "YV6I7nBpIDGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3af6b6-b15a-4687-d958-b5fd9f6d4247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(17), np.int64(4), np.int64(51), np.int64(18), np.int64(55), np.int64(31)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.4955\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 49.55 %\n",
            "Performance Difference: 50.449999999999996 %\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS_1d_pca.png\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Stimulus Selective"
      ],
      "metadata": {
        "id": "Xau0hq4bIHxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NSC_test_stim_1_data = LRNN_NSC_testing_data_0p0_test\n",
        "LRNN_NSC_test_stim_2_data = LRNN_NSC_testing_data_3p1_test\n",
        "LRNN_NSC_test_stim_data_dicts = [LRNN_NSC_test_stim_1_data['testing_trial_and_activity'], LRNN_NSC_test_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NSC_1D_PCA_tssl = LRNN_NSC_one_d_test_pca\n",
        "LRNN_NSC_2D_PCA_tssl = LRNN_NSC_two_d_test_pca\n"
      ],
      "metadata": {
        "id": "FbGknxm9M246"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NSC_test_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NSC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NSC_test_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NSC_1D_PCA_tssl, fig_file_name = 'LRNN_NSC/leisoned_unleisoned_LRNN_NSC_TS' , file_ext='.png', unleisoned_PCA_2d = LRNN_NSC_2D_PCA_tssl, return_results = True)"
      ],
      "metadata": {
        "id": "Ej7ZNb5PQC8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e16564a-a8fc-4f21-f193-2d2b9999bd6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(37), np.int64(47), np.int64(52), np.int64(51), np.int64(5), np.int64(44)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.4905\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 49.05 %\n",
            "Performance Difference: 50.95 %\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_TS_1d_pca.png\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_TS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match - No Match Selective"
      ],
      "metadata": {
        "id": "tVw2R8wiIJuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NSC_match_modality_1_data = LRNN_NSC_testing_data_matching\n",
        "LRNN_NSC_match_modality_2_data = LRNN_NSC_testing_data_non_matching\n",
        "LRNN_NSC_match_modality_data_dicts = [LRNN_NSC_match_modality_1_data['testing_trial_and_activity'], LRNN_NSC_match_modality_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NSC_1D_PCA_mmsl = LRNN_NSC_one_d_decision_pca\n",
        "LRNN_NSC_2D_PCA_mmsl = LRNN_NSC_two_d_decision_pca"
      ],
      "metadata": {
        "id": "b4tun539QVSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_NSC_match_modality_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NSC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NSC_match_modality_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NSC_1D_PCA_mmsl, fig_file_name = 'LRNN_NSC/leisoned_unleisoned_LRNN_NSC_MM' , file_ext='.png', unleisoned_PCA_2d = LRNN_NSC_2D_PCA_mmsl, return_results = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WPD3t4tRRBuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6133b72b-8417-4665-ade6-c4e5c6057cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(35), np.int64(15), np.int64(38), np.int64(14), np.int64(59), np.int64(8)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.25\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 25.0 %\n",
            "Performance Difference: 75.0 %\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_MM_1d_pca.png\n",
            "Figure saved to LRNN_NSC/leisoned_unleisoned_LRNN_NSC_MM_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEogXOrERcKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-SE2D"
      ],
      "metadata": {
        "id": "OX29HwuhRcmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "-KZGpy2FRcmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_SE2D_sample_stim_1_data = LRNN_SE2D_testing_data_0p0_sample\n",
        "LRNN_SE2D_sample_stim_2_data = LRNN_SE2D_testing_data_3p1_sample\n",
        "LRNN_SE2D_sample_stim_data_dicts = [LRNN_SE2D_sample_stim_1_data['testing_trial_and_activity'], LRNN_SE2D_sample_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE2D_1D_PCA_sssl = LRNN_SE2D_one_d_sample_pca\n",
        "LRNN_SE2D_2D_PCA_sssl = LRNN_SE2D_two_d_sample_pca\n"
      ],
      "metadata": {
        "id": "kahMO515Rcma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE2D_sample_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE2D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE2D_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE2D_1D_PCA_sssl, fig_file_name = 'LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE2D_2D_PCA_sssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "6u-_54jfRcmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c5d6d9-26e6-4d99-bae1-24560a2bcaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(63), np.int64(27), np.int64(15), np.int64(2), np.int64(54), np.int64(48)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.4935\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 49.35 %\n",
            "Performance Difference: 50.64999999999999 %\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_SS_1d_pca.png\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Stimulus Selective"
      ],
      "metadata": {
        "id": "WLACM495Rcmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data from Partition\n",
        "LRNN_SE2D_test_stim_1_data = LRNN_SE2D_testing_data_0p0_test\n",
        "LRNN_SE2D_test_stim_2_data = LRNN_SE2D_testing_data_3p1_test\n",
        "LRNN_SE2D_test_stim_data_dicts = [LRNN_SE2D_test_stim_1_data['testing_trial_and_activity'], LRNN_SE2D_test_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE2D_1D_PCA_tssl = LRNN_SE2D_one_d_test_pca\n",
        "LRNN_SE2D_2D_PCA_tssl = LRNN_SE2D_two_d_test_pca"
      ],
      "metadata": {
        "id": "64vKlt0bRcme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_SE2D_test_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE2D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE2D_test_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE2D_1D_PCA_tssl, fig_file_name = 'LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_TS' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE2D_2D_PCA_tssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "kCaMbHUORcmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0217144b-899c-402f-9af5-906d2b80c383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(10), np.int64(23), np.int64(50), np.int64(58), np.int64(18), np.int64(14)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.5085\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 50.849999999999994 %\n",
            "Performance Difference: 49.150000000000006 %\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_TS_1d_pca.png\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_TS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match - No Match Selective"
      ],
      "metadata": {
        "id": "iiafMVX_Rcmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "\n",
        "# Data from Partition\n",
        "LRNN_SE2D_match_modality_1_data = LRNN_SE2D_testing_data_matching\n",
        "LRNN_SE2D_match_modality_2_data = LRNN_SE2D_testing_data_non_matching\n",
        "LRNN_SE2D_match_modality_data_dicts = [LRNN_SE2D_match_modality_1_data['testing_trial_and_activity'], LRNN_SE2D_match_modality_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE2D_1D_PCA_mmsl = LRNN_SE2D_one_d_decision_pca\n",
        "LRNN_SE2D_2D_PCA_mmsl = LRNN_SE2D_two_d_decision_pca\n"
      ],
      "metadata": {
        "id": "ue0y0QkgRcmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_SE2D_match_modality_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE2D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE2D_match_modality_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE2D_1D_PCA_mmsl, fig_file_name = 'LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_MM' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE2D_2D_PCA_mmsl, return_results = True)\n"
      ],
      "metadata": {
        "id": "NAUBba0yRcmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc06c958-c468-4432-e671-8dd58e5b6cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(62), np.int64(47), np.int64(21), np.int64(45), np.int64(35), np.int64(61)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.504\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 50.4 %\n",
            "Performance Difference: 49.6 %\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_MM_1d_pca.png\n",
            "Figure saved to LRNN_SE2D/leisoned_unleisoned_LRNN_SE2D_MM_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYqnGslZR08E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzwtp8k0R5QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-SE3D"
      ],
      "metadata": {
        "id": "_i0_6m5aR5We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "4vWXoYu6R5Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_SE3D_sample_stim_1_data = LRNN_SE3D_testing_data_0p0_sample\n",
        "LRNN_SE3D_sample_stim_2_data = LRNN_SE3D_testing_data_3p1_sample\n",
        "LRNN_SE3D_sample_stim_data_dicts = [LRNN_SE3D_sample_stim_1_data['testing_trial_and_activity'], LRNN_SE3D_sample_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE3D_1D_PCA_sssl = LRNN_SE3D_one_d_sample_pca\n",
        "LRNN_SE3D_2D_PCA_sssl = LRNN_SE3D_two_d_sample_pca\n",
        "\n"
      ],
      "metadata": {
        "id": "MQnCocPDR-La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_SE3D_sample_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE3D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE3D_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE3D_1D_PCA_sssl, fig_file_name = 'LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE3D_2D_PCA_sssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "3igmrtWjR-c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88dadc8a-516f-4778-a89b-baf211531260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(19), np.int64(56), np.int64(59), np.int64(28), np.int64(31), np.int64(35)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.502\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 50.2 %\n",
            "Performance Difference: 49.8 %\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_SS_1d_pca.png\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Stimulus Selective"
      ],
      "metadata": {
        "id": "DOcDHrw9R5Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data from Partition\n",
        "LRNN_SE3D_test_stim_1_data = LRNN_SE3D_testing_data_0p0_test\n",
        "LRNN_SE3D_test_stim_2_data = LRNN_SE3D_testing_data_3p1_test\n",
        "LRNN_SE3D_test_stim_data_dicts = [LRNN_SE3D_test_stim_1_data['testing_trial_and_activity'], LRNN_SE3D_test_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE3D_1D_PCA_tssl = LRNN_SE3D_one_d_test_pca\n",
        "LRNN_SE3D_2D_PCA_tssl = LRNN_SE3D_two_d_test_pca\n"
      ],
      "metadata": {
        "id": "sbUQLUvWR8sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_SE3D_test_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE3D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE3D_test_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE3D_1D_PCA_tssl, fig_file_name = 'LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_TS' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE3D_2D_PCA_tssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "eaxS1Ci1R9AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1833a40-50be-4780-d87d-14ab7a9acf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(1), np.int64(15), np.int64(54), np.int64(50), np.int64(22), np.int64(30)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.7325\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 73.25 %\n",
            "Performance Difference: 26.749999999999996 %\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_TS_1d_pca.png\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_TS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match - No Match Selective"
      ],
      "metadata": {
        "id": "01kUSH5dR5Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data from Partition\n",
        "LRNN_SE3D_match_modality_1_data = LRNN_SE3D_testing_data_matching\n",
        "LRNN_SE3D_match_modality_2_data = LRNN_SE3D_testing_data_non_matching\n",
        "LRNN_SE3D_match_modality_data_dicts = [LRNN_SE3D_match_modality_1_data['testing_trial_and_activity'], LRNN_SE3D_match_modality_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_SE3D_1D_PCA_mmsl = LRNN_SE3D_one_d_decision_pca\n",
        "LRNN_SE3D_2D_PCA_mmsl = LRNN_SE3D_two_d_decision_pca\n"
      ],
      "metadata": {
        "id": "XzAnw3AYR5Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_SE3D_match_modality_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_SE3D_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_SE3D_match_modality_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_SE3D_1D_PCA_mmsl, fig_file_name = 'LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_MM' , file_ext='.png', unleisoned_PCA_2d = LRNN_SE3D_2D_PCA_mmsl, return_results = True)\n"
      ],
      "metadata": {
        "id": "GMQOHBpQR7J9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa4bb9b-ef05-4b69-cd1b-9f52c49b8fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(24), np.int64(21), np.int64(13), np.int64(4), np.int64(43), np.int64(55)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.503\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 50.3 %\n",
            "Performance Difference: 49.7 %\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_MM_1d_pca.png\n",
            "Figure saved to LRNN_SE3D/leisoned_unleisoned_LRNN_SE3D_MM_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-EI"
      ],
      "metadata": {
        "id": "5BUJn3v4SBQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "3dLWNU6bSBQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data from Partition\n",
        "LRNN_EI_sample_stim_1_data = LRNN_EI_testing_data_0p0_sample\n",
        "LRNN_EI_sample_stim_2_data = LRNN_EI_testing_data_3p1_sample\n",
        "LRNN_EI_sample_stim_data_dicts = [LRNN_EI_sample_stim_1_data['testing_trial_and_activity'], LRNN_EI_sample_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_EI_1D_PCA_sssl = LRNN_EI_one_d_sample_pca\n",
        "LRNN_EI_2D_PCA_sssl = LRNN_EI_two_d_sample_pca"
      ],
      "metadata": {
        "id": "de25796xSBQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_EI_sample_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_EI_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_EI_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_EI_1D_PCA_sssl, fig_file_name = 'LRNN_EI/leisoned_unleisoned_LRNN_EI_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_EI_2D_PCA_sssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "FP4BZAMMTCXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49411e4a-63ec-4c6d-89bf-812a52822f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: EIRecLinear()\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(56), np.int64(58), np.int64(48), np.int64(52), np.int64(51), np.int64(14)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.4905\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 49.05 %\n",
            "Performance Difference: 50.95 %\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_SS_1d_pca.png\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Stimulus Selective"
      ],
      "metadata": {
        "id": "_gv1l3MNSBQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_EI_test_stim_1_data = LRNN_EI_testing_data_0p0_test\n",
        "LRNN_EI_test_stim_2_data = LRNN_EI_testing_data_3p1_test\n",
        "LRNN_EI_test_stim_data_dicts = [LRNN_EI_test_stim_1_data['testing_trial_and_activity'], LRNN_EI_test_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_EI_1D_PCA_tssl = LRNN_EI_one_d_test_pca\n",
        "LRNN_EI_2D_PCA_tssl = LRNN_EI_two_d_test_pca\n"
      ],
      "metadata": {
        "id": "pCk8r3q8SBQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_EI_test_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_EI_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_EI_test_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_EI_1D_PCA_tssl, fig_file_name = 'LRNN_EI/leisoned_unleisoned_LRNN_EI_TS' , file_ext='.png', unleisoned_PCA_2d = LRNN_EI_2D_PCA_tssl, return_results = True)\n"
      ],
      "metadata": {
        "id": "Axolr1MOTKEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd69b17b-97aa-43b6-b8b7-3cfa52ff7d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: EIRecLinear()\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(55), np.int64(3), np.int64(38), np.int64(37), np.int64(5), np.int64(29)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.7545\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 75.44999999999999 %\n",
            "Performance Difference: 24.550000000000004 %\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_TS_1d_pca.png\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_TS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match - No Match Selective"
      ],
      "metadata": {
        "id": "9Ip3--X4SBQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data from Partition\n",
        "LRNN_EI_match_modality_1_data = LRNN_EI_testing_data_matching\n",
        "LRNN_EI_match_modality_2_data = LRNN_EI_testing_data_non_matching\n",
        "LRNN_EI_match_modality_data_dicts = [LRNN_EI_match_modality_1_data['testing_trial_and_activity'], LRNN_EI_match_modality_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_EI_1D_PCA_mmsl = LRNN_EI_one_d_decision_pca\n",
        "LRNN_EI_2D_PCA_mmsl = LRNN_EI_two_d_decision_pca\n"
      ],
      "metadata": {
        "id": "2N2jOkT6SBQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_EI_match_modality_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_EI_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_EI_match_modality_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_EI_1D_PCA_mmsl, fig_file_name = 'LRNN_EI/leisoned_unleisoned_LRNN_EI_MM' , file_ext='.png', unleisoned_PCA_2d = LRNN_EI_2D_PCA_mmsl, return_results = True)\n"
      ],
      "metadata": {
        "id": "iFBqVr4ySBQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfda65c-57d5-4b14-f0a5-e7b51f219a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: EIRecLinear()\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(62), np.int64(18), np.int64(26), np.int64(2), np.int64(12), np.int64(44)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.5105\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 51.05 %\n",
            "Performance Difference: 48.95 %\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_MM_1d_pca.png\n",
            "Figure saved to LRNN_EI/leisoned_unleisoned_LRNN_EI_MM_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPA"
      ],
      "metadata": {
        "id": "mswkpuZMPssl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Package Inits"
      ],
      "metadata": {
        "id": "tJsV_uxVPuQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/fixed-point-finder-master')\n",
        "%cd fixed-point-finder-master\n",
        "from FixedPointFinderTorch import FixedPointFinderTorch as FixedPointFinder\n",
        "import torch\n",
        "%cd .."
      ],
      "metadata": {
        "id": "3FwysyewPtj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2e71c1-ecac-4793-fb26-746284369438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fixed-point-finder-master\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHANGES TO CODE FOR BIC RNNs"
      ],
      "metadata": {
        "id": "h1900jowV7OP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a Testing Function to collect neuron states for initialising Initial Conditions"
      ],
      "metadata": {
        "id": "Y4d1ZqhWTWyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPF Implementation for BIC Networks"
      ],
      "metadata": {
        "id": "fGG7lM5uoa1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixation_input_array = np.array([[1.0,0.0,0.0]])\n",
        "delay_input_array = np.array([[1.0,0.0,0.0]])\n",
        "stim_pi_input_array = np.array([[1.0,0.0,1.0]])\n",
        "stim_0_input_array = np.array([[1.0,1.0,0.0]])\n",
        "response_input_array = np.array([[0.0,0.0,0.0]])"
      ],
      "metadata": {
        "id": "sBEn-2A3qR7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper for BIC RNN Layers"
      ],
      "metadata": {
        "id": "qQubMtF_ousL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedPointRNNWrapper_BIC(torch.nn.Module):\n",
        "    def __init__(self, rnn, batch_first=False):\n",
        "        super(FixedPointRNNWrapper_BIC, self).__init__()\n",
        "        self.rnn = rnn\n",
        "        self.batch_first = batch_first  # Ensure this matches your RNN's setting\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # # Squeeze the extra dimension from hidden state\n",
        "        # # Hidden shape transforms from [1, batch_size, hidden_size] to [batch_size, hidden_size]\n",
        "        # hidden = hidden.squeeze(0)\n",
        "\n",
        "        # # EI-RNN expects inputs of shape [seq_len, batch_size, input_size]\n",
        "        # # Since we have seq_len=1, input shape is already correct\n",
        "\n",
        "        # Forward pass through your EI-RNN\n",
        "        output, hidden = self.rnn.forward_helper_fpf(input, hidden)\n",
        "\n",
        "        # # Unsqueeze hidden to match FixedPointFinder's expectation\n",
        "        # # Hidden shape transforms from [batch_size, hidden_size] to [1, batch_size, hidden_size]\n",
        "        # hidden = hidden.unsqueeze(0)\n",
        "\n",
        "        # Return None for output as per FixedPointFinder's requirement # not a requirement\n",
        "        return None, hidden"
      ],
      "metadata": {
        "id": "_EqPKF4slEbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-NSC"
      ],
      "metadata": {
        "id": "AH3V3OLLoiFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do state tracked testing trials\n",
        "# LRNN_NSC_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_NSC_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_NSC_STATETRACKED_full_testing_data = LRNN_NSC_full_testing_data"
      ],
      "metadata": {
        "id": "glpgsyonixje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_tracked_env_info = LRNN_NSC_STATETRACKED_full_testing_data['testing_env_info']"
      ],
      "metadata": {
        "id": "0kCWVuPbkP0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NSC_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_NSC_TRAINED.rnn)"
      ],
      "metadata": {
        "id": "BfNSPIm1mIPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NSC_two_d_delay_pca = LRNN_NSC_two_d_all_pca"
      ],
      "metadata": {
        "id": "xSPngymGnZfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NSC Sample Period"
      ],
      "metadata": {
        "id": "6ftp1X41o-Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Sample_Stim0_delaypca.png', title_for_plot = 'Sample Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'sample_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Sample_Stimpi_delaypca.png', title_for_plot = 'Sample Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "ee7keb82txo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81589cfe-6ca8-4821-962b-8fc92fab6632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1033 iters\n",
            "\t\tq = 1.87e-05 +/- 4.58e-04\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 9.72e-06\n",
            "\t\tavg iter time = 2.78e-03 sec\n",
            "\tIdentified 2 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 2).\n",
            "\tComputing recurrent Jacobian at 2 unique fixed points.\n",
            "\tComputing input Jacobian at 2 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(2, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Sample_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 3.57e-03 +/- 2.78e-03\n",
            "\t\tdq = 2.09e-09 +/- 2.39e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.27e-03 sec\n",
            "\tIdentified 125 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 125).\n",
            "\tComputing recurrent Jacobian at 125 unique fixed points.\n",
            "\tComputing input Jacobian at 125 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(125, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Sample_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NSC Delay Period"
      ],
      "metadata": {
        "id": "t50iv63wpF-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Delay_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "REt5Lm1njwer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eba6e7d-33a6-4d9f-8413-661190a3dd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t6110 iters\n",
            "\t\tq = 1.22e-12 +/- 7.41e-12\n",
            "\t\tdq = 2.60e-17 +/- 1.38e-16\n",
            "\t\tlearning rate = 7.96e-05\n",
            "\t\tavg iter time = 3.19e-03 sec\n",
            "\tIdentified 3 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 3).\n",
            "\tComputing recurrent Jacobian at 3 unique fixed points.\n",
            "\tComputing input Jacobian at 3 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(3, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Delay_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NSC - Test Period"
      ],
      "metadata": {
        "id": "6YDmG1IopLzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'test_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Test_Stim0_delaypca.png', title_for_plot = 'Test Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'test_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Test_Stimpi_delaypca.png', title_for_plot = 'Test Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "ubt326cfpXb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e0c1fe-b658-4279-ccb3-34f4dae69a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t842 iters\n",
            "\t\tq = 9.36e-06 +/- 3.24e-04\n",
            "\t\tdq = 3.03e-17 +/- 2.29e-16\n",
            "\t\tlearning rate = 5.89e-04\n",
            "\t\tavg iter time = 2.69e-03 sec\n",
            "\tIdentified 2 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 2).\n",
            "\tComputing recurrent Jacobian at 2 unique fixed points.\n",
            "\tComputing input Jacobian at 2 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(2, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Test_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.49e-03 +/- 2.76e-03\n",
            "\t\tdq = 6.96e-10 +/- 1.62e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.90e-03 sec\n",
            "\tIdentified 53 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 53).\n",
            "\tComputing recurrent Jacobian at 53 unique fixed points.\n",
            "\tComputing input Jacobian at 53 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(53, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Test_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NSC - Decision Period"
      ],
      "metadata": {
        "id": "Z64wVLTtpR3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NSC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NSC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NSC_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NSC/LRNN_NSC_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)"
      ],
      "metadata": {
        "id": "7DaxcC89TVk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2263b10-8497-4478-eb58-373f2a069cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 7.84e-04 +/- 1.06e-03\n",
            "\t\tdq = 7.62e-10 +/- 1.29e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.27e-03 sec\n",
            "\tIdentified 114 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 114).\n",
            "\tComputing recurrent Jacobian at 114 unique fixed points.\n",
            "\tComputing input Jacobian at 114 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(114, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NSC/LRNN_NSC_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-SE2D"
      ],
      "metadata": {
        "id": "nbfN20CSJBxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE2D_STATETRACKED_full_testing_data = LRNN_SE2D_full_testing_data\n",
        "\n",
        "state_tracked_env_info = LRNN_SE2D_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_SE2D_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_SE2D_TRAINED.rnn)"
      ],
      "metadata": {
        "id": "lZY3DMXSJI7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE2D_two_d_delay_pca = LRNN_SE2D_two_d_all_pca"
      ],
      "metadata": {
        "id": "loWnioQPnlIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE2D Sample Period"
      ],
      "metadata": {
        "id": "PvGwbcs4JBxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Sample_Stim0_delaypca.png', title_for_plot = 'Sample Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'sample_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Sample_Stimpi_delaypca.png', title_for_plot = 'Sample Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "qN1Umx4KJHbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a17c0b-5517-4d78-84ed-c6fc218a4087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.18e-04 +/- 1.87e-04\n",
            "\t\tdq = 1.12e-10 +/- 2.53e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 4.13e-03 sec\n",
            "\tIdentified 32 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 32).\n",
            "\tComputing recurrent Jacobian at 32 unique fixed points.\n",
            "\tComputing input Jacobian at 32 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(32, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Sample_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1559 iters\n",
            "\t\tq = 1.31e-04 +/- 4.39e-04\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.04e-03 sec\n",
            "\tIdentified 20 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 20).\n",
            "\tComputing recurrent Jacobian at 20 unique fixed points.\n",
            "\tComputing input Jacobian at 20 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(20, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Sample_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE2D Delay Period"
      ],
      "metadata": {
        "id": "Sd3wY2vsJBxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Delay_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "TUGe5yV2JGRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4689465d-8919-4f3f-954d-2103ee1dbbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.38e-04 +/- 2.39e-04\n",
            "\t\tdq = 1.82e-10 +/- 3.13e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.75e-03 sec\n",
            "\tIdentified 113 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 113).\n",
            "\tComputing recurrent Jacobian at 113 unique fixed points.\n",
            "\tComputing input Jacobian at 113 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(113, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Delay_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE2D - Test Period"
      ],
      "metadata": {
        "id": "Vmh5bzmhJBxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'test_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Test_Stim0_delaypca.png', title_for_plot = 'Test Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'test_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Test_Stimpi_delaypca.png', title_for_plot = 'Test Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "v4FWrbFXJFTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec7ad71-88d6-4d6d-9054-19dbfd87ba2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.89e-04 +/- 2.69e-04\n",
            "\t\tdq = 1.51e-10 +/- 3.63e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.99e-03 sec\n",
            "\tIdentified 31 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 31).\n",
            "\tComputing recurrent Jacobian at 31 unique fixed points.\n",
            "\tComputing input Jacobian at 31 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(31, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Test_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 6.84e-04 +/- 1.77e-03\n",
            "\t\tdq = 3.65e-10 +/- 7.37e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.90e-03 sec\n",
            "\tIdentified 42 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 42).\n",
            "\tComputing recurrent Jacobian at 42 unique fixed points.\n",
            "\tComputing input Jacobian at 42 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(42, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Test_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE2D - Decision Period"
      ],
      "metadata": {
        "id": "t0FmK7akJBxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE2D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE2D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE2D_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE2D/LRNN_SE2D_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "_-WX_OksJEHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129c8977-833a-40c3-ed49-a5cbeabb7f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.87e-04 +/- 1.18e-04\n",
            "\t\tdq = 2.59e-10 +/- 3.69e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.58e-03 sec\n",
            "\tIdentified 97 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 97).\n",
            "\tComputing recurrent Jacobian at 97 unique fixed points.\n",
            "\tComputing input Jacobian at 97 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(97, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE2D/LRNN_SE2D_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-SE3D"
      ],
      "metadata": {
        "id": "ZcuAURorJejq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE3D_STATETRACKED_full_testing_data = LRNN_SE3D_full_testing_data\n",
        "\n",
        "state_tracked_env_info = LRNN_SE3D_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_SE3D_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_SE3D_TRAINED.rnn)\n"
      ],
      "metadata": {
        "id": "cIyjDYgZJejr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_SE3D_two_d_delay_pca = LRNN_SE3D_two_d_all_pca"
      ],
      "metadata": {
        "id": "AtmyXJ5Jnp1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE3D Sample Period"
      ],
      "metadata": {
        "id": "_Ux9LHv8Jejs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Sample_Stim0_delaypca.png', title_for_plot = 'Sample Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'sample_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Sample_Stimpi_delaypca.png', title_for_plot = 'Sample Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "GnclbQV5Jejs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2581ab3-9bf2-46ed-eab1-40177cb1a4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1696 iters\n",
            "\t\tq = 1.71e-03 +/- 4.10e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.38e-03 sec\n",
            "\tIdentified 12 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 12).\n",
            "\tComputing recurrent Jacobian at 12 unique fixed points.\n",
            "\tComputing input Jacobian at 12 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(12, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Sample_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1113 iters\n",
            "\t\tq = 1.33e-03 +/- 2.60e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 4.96e-07\n",
            "\t\tavg iter time = 3.86e-03 sec\n",
            "\tIdentified 23 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 23).\n",
            "\tComputing recurrent Jacobian at 23 unique fixed points.\n",
            "\tComputing input Jacobian at 23 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(23, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Sample_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE3D Delay Period"
      ],
      "metadata": {
        "id": "-oG-He8GJejt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Delay_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "IRuJ8dOCJejt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d8f940-106a-486e-d900-9db0025638b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 3.30e-07 +/- 5.99e-07\n",
            "\t\tdq = 2.66e-12 +/- 4.29e-12\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 4.11e-03 sec\n",
            "\tIdentified 78 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 78).\n",
            "\tComputing recurrent Jacobian at 78 unique fixed points.\n",
            "\tComputing input Jacobian at 78 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(78, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Delay_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE3D - Test Period"
      ],
      "metadata": {
        "id": "PHEpgYcdJeju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'test_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Test_Stim0_delaypca.png', title_for_plot = 'Test Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'test_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Test_Stimpi_delaypca.png', title_for_plot = 'Test Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "nMRQ5K07Jejv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336f0d1d-562b-4b7c-b5d5-e183a4f7f9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1354 iters\n",
            "\t\tq = 1.05e-03 +/- 3.31e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 4.39e-03 sec\n",
            "\tIdentified 11 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 11).\n",
            "\tComputing recurrent Jacobian at 11 unique fixed points.\n",
            "\tComputing input Jacobian at 11 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(11, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Test_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1124 iters\n",
            "\t\tq = 1.70e-03 +/- 2.83e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 3.65e-07\n",
            "\t\tavg iter time = 3.08e-03 sec\n",
            "\tIdentified 23 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 23).\n",
            "\tComputing recurrent Jacobian at 23 unique fixed points.\n",
            "\tComputing input Jacobian at 23 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(23, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Test_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-SE3D - Decision Period"
      ],
      "metadata": {
        "id": "b89MiOz_Jejv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_SE3D_FOR_FPF, testing_trial_data_for_fpa=LRNN_SE3D_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_SE3D_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_SE3D/LRNN_SE3D_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "XMSCTxQHJejw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97d83f7-302c-433f-a74b-0f6fcaa15dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 2.27e-04 +/- 2.47e-04\n",
            "\t\tdq = 1.86e-10 +/- 3.35e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.64e-03 sec\n",
            "\tIdentified 101 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 101).\n",
            "\tComputing recurrent Jacobian at 101 unique fixed points.\n",
            "\tComputing input Jacobian at 101 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(101, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_SE3D/LRNN_SE3D_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-EI"
      ],
      "metadata": {
        "id": "0CO2kSTpJMo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_EI_STATETRACKED_full_testing_data = LRNN_EI_full_testing_data\n",
        "\n",
        "state_tracked_env_info = LRNN_EI_STATETRACKED_full_testing_data['testing_env_info']\n",
        "\n",
        "LRNN_EI_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_EI_TRAINED.rnn)"
      ],
      "metadata": {
        "id": "891HmwgGJMo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_EI_two_d_delay_pca = LRNN_EI_two_d_all_pca"
      ],
      "metadata": {
        "id": "gT06dEmmnvHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-EI Sample Period"
      ],
      "metadata": {
        "id": "VPqy3TJmJMo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Sample_Stim0_delaypca.png', title_for_plot = 'Sample Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'sample_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Sample_Stimpi_delaypca.png', title_for_plot = 'Sample Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "uaSNxYiGJMo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c05b216-0eea-4d83-eff6-7ae62deba160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t313 iters\n",
            "\t\tq = 9.57e-14 +/- 3.77e-14\n",
            "\t\tdq = 5.05e-14 +/- 1.16e-12\n",
            "\t\tlearning rate = 4.63e-01\n",
            "\t\tavg iter time = 3.47e-03 sec\n",
            "\tIdentified 1 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 1).\n",
            "\tComputing recurrent Jacobian at 1 unique fixed points.\n",
            "\tComputing input Jacobian at 1 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(1, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Sample_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1245 iters\n",
            "\t\tq = 7.32e-04 +/- 1.13e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.07e-06\n",
            "\t\tavg iter time = 3.83e-03 sec\n",
            "\tIdentified 65 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 65).\n",
            "\tComputing recurrent Jacobian at 65 unique fixed points.\n",
            "\tComputing input Jacobian at 65 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(65, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Sample_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-EI Delay Period"
      ],
      "metadata": {
        "id": "TPT9Vj9tJMo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Delay_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "esphEDitJMo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757a1cfe-21e3-4dea-af64-a34e0370c874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1318 iters\n",
            "\t\tq = 7.60e-06 +/- 2.78e-05\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 5.69e-03 sec\n",
            "\tIdentified 19 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 19).\n",
            "\tComputing recurrent Jacobian at 19 unique fixed points.\n",
            "\tComputing input Jacobian at 19 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(19, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Delay_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-EI - Test Period"
      ],
      "metadata": {
        "id": "OZdx4en2JMo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'test_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Test_Stim0_delaypca.png', title_for_plot = 'Test Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'test_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Test_Stimpi_delaypca.png', title_for_plot = 'Test Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "ygkJb3CCJMo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e1f137-1269-4d96-da7f-209a8d584942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t856 iters\n",
            "\t\tq = 4.28e-04 +/- 2.44e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 7.15e-06\n",
            "\t\tavg iter time = 3.55e-03 sec\n",
            "\tIdentified 4 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 4).\n",
            "\tComputing recurrent Jacobian at 4 unique fixed points.\n",
            "\tComputing input Jacobian at 4 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(4, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Test_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t1320 iters\n",
            "\t\tq = 2.93e-04 +/- 7.97e-04\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 4.04e-07\n",
            "\t\tavg iter time = 4.26e-03 sec\n",
            "\tIdentified 73 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 73).\n",
            "\tComputing recurrent Jacobian at 73 unique fixed points.\n",
            "\tComputing input Jacobian at 73 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(73, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Test_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-EI - Decision Period"
      ],
      "metadata": {
        "id": "HOl44m08JMo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_EI_FOR_FPF, testing_trial_data_for_fpa=LRNN_EI_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_EI_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_EI/LRNN_EI_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100)\n"
      ],
      "metadata": {
        "id": "t_ZzK3-WJMo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3b1d0c-643a-4357-9ad2-30a8b21ecfe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 1.61e-04 +/- 2.61e-04\n",
            "\t\tdq = 2.19e-10 +/- 3.32e-10\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 4.19e-03 sec\n",
            "\tIdentified 186 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 186).\n",
            "\tComputing recurrent Jacobian at 186 unique fixed points.\n",
            "\tComputing input Jacobian at 186 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(186, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_EI/LRNN_EI_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:\n",
        "#   continue"
      ],
      "metadata": {
        "id": "6k2KjBX6JMo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NBIC WORK (BROUGHT IN FROM OTHER NOTEBOOK - SHOULD STILL WORK THO)"
      ],
      "metadata": {
        "id": "OJjnUjlMe3o9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ls9xaT_S8uP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINING NBIC NETWORK (LAST UPDATE : 1507_4:07pm)"
      ],
      "metadata": {
        "id": "OvsHMmXghYKK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hkpAu-PhYKM"
      },
      "source": [
        "## LeakyRNN Layer - No BICs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9Hk8gM10j49"
      },
      "outputs": [],
      "source": [
        "# Leaky RNN\n",
        "class LeakyRNN(nn.Module):\n",
        "    \"\"\"Leaky RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialised through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=50, tau=100, **kwargs): # dt is now required\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.alpha = dt / self.tau # Alpha is always dt/tau\n",
        "        self.batch_first = False # For fixed point finder\n",
        "        # Check for stability (/biological plausibility)\n",
        "        if self.alpha > 1.0:\n",
        "            print(f\"Warning: dt ({dt}) is greater than tau ({tau}). Alpha ({self.alpha:.2f}) > 1.0. This can lead to numerical instability.\")\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      # Initialise input-to-hidden layer with Kaiming Uniform\n",
        "      init.kaiming_uniform_(self.input2h.weight, a=math.sqrt(5))\n",
        "      if self.input2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.input2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.input2h.bias, -bound, bound)\n",
        "\n",
        "      # Initialise hidden-to-hidden layer with Orthogonal\n",
        "      init.orthogonal_(self.h2h.weight)\n",
        "      if self.h2h.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(self.h2h.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(self.h2h.bias, -bound, bound)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = input_shape[1]\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "        h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
        "        h_new = hidden * (1 - self.alpha) + h_new * self.alpha\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        # Hidden is the final step state of this layers activity, output is all step states (including final)\n",
        "        # change for using bic code:\n",
        "\n",
        "        return output, hidden\n",
        "    def forward_helper_fpf(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "    def forward_helper_fpf_ICs(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialise it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "        output = []\n",
        "        hidden_s = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "            hidden_s.append(hidden)\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        hidden_tensor = torch.stack(hidden_s, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NBIC : Main Network"
      ],
      "metadata": {
        "id": "qDlBhdFEhYKR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnp-_hrR0jJk"
      },
      "outputs": [],
      "source": [
        "class RNNNet(nn.Module):\n",
        "    \"\"\"Full Network with a Leaky Recurrent Layer.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_layers = 1\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # Leaky RNN\n",
        "        self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.all_layers = [self.fc]\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      for layer in self.all_layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "          init.kaiming_uniform_(layer.weight, a=math.sqrt(5))\n",
        "        if layer.bias is not None:\n",
        "          fan_in, _ = init._calculate_fan_in_and_fan_out(layer.weight)\n",
        "          bound = 1 / math.sqrt(fan_in)\n",
        "          init.uniform_(layer.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output\n",
        "\n",
        "    def forward_for_fpf_ics(self, x):\n",
        "      rnn_outputs, hidden_state_tensor = self.rnn.forward_helper_fpf_ICs(x)\n",
        "      out = self.fc(rnn_outputs)\n",
        "      return out, rnn_outputs, hidden_state_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting From Pretrained // TRAIN"
      ],
      "metadata": {
        "id": "jEvLIZuVhYKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training for LRNN_NBIC"
      ],
      "metadata": {
        "id": "6o0u8SqbZMN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising LRNN-NBIC from .pth // Training"
      ],
      "metadata": {
        "id": "EPjM-6IGhYKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Parameters\n",
        "hidden_size_NBIC = 64\n",
        "input_size_NBIC = 3\n",
        "output_size_NBIC = 3\n",
        "dt_NBIC = 50\n",
        "tau_NBIC = 100\n",
        "# Initialising base model\n",
        "LRNN_NBIC = RNNNet(input_size=input_size_NBIC, hidden_size = hidden_size_NBIC, output_size = output_size_NBIC, dt=dt_NBIC, tau=tau_NBIC)\n",
        "# MODEL_IO_NBIC = False\n",
        "if MODEL_IO_NBIC:\n",
        "  LRNN_NBIC_TRAINED = LRNN_NBIC\n",
        "  # LRNN_NBIC_TRAINED.load_state_dict(torch.load('CURRENT_MODEL_PTHS/NBIC_LRNN_MODEL.pth'))\n",
        "  LRNN_NBIC_TRAINED.load_state_dict(torch.load('LRNN_NBIC/LRNN_NBIC.pth'))\n",
        "  LRNN_NBIC_TRAINED.eval()\n",
        "else:\n",
        "  # LRNN_NBIC_TRAINED, LRNN_NBIC_learning_curve_info = training_with_early_stop(LRNN_NBIC, dataset_training, validation_set_dictionary, max_steps = 10000, min_validation_perf = 0.8, patience = 3, num_steps_for_early_stop_check = 500, num_validation_trials = 200, model_name='LRNN_NBIC', tr_output_mode = True)\n",
        "  # Save learning Curve now because i/o\n",
        "  LRNN_NBIC_TRAINED, LRNN_NBIC_learning_curve_info = training_with_early_stop_and_regularisation(\n",
        "    model = LRNN_NBIC,\n",
        "    training_set =dataset_training ,\n",
        "    validation_set_dict = validation_set_dictionary,\n",
        "    WD_approach=False,\n",
        "    WD_regulariser=None,\n",
        "    wiring_beta=0.001,\n",
        "    activity_regularisation=False,\n",
        "    activity_beta=1e-3,\n",
        "    max_steps=10000,\n",
        "    min_validation_perf=0.8,\n",
        "    patience=5,\n",
        "    num_steps_for_early_stop_check=500,\n",
        "    num_validation_trials=200,\n",
        "    model_name='LRNN_NBIC',\n",
        "    tr_output_mode=True)\n",
        "  plot_learning_curve(\n",
        "    learning_curve_dict=LRNN_NBIC_learning_curve_info,\n",
        "    average_only=False,\n",
        "    plot_loss_components=False,\n",
        "    filename='LRNN_NBIC/Learning_Curve_NBIC_all.png',\n",
        "    show_legend=True,\n",
        "    legend_location='upper center')\n",
        "  plot_learning_curve(\n",
        "    learning_curve_dict=LRNN_NBIC_learning_curve_info,\n",
        "    average_only=True,\n",
        "    plot_loss_components=False,\n",
        "    filename='LRNN_NBIC/Learning_Curve_NBIC_avg.png',\n",
        "    show_legend=True,\n",
        "    legend_location='upper center')"
      ],
      "metadata": {
        "id": "oXjFxuFMhYKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_learning_curve(LRNN_NBIC_learning_curve_info, average_only=False, filename='LRNN_NBIC/LRNN_NBIC_learning_curve_all.png')"
      ],
      "metadata": {
        "id": "h6V-U5Dtn7JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Testing"
      ],
      "metadata": {
        "id": "W6Yw0V3VhYKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Testing for Each Network"
      ],
      "metadata": {
        "id": "WELLu3ALhYKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for LRNN - NBIC"
      ],
      "metadata": {
        "id": "iufa1FaShYKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_full_testing_data = bic_testing_w_state_tracking(LRNN_NBIC_TRAINED, dataset_testing, num_trials=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b14e0c-002f-4eb0-ec25-9ac7ae3c8a55",
        "id": "6c9e2deIhYKb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Data Partitioning for NBIC Network's Testing Data"
      ],
      "metadata": {
        "id": "W2cCAJEFhYKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning LRNN - NBIC"
      ],
      "metadata": {
        "id": "PYsnCITAhYKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : THESE ARE ALL OF THE SAME SHAPE AS THE ORIGINAL INPUT DICT\n",
        "# trial_activity_matching\n",
        "cond_dict_matching = {\n",
        "    'test_equals_sample' : True\n",
        "}\n",
        "LRNN_NBIC_testing_data_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, cond_dict_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_non_matching\n",
        "\n",
        "cond_dict_non_matching = {\n",
        "    'test_equals_sample' : False\n",
        "}\n",
        "LRNN_NBIC_testing_data_non_matching = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, cond_dict_non_matching, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_sample\n",
        "cond_dict_0p0_sample = {\n",
        "    'sample_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NBIC_testing_data_0p0_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_test\n",
        "cond_dict_0p0_test = {\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NBIC_testing_data_0p0_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "\n",
        "# trial_activity_3p1_sample\n",
        "cond_dict_3p1_sample = {\n",
        "    'sample_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NBIC_testing_data_3p1_sample = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_3p1_test\n",
        "cond_dict_3p1_test = {\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NBIC_testing_data_3p1_test = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "# trial_activity_0p0_3p1\n",
        "cond_dict_0p0_3p1 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NBIC_testing_data_0p0_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : np.pi}, return_like_full=True)\n",
        "\n",
        "#trial_activity_0p0_0p0\n",
        "cond_dict_0p0_0p0 = {\n",
        "    'sample_stim_value' : 0.0,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NBIC_testing_data_0p0_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : 0.0, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_0p0\n",
        "cond_dict_3p1_0p0 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : 0.0\n",
        "}\n",
        "LRNN_NBIC_testing_data_3p1_0p0 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : 0.0}, return_like_full=True)\n",
        "\n",
        "#trial_activity_3p1_3p1\n",
        "cond_dict_3p1_3p1 = {\n",
        "    'sample_stim_value' : np.pi,\n",
        "    'test_stim_value' : np.pi\n",
        "}\n",
        "LRNN_NBIC_testing_data_3p1_3p1 = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, {'sample_stim_value' : np.pi, 'test_stim_value' : np.pi}, return_like_full=True)"
      ],
      "metadata": {
        "id": "9vYb9xtqhYKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Unit Activity"
      ],
      "metadata": {
        "id": "1s9Cjb7GhYKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Unit Activity - LRNN NBIC"
      ],
      "metadata": {
        "id": "Zt21ul4whYKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NBIC - Single Trial Unit Activity"
      ],
      "metadata": {
        "id": "LnN-N3DNhYKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single trial of each sample x test combination\n",
        "LRNN_NBIC_one_trial_0p0_0p0 = LRNN_NBIC_testing_data_0p0_0p0['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_0p0_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NBIC_one_trial_0p0_3p1 = LRNN_NBIC_testing_data_0p0_3p1['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_0p0_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NBIC_one_trial_3p1_0p0 = LRNN_NBIC_testing_data_3p1_0p0['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_3p1_0p0['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NBIC_one_trial_3p1_3p1 = LRNN_NBIC_testing_data_3p1_3p1['testing_trial_and_activity'][list(LRNN_NBIC_testing_data_3p1_3p1['testing_trial_and_activity'].keys())[0]]['network_activity']\n",
        "LRNN_NBIC_one_trial_plot_env_info = LRNN_NBIC_testing_data_0p0_0p0['testing_env_info'] # Same for each\n",
        "\n"
      ],
      "metadata": {
        "id": "CB8hXZ8thYKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0p0_0p0\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_0p0_0p0, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NBIC/1trial_0p0_0p0_LRNN_NBIC.png') # plot all units, no legend for now\n",
        "#0p0_3p1\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_0p0_3p1, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NBIC/1trial_0p0_3p1_LRNN_NBIC.png') # plot all units, no legend for now\n",
        "# 3p1_0p0\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_3p1_0p0, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NBIC/1trial_3p1_0p0_LRNN_NBIC.png')\n",
        "#3p1_3p1\n",
        "plot_unit_activity_over_time(LRNN_NBIC_one_trial_3p1_3p1, LRNN_NBIC_one_trial_plot_env_info, unit_indices_to_plot=None, legend = False, filename='LRNN_NBIC/1trial_3p1_3p1_LRNN_NBIC.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc04921-7d62-4f62-a9c6-f0239a1c67e7",
        "id": "LSj9J0HehYKd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/1trial_0p0_0p0_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/1trial_0p0_3p1_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/1trial_3p1_0p0_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/1trial_3p1_3p1_LRNN_NBIC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LRNN NBIC - Average Unit Activity Plot"
      ],
      "metadata": {
        "id": "XOEVOICQhYKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LRNN_NBIC_all_trial_0p0_0p0 = LRNN_NBIC_testing_data_0p0_0p0['testing_trial_and_activity']\n",
        "LRNN_NBIC_all_trial_0p0_3p1 = LRNN_NBIC_testing_data_0p0_3p1['testing_trial_and_activity']\n",
        "LRNN_NBIC_all_trial_3p1_0p0 = LRNN_NBIC_testing_data_3p1_0p0['testing_trial_and_activity']\n",
        "LRNN_NBIC_all_trial_3p1_3p1 = LRNN_NBIC_testing_data_3p1_3p1['testing_trial_and_activity']\n",
        "LRNN_NBIC_all_trial_plot_env_info = LRNN_NBIC_testing_data_0p0_0p0['testing_env_info'] # Same for each\n"
      ],
      "metadata": {
        "id": "h1f6CD5PhYKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#0p0_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_0p0_0p0, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NBIC/avg_0p0_0p0_LRNN_NBIC.png')\n",
        "\n",
        "#0p0_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_0p0_3p1, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NBIC/avg_0p0_3p1_LRNN_NBIC.png')\n",
        "\n",
        "#3p1_0p0\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_3p1_0p0, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NBIC/avg_3p1_0p0_LRNN_NBIC.png')\n",
        "\n",
        "#3p1_3p1\n",
        "plot_average_unit_activity_over_time(LRNN_NBIC_all_trial_3p1_3p1, LRNN_NBIC_all_trial_plot_env_info, unit_indices_to_plot=None, legend=False, filename='LRNN_NBIC/avg_3p1_3p1_LRNN_NBIC.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398d5528-1257-4ba8-d0c4-c4afc777a294",
        "id": "tpQHuQnohYKe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/avg_0p0_0p0_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/avg_0p0_3p1_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/avg_3p1_0p0_LRNN_NBIC.png\n",
            "Figure saved to LRNN_NBIC/avg_3p1_3p1_LRNN_NBIC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Re-) Plotting Network Structure"
      ],
      "metadata": {
        "id": "ctAe5LkKhYKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Structure Plot LRNN NBIC"
      ],
      "metadata": {
        "id": "JtywSLNnhYKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_recurrent_weights_heatmap_BIC(LRNN_NBIC_TRAINED, filename='LRNN_NBIC/LRNN_NBIC_Connectivity.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944dce3f-d9ee-40b3-cf18-f27cd427419b",
        "id": "j84S0mdLhYKe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Connectivity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (EXPORTING DATA)"
      ],
      "metadata": {
        "id": "JyE39-jNhYKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Export - LRNN-NBIC"
      ],
      "metadata": {
        "id": "wJEpNpYmhYKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_nested_dict_to_json(LRNN_NBIC_full_testing_data, filename= 'LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b491a1-8a4b-4e09-d01a-d562ce87bb60",
        "id": "6JJdPp3xhYKf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_testing_structure = import_nested_dict_from_json(filename = 'LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea239b3-e68e-4fc9-e73b-a616f6b717af",
        "id": "eL3ZVbqFhYKf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully imported from LRNN_NBIC/LRNN_NBIC_testing_data_for_dPCA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_from_io = compare_dicts(LRNN_NBIC_full_testing_data, temp_testing_structure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f31a35-ffa5-4112-ab56-b4f145b43208",
        "id": "8Rps5b7phYKg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences found:\n",
            "{'type_changes': {\"root['testing_env_info']['sigma']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}, \"root['testing_trial_performance']\": {'old_type': <class 'numpy.float64'>, 'new_type': <class 'float'>}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dPCA - All Networks (Importing Plots and Displaying)"
      ],
      "metadata": {
        "id": "9yCcmR1RhYKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dPCA Display Outs - LRNN-NBIC"
      ],
      "metadata": {
        "id": "n85_7pbjhYKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Define the directory containing the images\n",
        "image_directory = 'LRNN_NBIC/LRNN_NBIC_dpca_plots'\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_directory):\n",
        "    print(f\"Directory '{image_directory}' not found.\")\n",
        "else:\n",
        "    # List all files in the directory\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No files found in '{image_directory}'.\")\n",
        "    else:\n",
        "        print(f\"Displaying images from '{image_directory}':\")\n",
        "        # Sort the files alphabetically for consistent order\n",
        "        image_files.sort()\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(image_directory, image_file)\n",
        "            print(f\"\\n--- {image_file} ---\")\n",
        "            try:\n",
        "                display(Image(filename=image_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not display image {image_file}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3408e926-67d4-4ddd-ca80-60e5979fddc5",
        "id": "zKskoP5YhYKh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'LRNN_NBIC/LRNN_NBIC_dpca_plots' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA (NBIC Network)"
      ],
      "metadata": {
        "id": "2HtX8UPuhYKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "tvdaoD7nhYKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "Rny5g0oihYKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample period data for all conds:\n",
        "LRNN_NBIC_sample_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='sample')\n",
        "\n",
        "\n",
        "# delay period data for all conds:\n",
        "LRNN_NBIC_delay_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='delay')\n",
        "\n",
        "# test period data for all conds:\n",
        "LRNN_NBIC_test_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='test')\n",
        "\n",
        "# decision period data all conds:\n",
        "LRNN_NBIC_decision_period_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False, hla_index='decision')\n",
        "\n"
      ],
      "metadata": {
        "id": "WsDJv87-hYKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA for the sample period (1d)\n",
        "LRNN_NBIC_one_d_sample_pca = fit_pca_on_selected_data(LRNN_NBIC_sample_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the sample period (2d)\n",
        "LRNN_NBIC_two_d_sample_pca = fit_pca_on_selected_data(LRNN_NBIC_sample_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the delay period (1d)\n",
        "LRNN_NBIC_one_d_delay_pca = fit_pca_on_selected_data(LRNN_NBIC_delay_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the delay period (2d)\n",
        "LRNN_NBIC_two_d_delay_pca = fit_pca_on_selected_data(LRNN_NBIC_delay_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the test period (1d)\n",
        "LRNN_NBIC_one_d_test_pca = fit_pca_on_selected_data(LRNN_NBIC_test_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the test period (2d)\n",
        "LRNN_NBIC_two_d_test_pca = fit_pca_on_selected_data(LRNN_NBIC_test_period_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "# Fit PCA for the decision period(1d)\n",
        "LRNN_NBIC_one_d_decision_pca = fit_pca_on_selected_data(LRNN_NBIC_decision_period_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for the decision period(2d)\n",
        "LRNN_NBIC_two_d_decision_pca = fit_pca_on_selected_data(LRNN_NBIC_decision_period_trials_dict, pca_components=2, report_var_expls = False)"
      ],
      "metadata": {
        "id": "a78gI09yhYKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot PCA - LRNN NBIC"
      ],
      "metadata": {
        "id": "7rq2RsLVhYKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1D PCA - LRNN NBIC Plot"
      ],
      "metadata": {
        "id": "3HSzztEEhYKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_sample_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_sample_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKLbAceXhYKj",
        "outputId": "6caa1f9d-a2d4-49c8-b5d9-7d310774c884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_sample_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_delay_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_delay_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a694c5-4b62-4ff4-d03c-0524eb13b51b",
        "id": "mYuJKfn7hYKk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_delay_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_test_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_test_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e405d9-8d6b-4c96-9114-d2d1bb759cb1",
        "id": "LvwdJILVhYKk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_test_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_decision_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_decision_PCA_1D_full_trials.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267976ba-7534-4764-bc1b-2779d8e5a04e",
        "id": "_0ysFnyRhYKl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_decision_PCA_1D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2D PCA - LRNN NBIC Plot"
      ],
      "metadata": {
        "id": "rtfBe-HUhYKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_sample_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_sample_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab17420-38b0-4552-e32c-866f6e83041a",
        "id": "DbzPwhYChYKl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_sample_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_delay_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_delay_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffffbbf0-813f-4a6a-9142-bc06aec55973",
        "id": "TFdJ1N6hhYKl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_delay_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_test_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_test_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d32ecd2-fc3a-425b-c5b8-03c8b11e2e60",
        "id": "oFBcZepyhYKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_test_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_decision_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_decision_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb30ffe9-4fca-4a53-87d3-234396656617",
        "id": "oRtPfVe9hYKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_decision_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add All Period PCA"
      ],
      "metadata": {
        "id": "DvSJ3dJuhYKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all periods all conds (correct)\n",
        "LRNN_NBIC_all_periods_trials_dict = extract_dict_of_trial_data_for_conds_and_hla_index(LRNN_NBIC_full_testing_data, dict_of_conds= {'network_correct': True}, return_like_full=False)\n",
        "\n",
        "# Fit PCA for al period(1d)\n",
        "LRNN_NBIC_one_d_all_pca = fit_pca_on_selected_data(LRNN_NBIC_all_periods_trials_dict, pca_components=1, report_var_expls = False)\n",
        "# Fit PCA for all period(2d)\n",
        "LRNN_NBIC_two_d_all_pca = fit_pca_on_selected_data(LRNN_NBIC_all_periods_trials_dict, pca_components=2, report_var_expls = False)\n",
        "\n",
        "\n",
        "plot_pca_trajectories(pca_object=LRNN_NBIC_one_d_all_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'], num_trials_to_plot=100, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_all_PCA_1D_full_trials.png')\n",
        "\n",
        "plot_pca_trajectories_2d(pca_object=LRNN_NBIC_two_d_all_pca, data_to_transform_dict=LRNN_NBIC_full_testing_data['testing_trial_and_activity'], testing_env_info=LRNN_NBIC_full_testing_data['testing_env_info'],\n",
        "                             num_trials_to_plot=20, plot_title=None, save_filename='LRNN_NBIC/LRNN_NBIC_all_PCA_2D_full_trials.png',\n",
        "                             add_phase_markers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4632a55-fdfc-4ad3-b77d-3fe52ca757e9",
        "id": "btaE1ICQhYKn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure saved to LRNN_NBIC/LRNN_NBIC_all_PCA_1D_full_trials.png\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_all_PCA_2D_full_trials.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selectivity and Leisoning - All NBIC"
      ],
      "metadata": {
        "id": "h2ZNxjykhYKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables for all"
      ],
      "metadata": {
        "id": "kVVXOOCDhYKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leisoning_testing_data_set = dataset_testing"
      ],
      "metadata": {
        "id": "_ewrMrl-hYKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LRNN-NBIC"
      ],
      "metadata": {
        "id": "iGFe68wJhYKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Stimulus Selective"
      ],
      "metadata": {
        "id": "xe7ADNt_hYKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NBIC_sample_stim_1_data = LRNN_NBIC_testing_data_0p0_sample\n",
        "LRNN_NBIC_sample_stim_2_data = LRNN_NBIC_testing_data_3p1_sample\n",
        "LRNN_NBIC_sample_stim_data_dicts = [LRNN_NBIC_sample_stim_1_data['testing_trial_and_activity'], LRNN_NBIC_sample_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NBIC_1D_PCA_sssl = LRNN_NBIC_one_d_sample_pca\n",
        "LRNN_NBIC_2D_PCA_sssl = LRNN_NBIC_two_d_sample_pca\n"
      ],
      "metadata": {
        "id": "blsjZgLThYKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_sample_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NBIC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NBIC_sample_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NBIC_1D_PCA_sssl, fig_file_name = 'LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_SS' , file_ext='.png', unleisoned_PCA_2d = LRNN_NBIC_2D_PCA_sssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2502861a-82ef-4472-8505-d5aaa0842264",
        "id": "32Ql3EPOhYKp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(24), np.int64(50), np.int64(5), np.int64(58), np.int64(11), np.int64(14)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.4865\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 48.65 %\n",
            "Performance Difference: 51.35000000000001 %\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_SS_1d_pca.png\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_SS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Stimulus Selective"
      ],
      "metadata": {
        "id": "285YFPRZhYKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NBIC_test_stim_1_data = LRNN_NBIC_testing_data_0p0_test\n",
        "LRNN_NBIC_test_stim_2_data = LRNN_NBIC_testing_data_3p1_test\n",
        "LRNN_NBIC_test_stim_data_dicts = [LRNN_NBIC_test_stim_1_data['testing_trial_and_activity'], LRNN_NBIC_test_stim_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NBIC_1D_PCA_tssl = LRNN_NBIC_one_d_test_pca\n",
        "LRNN_NBIC_2D_PCA_tssl = LRNN_NBIC_two_d_test_pca\n"
      ],
      "metadata": {
        "id": "P13Cgqb_hYKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_test_stim_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NBIC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NBIC_test_stim_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NBIC_1D_PCA_tssl, fig_file_name = 'LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_TS' , file_ext='.png', unleisoned_PCA_2d = LRNN_NBIC_2D_PCA_tssl, return_results = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cce938d-3d5a-4965-c4d1-5dc3a362d29b",
        "id": "1whBuvRhhYKq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(43), np.int64(58), np.int64(0), np.int64(15), np.int64(36), np.int64(47)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.2455\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 24.55 %\n",
            "Performance Difference: 75.44999999999999 %\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_TS_1d_pca.png\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_TS_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match - No Match Selective"
      ],
      "metadata": {
        "id": "UynNBtLDhYKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from Partition\n",
        "LRNN_NBIC_match_modality_1_data = LRNN_NBIC_testing_data_matching\n",
        "LRNN_NBIC_match_modality_2_data = LRNN_NBIC_testing_data_non_matching\n",
        "LRNN_NBIC_match_modality_data_dicts = [LRNN_NBIC_match_modality_1_data['testing_trial_and_activity'], LRNN_NBIC_match_modality_2_data['testing_trial_and_activity']]\n",
        "\n",
        "LRNN_NBIC_1D_PCA_mmsl = LRNN_NBIC_one_d_decision_pca\n",
        "LRNN_NBIC_2D_PCA_mmsl = LRNN_NBIC_two_d_decision_pca"
      ],
      "metadata": {
        "id": "r51OexC2hYKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LRNN_NBIC_match_modality_leisoning_results_dict = leison_network_for_top_n_and_test_BIC(trained_network = LRNN_NBIC_TRAINED, list_of_task_cond_1_cond_2_data_dicts_for_selectivity=LRNN_NBIC_match_modality_data_dicts, testing_data_set = leisoning_testing_data_set, n_perc_leison = 10, unleisoned_PCA_1d = LRNN_NBIC_1D_PCA_mmsl, fig_file_name = 'LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_MM' , file_ext='.png', unleisoned_PCA_2d = LRNN_NBIC_2D_PCA_mmsl, return_results = True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc0dbea-1538-4811-9b0a-7f521ef437b8",
        "id": "S1LHzKmvhYKq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a deep copy of the network.\n",
            "Found h2h layer: Linear(in_features=64, out_features=64, bias=True)\n",
            "Original h2h weights shape: (64, 64)\n",
            "Lesioning recurrent connections for units: [np.int64(5), np.int64(12), np.int64(25), np.int64(59), np.int64(13), np.int64(43)]\n",
            "Recurrent weights for specified units set to zero.\n",
            "Average performance 1.0\n",
            "Average performance 0.235\n",
            "Unleisoned Network Performance: 100.0 %\n",
            "Leisoned Network Performance: 23.5 %\n",
            "Performance Difference: 76.5 %\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_MM_1d_pca.png\n",
            "Figure saved to LRNN_NBIC/leisoned_unleisoned_LRNN_NBIC_MM_2d_pca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znp36p8NhYKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPA"
      ],
      "metadata": {
        "id": "qWgBcGodhYKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Package Inits"
      ],
      "metadata": {
        "id": "xJ95drxkhYKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/fixed-point-finder-master')\n",
        "%cd fixed-point-finder-master\n",
        "from FixedPointFinderTorch import FixedPointFinderTorch as FixedPointFinder\n",
        "import torch\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad73c69e-1324-43c9-8a41-8c5d50df252d",
        "id": "_P3OFr9mhYKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fixed-point-finder-master\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FPF Implementation for BIC Networks"
      ],
      "metadata": {
        "id": "K_Z7gY5HhYKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixation_input_array = np.array([[1.0,0.0,0.0]])\n",
        "delay_input_array = np.array([[1.0,0.0,0.0]])\n",
        "stim_pi_input_array = np.array([[1.0,0.0,1.0]])\n",
        "stim_0_input_array = np.array([[1.0,1.0,0.0]])\n",
        "response_input_array = np.array([[0.0,0.0,0.0]])"
      ],
      "metadata": {
        "id": "n5YFHmIihYKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapper for BIC RNN Layers (and NBIC)"
      ],
      "metadata": {
        "id": "-uAok-q3hYKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedPointRNNWrapper_BIC(torch.nn.Module):\n",
        "    def __init__(self, rnn, batch_first=False):\n",
        "        super(FixedPointRNNWrapper_BIC, self).__init__()\n",
        "        self.rnn = rnn\n",
        "        self.batch_first = batch_first  # Ensure this matches your RNN's setting\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # # Squeeze the extra dimension from hidden state\n",
        "        # # Hidden shape transforms from [1, batch_size, hidden_size] to [batch_size, hidden_size]\n",
        "        # hidden = hidden.squeeze(0)\n",
        "\n",
        "        # # EI-RNN expects inputs of shape [seq_len, batch_size, input_size]\n",
        "        # # Since we have seq_len=1, input shape is already correct\n",
        "\n",
        "        # Forward pass through your EI-RNN\n",
        "        output, hidden = self.rnn.forward_helper_fpf(input, hidden)\n",
        "\n",
        "        # # Unsqueeze hidden to match FixedPointFinder's expectation\n",
        "        # # Hidden shape transforms from [batch_size, hidden_size] to [1, batch_size, hidden_size]\n",
        "        # hidden = hidden.unsqueeze(0)\n",
        "\n",
        "        # Return None for output as per FixedPointFinder's requirement # not a requirement\n",
        "        return None, hidden"
      ],
      "metadata": {
        "id": "0zMaPselhYKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPF - LRNN-NBIC"
      ],
      "metadata": {
        "id": "CjPqkEPchYKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do state tracked testing trials\n",
        "# LRNN_NBIC_STATETRACKED_full_testing_data = bic_testing_w_state_tracking(network=LRNN_NBIC_TRAINED, dataset_to_evaluate=dataset_testing, num_trials=200)\n",
        "LRNN_NBIC_STATETRACKED_full_testing_data = LRNN_NBIC_full_testing_data"
      ],
      "metadata": {
        "id": "VwDPyk-mhYKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_tracked_env_info = LRNN_NBIC_STATETRACKED_full_testing_data['testing_env_info']"
      ],
      "metadata": {
        "id": "XyJSObX5hYKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_FOR_FPF = FixedPointRNNWrapper_BIC(rnn=LRNN_NBIC_TRAINED.rnn)"
      ],
      "metadata": {
        "id": "jJbXBNxIhYKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LRNN_NBIC_two_d_delay_pca = LRNN_NBIC_two_d_all_pca"
      ],
      "metadata": {
        "id": "beUqO6p_nShu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC Sample Period"
      ],
      "metadata": {
        "id": "9CRZyFW8hYKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'sample_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Sample_Stim0_delaypca.png', title_for_plot = 'Sample Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_activity')\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'sample', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'sample_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Sample_Stimpi_delaypca.png', title_for_plot = 'Sample Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key = 'network_activity')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ac1c67-1bf4-4fb0-cacc-2ce96d73ea6d",
        "id": "8dkQJ458hYKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 9.31e-03 +/- 6.76e-03\n",
            "\t\tdq = 3.54e-09 +/- 3.48e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.02e-03 sec\n",
            "\tIdentified 70 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 70).\n",
            "\tComputing recurrent Jacobian at 70 unique fixed points.\n",
            "\tComputing input Jacobian at 70 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(70, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Sample_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 4.91e-02 +/- 1.53e-02\n",
            "\t\tdq = 1.36e-08 +/- 1.02e-08\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.00e-03 sec\n",
            "\tIdentified 128 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 128).\n",
            "\tComputing recurrent Jacobian at 128 unique fixed points.\n",
            "\tComputing input Jacobian at 128 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(128, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Sample_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC Delay Period"
      ],
      "metadata": {
        "id": "el37QeWdhYKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'delay', fixed_input_array_ = delay_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Delay_delaypca.png', title_for_plot = 'Delay Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_activity')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639804bf-0b67-4031-e142-17e45006f2ff",
        "id": "Py_B7qrfhYKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tOptimization complete to desired tolerance.\n",
            "\t\t2230 iters\n",
            "\t\tq = 2.58e-04 +/- 2.39e-03\n",
            "\t\tdq = 0.00e+00 +/- 0.00e+00\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.55e-03 sec\n",
            "\tIdentified 226 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 226).\n",
            "\tComputing recurrent Jacobian at 226 unique fixed points.\n",
            "\tComputing input Jacobian at 226 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(226, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Delay_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC - Test Period"
      ],
      "metadata": {
        "id": "fhjp1SfRhYK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_0_input_array, trial_cond_for_plot = {'test_stim_value': 0.0}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Test_Stim0_delaypca.png', title_for_plot = 'Test Stim = 0.0 Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_activity')\n",
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'test', fixed_input_array_ = stim_pi_input_array, trial_cond_for_plot = {'test_stim_value': np.pi}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Test_Stimpi_delaypca.png', title_for_plot = 'Test Stim = Pi Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100, hidden_key='network_activity')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c813a0-44e1-40db-c804-3498eae6ad85",
        "id": "OmIlkieohYK7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 7.57e-03 +/- 4.86e-03\n",
            "\t\tdq = 4.54e-09 +/- 5.81e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.88e-03 sec\n",
            "\tIdentified 158 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 158).\n",
            "\tComputing recurrent Jacobian at 158 unique fixed points.\n",
            "\tComputing input Jacobian at 158 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(158, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Test_Stim0_delaypca.png\n",
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 2.76e-02 +/- 1.06e-02\n",
            "\t\tdq = 8.71e-09 +/- 9.84e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 3.14e-03 sec\n",
            "\tIdentified 207 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 207).\n",
            "\tComputing recurrent Jacobian at 207 unique fixed points.\n",
            "\tComputing input Jacobian at 207 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(207, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Test_Stimpi_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FPF LRNN-NBIC - Decision Period"
      ],
      "metadata": {
        "id": "knMj1sthhYK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_fpf_2d_pca_plot_BIC(rnn_for_fpf=LRNN_NBIC_FOR_FPF, testing_trial_data_for_fpa=LRNN_NBIC_STATETRACKED_full_testing_data, testing_trial_env_for_fpa = state_tracked_env_info, pca_object_for_plotting = LRNN_NBIC_two_d_delay_pca, ic_period = 'decision', fixed_input_array_ = response_input_array, trial_cond_for_plot = {'network_correct': True}, use_random_ics=True, use_noisey_ics = True, filename_for_plot = 'LRNN_NBIC/LRNN_NBIC_Decision_delaypca.png', title_for_plot = 'Decision Fixed Points Plotted in Delay PC1,PC2', plot_prev=True, max_trials_to_plot=100,hidden_key='network_activity')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff322def-fc49-4015-b138-87042fbbaa67",
        "id": "U_f0dMdwhYK8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for fixed points from 1200 initial states.\n",
            "\n",
            "\tFreezing model parameters so model is not affected by fixed point optimization.\n",
            "\tFinding fixed points via joint optimization.\n",
            "\tMaximum iteration count reached. Terminating.\n",
            "\t\t20000 iters\n",
            "\t\tq = 5.09e-04 +/- 5.21e-04\n",
            "\t\tdq = 7.12e-10 +/- 1.28e-09\n",
            "\t\tlearning rate = 1.97e-07\n",
            "\t\tavg iter time = 2.91e-03 sec\n",
            "\tIdentified 265 unique fixed points.\n",
            "\t\tinitial_states: 0 outliers detected (of 1200).\n",
            "\t\tfixed points: 0 outliers detected (of 265).\n",
            "\tComputing recurrent Jacobian at 265 unique fixed points.\n",
            "\tComputing input Jacobian at 265 unique fixed points.\n",
            "\tDecomposing Jacobians in a single batch.\n",
            "\tSorting by Eigenvalue magnitude.\n",
            "\tFixed point finding complete.\n",
            "\n",
            "(265, 64)\n",
            "(1200, 64)\n",
            "Figure saved to LRNN_NBIC/LRNN_NBIC_Decision_delaypca.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8y2Q7yEq4aP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}